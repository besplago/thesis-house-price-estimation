{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_utils import *\n",
    "path = \"../nybolig-scrape/output\"\n",
    "houses_df = data_to_DF(path, max_houses=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import remove_outliers\n",
    "from img_utils import preprocess_images\n",
    "\n",
    "#Take only Copenhagen, and Ejerlejligheder\n",
    "houses_df = houses_df[(houses_df['postal_code'] >= 1000) & (houses_df['postal_code'] <= 2920)]\n",
    "houses_df = houses_df[houses_df['type'] == 'ejerlejlighed']\n",
    "\n",
    "#Remove theoutliers \n",
    "houses_df = remove_outliers(houses_df, 'price')\n",
    "\n",
    "#Drop houses with no floorplan\n",
    "houses_df = houses_df.dropna(subset=['image_floorplan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Set the basement_size to 0 if it is NaN\n",
    "houses_df['basement_size'] = houses_df['basement_size'].fillna(0)\n",
    "\n",
    "#Set the year_rebuilt to year_built if it is NaN\n",
    "houses_df['year_rebuilt'] = houses_df['year_rebuilt'].fillna(houses_df['year_built'])\n",
    "\n",
    "#Encode the features: postal_code, type, energy_class\n",
    "houses_df['postal_code'] = houses_df['postal_code'].astype('category').cat.codes\n",
    "houses_df['type'] = houses_df['type'].astype('category').cat.codes\n",
    "houses_df['energy_label'] = houses_df['energy_label'].astype('category').cat.codes\n",
    "\n",
    "#Drop Adress\n",
    "houses_df = houses_df.drop(columns=['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#DROP ANY NAN VALUES\n",
    "houses_df = houses_df.dropna()\n",
    "\n",
    "# Split the data into train, validation and test sets with a 60-20-20 ratio\n",
    "train_df, test_df = train_test_split(houses_df, test_size=0.2, random_state=0)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding Vision Prediction into Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils import plot_regression_results, regression_stats\n",
    "from multiprocessing import Process\n",
    "import pandas as pd\n",
    "\n",
    "def flatten_features(features):\n",
    "    num_samples = features.shape[0]\n",
    "    flattened_features = features.reshape(num_samples, -1)\n",
    "    return flattened_features\n",
    "\n",
    "def feature_extraction_vgg16(image_data):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(500, 500, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "    features = model.predict(image_data)\n",
    "    return features\n",
    "\n",
    "def feature_extraction_custom_model(image_data, model, layer_index):\n",
    "    \"\"\"Extract features from a custom model, based on a specified layer\"\"\"\n",
    "    num_layers = len(model.layers)\n",
    "    adjusted_index = num_layers - layer_index - 1\n",
    "    print(f\"Selected layer: {model.layers[adjusted_index].name}\")\n",
    "    \n",
    "    features = model.layers[adjusted_index].output\n",
    "    model = Model(inputs=model.inputs, outputs=features)\n",
    "    features = model.predict(image_data)\n",
    "    return features\n",
    "\n",
    "def random_forest_prediction_with_feature_importance(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshold, use_model, use_custom_model=False, layer_index=0):\n",
    "    if use_model:\n",
    "        if use_custom_model:\n",
    "            vision_model = load_model('VGG16_regression_model')\n",
    "            print(vision_model.summary())\n",
    "            train_features = feature_extraction_custom_model(preprocess_images(train_df, 'image_floorplan', target_width, target_height, resize, gray_scale, threshold), vision_model, layer_index)\n",
    "            test_features = feature_extraction_custom_model(preprocess_images(test_df, 'image_floorplan', target_width, target_height, resize, gray_scale, threshold), vision_model, layer_index)\n",
    "        else:\n",
    "            train_features = feature_extraction_vgg16(preprocess_images(train_df, 'image_floorplan', target_width, target_height, resize, gray_scale, threshold))\n",
    "            test_features = feature_extraction_vgg16(preprocess_images(test_df, 'image_floorplan', target_width, target_height, resize, gray_scale, threshold))\n",
    "\n",
    "        print(f\"Train features shape: {train_features.shape}\")\n",
    "        print(f\"Test features shape: {test_features.shape}\")\n",
    "        \n",
    "        train_features_flat = flatten_features(train_features)\n",
    "        test_features_flat = flatten_features(test_features)\n",
    "        \n",
    "        train_features_df = pd.DataFrame(train_features_flat, index=train_df.index)\n",
    "        test_features_df = pd.DataFrame(test_features_flat, index=test_df.index)\n",
    "\n",
    "        # Name the new features\n",
    "        feature_names = [f'vision_feature_{i}' for i in range(train_features_flat.shape[1])]\n",
    "        train_features_df.columns = feature_names\n",
    "        test_features_df.columns = feature_names\n",
    "        \n",
    "        train_df = pd.concat([train_df, train_features_df], axis=1)\n",
    "        test_df = pd.concat([test_df, test_features_df], axis=1)\n",
    "\n",
    "    # Setup Training Data\n",
    "    x_train = train_df.drop(columns=['image_floorplan', 'price'])\n",
    "    y_train = train_df['price']\n",
    "    x_test = test_df.drop(columns=['image_floorplan', 'price'])\n",
    "    y_test = test_df['price']\n",
    "    \n",
    "    # Train model with RandomForestRegressor\n",
    "    forest = RandomForestRegressor(random_state=0)\n",
    "    forest.fit(x_train, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = forest.feature_importances_\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "    \n",
    "    # Select top features\n",
    "    num_selected_features = 100\n",
    "    selected_feature_indices = sorted_indices[:num_selected_features]\n",
    "    x_train_selected = x_train.iloc[:, selected_feature_indices]\n",
    "    x_test_selected = x_test.iloc[:, selected_feature_indices]\n",
    "    \n",
    "    # Train model with selected features\n",
    "    forest_selected = RandomForestRegressor(random_state=0)\n",
    "    forest_selected.fit(x_train_selected, y_train)\n",
    "    \n",
    "    y_test_pred = forest_selected.predict(x_test_selected)\n",
    "\n",
    "    regression_stats(y_test, y_test_pred)\n",
    "    plot_regression_results('Random Forest Regression with Feature Importance', y_test, y_test_pred)\n",
    "\n",
    "target_width = 500\n",
    "target_height = 500\n",
    "resize = True\n",
    "gray_scale = False\n",
    "threshhold = True\n",
    "scale = False\n",
    "\n",
    "# No model\n",
    "p = Process(target=random_forest_prediction_with_feature_importance, args=(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshhold, False))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "# Base VGG16 model\n",
    "p = Process(target=random_forest_prediction_with_feature_importance, args=(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshhold, True))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "# Transfer learned mode with layer index 0\n",
    "p = Process(target=random_forest_prediction_with_feature_importance, args=(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshhold, True, True, 0))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "# Transfer learned mode with layer index 2\n",
    "p = Process(target=random_forest_prediction_with_feature_importance, args=(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshhold, True, True, 2))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "# Transfer learned mode with layer index 4\n",
    "p = Process(target=random_forest_prediction_with_feature_importance, args=(train_df, valid_df, test_df, target_width, target_height, resize, gray_scale, threshhold, True, True, 4))\n",
    "p.start()\n",
    "p.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
