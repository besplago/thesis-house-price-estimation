{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 09:48:01.175233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, MobileNetV3Small\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing output/train/train_1: 100%|██████████| 311/311 [00:00<00:00, 360339.38it/s]\n",
      "Processing output/train/train_2: 100%|██████████| 312/312 [00:00<00:00, 511380.56it/s]\n",
      "Processing output/valid: 100%|██████████| 89/89 [00:00<00:00, 257088.88it/s]\n",
      "Processing output/test: 100%|██████████| 178/178 [00:00<00:00, 462282.42it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 35.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from img_utils import data_to_df\n",
    "#try reloading the module\n",
    "IMAGE_WIDTH: int = 224\n",
    "IMAGE_HEIGHT: int = 224\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "\n",
    "train_1_path: str = \"output/train/train_1\"\n",
    "train_2_path: str = \"output/train/train_2\"\n",
    "valid_path: str = \"output/valid\"\n",
    "test_path: str = \"output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "# TODO: Would be better with this format\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_expected_predicted(test_prices, test_predictions, img_dir):\n",
    "        #Set X and Y axis to [0, 9.000.000]\n",
    "    #plt.xlim(0, 9999999)\n",
    "    #plt.ylim(0, 9999999)\n",
    "    plt.scatter(test_prices, test_predictions)\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(\"Expected vs Predicted Price\")\n",
    "    try: \n",
    "        plt.plot([min(test_prices), max(test_prices)], [min(test_prices), max(test_prices)], color='red')\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f\"{img_dir}/expected_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_residuals(test_prices, test_predictions, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    plt.scatter(test_predictions, residuals)\n",
    "    try:\n",
    "        plt.hlines(y=0, xmin=test_prices.min(), xmax=test_prices.max(), colors=\"r\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(f\"{img_dir}/residuals.png\")\n",
    "    plt.close()\n",
    "\n",
    "def get_saliency_map(model, image):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "    gradients = tape.gradient(prediction, image)\n",
    "    gradients = tf.squeeze(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy()\n",
    "    gradients = (gradients - np.min(gradients)) / (np.max(gradients) - np.min(gradients))\n",
    "    return gradients\n",
    "\n",
    "def save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    test_images = np.array(test_images)\n",
    "    for i, idx in enumerate(worst_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    for i, idx in enumerate(best_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_{i}.png\")\n",
    "        plt.close()\n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_features_importance(feature_importance, img_dir):\n",
    "    #sort the feature_importance dict by value\n",
    "    feature_importance = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #add percentages to the bars\n",
    "    plt.bar(feature_importance.keys(), feature_importance.values())\n",
    "    #plt.bar_label = feature_importance.values()\n",
    "    plt.title('Feature Importance')\n",
    "    #Remove y-labels\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=90)\n",
    "    #Zoom out so that text is visible \n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.savefig(f\"{img_dir}/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_worst_best(test_predictions, test_prices, test_features, model_dir):\n",
    "    #Find the best predictions, and worst predictions. \n",
    "    #Save them in two dataframes. Save a latex of the dataframe in a txt-file \n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    \n",
    "    test_features_ = pd.DataFrame(test_features).copy()\n",
    "    test_features_[\"Price\"] = test_prices\n",
    "    test_features_[\"Predicted Price\"] = test_predictions\n",
    "    test_features_[\"Residual\"] = residuals\n",
    "    test_features_ = test_features_.sort_values(by=\"Residual\", ascending=False)\n",
    "    worst_df = test_features_.iloc[worst_predictions]\n",
    "    best_df = test_features_.iloc[best_predictions]\n",
    "    #save worst and best as latex in txt-file \n",
    "    worst_df.to_latex(f\"{model_dir}/worst_predictions.txt\")\n",
    "    best_df.to_latex(f\"{model_dir}/best_predictions.txt\")\n",
    "    \n",
    "def get_reconstructions(CNN_AE_RF_model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    for i in range(8):\n",
    "        idx = worst_predictions[i]\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        encoded_img, decoded_img = CNN_AE_RF_model.get_reconstruction(image)\n",
    "        #Show encoded, decoded side by side\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        axs[0].imshow(encoded_img)\n",
    "        axs[0].set_title(\"Encoded Image\")\n",
    "        axs[1].imshow(decoded_img)\n",
    "        axs[1].set_title(\"Decoded Image\")\n",
    "        plt.savefig(f\"{img_dir}/worst_reconstruction_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    for i in range(8):\n",
    "        idx = best_predictions[i]\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        encoded_img, decoded_img = CNN_AE_RF_model.get_reconstruction(image)\n",
    "        #Show encoded, decoded side by side\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        axs[0].imshow(encoded_img)\n",
    "        axs[0].set_title(\"Encoded Image\")\n",
    "        axs[1].imshow(decoded_img)\n",
    "        axs[1].set_title(\"Decoded Image\")\n",
    "        plt.savefig(f\"{img_dir}/best_reconstruction_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "    \n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        #Save Model Architecture\n",
    "        #plot_model(model, to_file=f\"{model_dir}/model_architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "        img = plot_model(model, to_file=f\"{model_dir}/architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "        \n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "    \n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "    \n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "    if model_type == 'CNN_AE_RF':\n",
    "        print(\"\\nSaving Reconstructions\")\n",
    "        get_reconstructions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: train_save_model() missing 1 required positional argument: 'model_type'\n"
     ]
    }
   ],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = True\n",
    "\n",
    "#TYPE = \"RF\"\n",
    "# MODEL_NAME: str = \"RF\"\n",
    "# FUNCTION: object = RF\n",
    "# ARGS: tuple = (\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "TYPE = \"CNN\"\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV2,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "p = Process(\n",
    "    target=train_save_model,\n",
    "    args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    ")\n",
    "\n",
    "\n",
    "# from models import CNN_RF_model\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "# FUNCTION: object = CNN_RF_model\n",
    "# ARGS: tuple = (\n",
    "#     # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\") #Load the model that is trained above\n",
    "#     train2_images,\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "# FUNCTION: object = CNN_AE_RF_model\n",
    "# ARGS: tuple = (\n",
    "#      # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\") #Load the model that is trained above (e.g. vgg16)\n",
    "#     train2_images,\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "# FUNCTION: object = N_CNN_RF_model\n",
    "# ARGS: tuple = (\n",
    "#     2,\n",
    "#     MobileNetV3Small,\n",
    "#     np.concatenate((train1_images, train2_images), axis=0),\n",
    "#     pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "#     np.concatenate((train1_prices, train2_prices), axis=0),\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#TYPE = \"N_CNN\"\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2\"\n",
    "# FUNCTION: object = N_CNN_model\n",
    "# ARGS: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     3,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.545454</td>\n",
       "      <td>12.234008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           49     0   111              0    3.0      2020.0        2020.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             0                   0.0  55.545454  12.234008  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>4</td>\n",
       "      <td>57450.25</td>\n",
       "      <td>55.667935</td>\n",
       "      <td>12.547432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           12     0    56              0    2.0        1897        1897.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             4              57450.25  55.667935  12.547432  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32687.5</td>\n",
       "      <td>55.736966</td>\n",
       "      <td>12.513117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           64     0    40              0    2.0      1944.0        1944.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             4               32687.5  55.736966  12.513117  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set postal_av_sqm_price as the last column \n",
    "train2_features = train2_features[['postal_code', 'type', 'size', 'basement_size', 'rooms', 'year_built','year_rebuilt', 'energy_label', 'postal_avg_sqm_price', 'lat', 'lng' ]]\n",
    "display(train2_features.head(1))\n",
    "display(test_features.head(1))\n",
    "display(train1_features.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Saving Model...\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 18:16:16.409053', 'R2': 0.863210881503027, 'MAE': 640252.7811860942, 'Percentage Error': 14.555455889401983, 'MSE': 887344164830.4703, 'Feature Importances': {'postal_code': 0.04178821765576753, 'type': 0.0, 'size': 0.7533048710417436, 'basement_size': 0.0, 'rooms': 0.012284278807655844, 'year_built': 0.028783707590687695, 'year_rebuilt': 0.029395987314544784, 'energy_label': 0.016069223872384093, 'postal_avg_sqm_price': 0.06729432938082287, 'lat': 0.016656297073025354, 'lng': 0.034423087263368325}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.824270045350453, 'MAE': 1001557.6750555441, 'Percentage Error': 27.74469519049738, 'MSE': 2038550485418.0845}\n",
      "Feauter Importance...\n",
      "{'postal_code': 0.04178821765576753, 'type': 0.0, 'size': 0.7533048710417436, 'basement_size': 0.0, 'rooms': 0.012284278807655844, 'year_built': 0.028783707590687695, 'year_rebuilt': 0.029395987314544784, 'energy_label': 0.016069223872384093, 'postal_avg_sqm_price': 0.06729432938082287, 'lat': 0.016656297073025354, 'lng': 0.034423087263368325}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import RF\n",
    "TYPE = \"RF\"\n",
    "MODEL_NAME: str = \"RF\"\n",
    "FUNCTION: object = RF\n",
    "ARGS: tuple = (\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "10/10 [==============================] - 29s 1s/step - loss: 4107199.5000 - mean_absolute_error: 4099685.2500 - val_loss: 4409029.5000 - val_mean_absolute_error: 4405765.5000\n",
      "Saving Model...\n",
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2_DONOTUSE_JUST_TESTING/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2_DONOTUSE_JUST_TESTING/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 7s 413ms/step\n",
      "Evaluating Model...\n",
      "Cant find feature_importance\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-25 10:22:57.002866', 'R2': -2.7381991723084913, 'MAE': 4214564.083321928, 'Percentage Error': 99.99443490218081, 'MSE': 24249510918483.164, 'Feature Importances': None}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': -2.7381991723084913, 'MAE': 4214564.083321928, 'Percentage Error': 99.99443490218081, 'MSE': 24249510918483.164}\n",
      "Feauter Importance...\n",
      "None\n",
      "\n",
      "Saving Best and Worst Image Predictions\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_model\n",
    "TYPE = 'CNN'\n",
    "MODEL_NAME: str = \"MobileNetV2_\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV3Small,\n",
    "    True,\n",
    "    [\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l1(0.1)),\n",
    "    # BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l1(0.1)),\n",
    "    layers.Dropout(0.1),\n",
    "    Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1(0.5)),\n",
    "    layers.Dropout(0.1),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\"),\n",
    "    ],\n",
    "\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "10/10 [==============================] - 5s 417ms/step\n",
      "Saving Model...\n",
      "6/6 [==============================] - 3s 376ms/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-25 08:17:39.326545', 'R2': 0.8761616090267981, 'MAE': 614687.5264940867, 'Percentage Error': 14.881238577325412, 'MSE': 803333443621.0787, 'Feature Importances': {'image_predictions': 0.09193175729179162, 'postal_code': 0.038931405302579915, 'type': 0.0, 'size': 0.7089138052159959, 'basement_size': 0.0, 'rooms': 0.006351376243871719, 'year_built': 0.014674708880334827, 'year_rebuilt': 0.02688644146697862, 'energy_label': 0.014482647490851257, 'postal_avg_sqm_price': 0.06393213268017557, 'lat': 0.01573478907532231, 'lng': 0.01816093635209813}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8235958143566431, 'MAE': 1003448.2358061768, 'Percentage Error': 27.956873490898488, 'MSE': 2046371883440.1582}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.09193175729179162, 'postal_code': 0.038931405302579915, 'type': 0.0, 'size': 0.7089138052159959, 'basement_size': 0.0, 'rooms': 0.006351376243871719, 'year_built': 0.014674708880334827, 'year_rebuilt': 0.02688644146697862, 'energy_label': 0.014482647490851257, 'postal_avg_sqm_price': 0.06393213268017557, 'lat': 0.01573478907532231, 'lng': 0.01816093635209813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "FUNCTION: object = CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN_AE_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1816 - val_loss: 0.1416\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1020 - val_loss: 0.0508\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0409 - val_loss: 0.0394\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0405 - val_loss: 0.0399\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0377 - val_loss: 0.0357\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0353 - val_loss: 0.0342\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0336 - val_loss: 0.0329\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0321 - val_loss: 0.0313\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 9s 1s/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 9s 998ms/step - loss: 0.0289 - val_loss: 0.0279\n"
     ]
    }
   ],
   "source": [
    "auto_encoder = autoEncoder(train2_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "10/10 [==============================] - 4s 362ms/step\n",
      "Saving Model...\n",
      "6/6 [==============================] - 3s 404ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-25 10:01:29.970411', 'R2': 0.7456372732023632, 'MAE': 944848.5407964305, 'Percentage Error': 22.41859327556923, 'MSE': 1650038276832.9985, 'Feature Importances': {'image_predictions': 0.01691056589508539, 'reconstruction_error': 0.08035195503469687, 'postal_code': 0.03394432701552655, 'type': 0.0, 'size': 0.6913527790726499, 'basement_size': 0.0, 'rooms': 0.015980351233642, 'year_built': 0.025645998604576746, 'year_rebuilt': 0.02622153179263347, 'energy_label': 0.010979129287475718, 'lat': 0.010986148058905439, 'lng': 0.02015340542174038, 'postal_avg_sqm_price': 0.06747380858306766}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8519615984605398, 'MAE': 883771.7422872891, 'Percentage Error': 22.36713524268901, 'MSE': 1354684423379.0215}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.01691056589508539, 'reconstruction_error': 0.08035195503469687, 'postal_code': 0.03394432701552655, 'type': 0.0, 'size': 0.6913527790726499, 'basement_size': 0.0, 'rooms': 0.015980351233642, 'year_built': 0.025645998604576746, 'year_rebuilt': 0.02622153179263347, 'energy_label': 0.010979129287475718, 'lat': 0.010986148058905439, 'lng': 0.02015340542174038, 'postal_avg_sqm_price': 0.06747380858306766}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n",
      "\n",
      "Saving Reconstructions\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m FUNCTION: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m CNN_AE_RF_model\n\u001b[1;32m      6\u001b[0m ARGS: \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     img_model, \u001b[38;5;66;03m#keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     auto_encoder, \u001b[38;5;66;03m#Or none for training it from scratch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     train2_prices,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFUNCTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mARGS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODELS_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSE_GPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTYPE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 317\u001b[0m, in \u001b[0;36mtrain_save_model\u001b[0;34m(model_func, args, test_images, test_features, test_prices, model_dir, use_gpu, model_type)\u001b[0m\n\u001b[1;32m    315\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    316\u001b[0m     fit_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m \u001b[43msave_model_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 290\u001b[0m, in \u001b[0;36msave_model_and_evaluate\u001b[0;34m(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_AE_RF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaving Reconstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m     \u001b[43mget_reconstructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 139\u001b[0m, in \u001b[0;36mget_reconstructions\u001b[0;34m(CNN_AE_RF_model, test_predictions, test_prices, test_images, img_dir)\u001b[0m\n\u001b[1;32m    137\u001b[0m prediction \u001b[38;5;241m=\u001b[39m test_predictions[idx]\n\u001b[1;32m    138\u001b[0m residual \u001b[38;5;241m=\u001b[39m residuals[idx]\n\u001b[0;32m--> 139\u001b[0m encoded_img, decoded_img \u001b[38;5;241m=\u001b[39m \u001b[43mCNN_AE_RF_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#Show encoded, decoded side by side\u001b[39;00m\n\u001b[1;32m    141\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Google Drev/Datalogi/Masters Project/Git/thesis-house-price-estimation/models.py:394\u001b[0m, in \u001b[0;36mCNN_AE_RF.get_reconstruction\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_reconstruction\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 394\u001b[0m     encoded_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoEncoder_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     decoded_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoEncoder_\u001b[38;5;241m.\u001b[39mdecoder(encoded_img)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded_img, decoded_img\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/engine/input_spec.py:298\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 298\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)"
     ]
    }
   ],
   "source": [
    "from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "TYPE = 'CNN_AE_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, #keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    auto_encoder, #Or none for training it from scratch\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 26s 4s/step - loss: 4100177.0000 - mean_absolute_error: 4098541.7500 - val_loss: 3974675.0000 - val_mean_absolute_error: 3973844.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 4097649.2500 - mean_absolute_error: 4096912.5000 - val_loss: 3970960.7500 - val_mean_absolute_error: 3970133.5000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 4092029.0000 - mean_absolute_error: 4091102.2500 - val_loss: 3960168.2500 - val_mean_absolute_error: 3959062.2500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 4076274.5000 - mean_absolute_error: 4075067.5000 - val_loss: 3932723.0000 - val_mean_absolute_error: 3931239.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4038510.5000 - mean_absolute_error: 4036842.0000 - val_loss: 3870072.7500 - val_mean_absolute_error: 3867960.5000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3954569.5000 - mean_absolute_error: 3952208.7500 - val_loss: 3737726.7500 - val_mean_absolute_error: 3734789.2500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3780488.0000 - mean_absolute_error: 3777234.7500 - val_loss: 3475249.2500 - val_mean_absolute_error: 3471276.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3438744.2500 - mean_absolute_error: 3434395.0000 - val_loss: 2982499.0000 - val_mean_absolute_error: 2977296.2500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 2814942.0000 - mean_absolute_error: 2809298.7500 - val_loss: 2177082.5000 - val_mean_absolute_error: 2170456.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1899743.3750 - mean_absolute_error: 1892635.8750 - val_loss: 1801265.0000 - val_mean_absolute_error: 1793168.8750\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1722885.5000 - mean_absolute_error: 1714503.5000 - val_loss: 2004706.2500 - val_mean_absolute_error: 1995983.3750\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1832034.8750 - mean_absolute_error: 1823341.0000 - val_loss: 1888309.8750 - val_mean_absolute_error: 1879737.2500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1612350.2500 - mean_absolute_error: 1603855.3750 - val_loss: 1771766.2500 - val_mean_absolute_error: 1763449.1250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1520043.3750 - mean_absolute_error: 1511777.5000 - val_loss: 1779439.2500 - val_mean_absolute_error: 1771211.2500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1541823.3750 - mean_absolute_error: 1533539.7500 - val_loss: 1759768.6250 - val_mean_absolute_error: 1751310.1250\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1440194.8750 - mean_absolute_error: 1431624.2500 - val_loss: 1778993.2500 - val_mean_absolute_error: 1770173.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1473587.6250 - mean_absolute_error: 1464676.6250 - val_loss: 1795845.7500 - val_mean_absolute_error: 1786788.3750\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1438428.8750 - mean_absolute_error: 1429346.0000 - val_loss: 1765861.7500 - val_mean_absolute_error: 1756709.2500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1358538.1250 - mean_absolute_error: 1349330.5000 - val_loss: 1748481.6250 - val_mean_absolute_error: 1739162.2500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1322088.5000 - mean_absolute_error: 1312704.6250 - val_loss: 1745731.0000 - val_mean_absolute_error: 1736178.8750\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1283422.3750 - mean_absolute_error: 1273781.3750 - val_loss: 1747783.8750 - val_mean_absolute_error: 1737935.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1248915.0000 - mean_absolute_error: 1238972.6250 - val_loss: 1738358.0000 - val_mean_absolute_error: 1728237.3750\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1186312.8750 - mean_absolute_error: 1176112.7500 - val_loss: 1730283.5000 - val_mean_absolute_error: 1719880.8750\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1146348.3750 - mean_absolute_error: 1135816.6250 - val_loss: 1738262.5000 - val_mean_absolute_error: 1727462.7500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1056955.0000 - mean_absolute_error: 1046043.4375 - val_loss: 1728863.0000 - val_mean_absolute_error: 1717716.3750\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1005953.3125 - mean_absolute_error: 994697.4375 - val_loss: 1722714.2500 - val_mean_absolute_error: 1711225.1250\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 907454.3125 - mean_absolute_error: 895864.3750 - val_loss: 1723279.8750 - val_mean_absolute_error: 1711473.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 868888.0000 - mean_absolute_error: 856996.8750 - val_loss: 1704444.0000 - val_mean_absolute_error: 1692408.8750\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 843773.9375 - mean_absolute_error: 831674.7500 - val_loss: 1696936.6250 - val_mean_absolute_error: 1684695.8750\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 789290.8750 - mean_absolute_error: 776977.0000 - val_loss: 1707711.8750 - val_mean_absolute_error: 1695237.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 742668.8125 - mean_absolute_error: 730122.8750 - val_loss: 1706036.6250 - val_mean_absolute_error: 1693371.5000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 675427.8125 - mean_absolute_error: 662706.0625 - val_loss: 1700993.2500 - val_mean_absolute_error: 1688158.3750\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 621737.5000 - mean_absolute_error: 608861.6875 - val_loss: 1715633.0000 - val_mean_absolute_error: 1702660.1250\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 612536.3750 - mean_absolute_error: 599535.4375 - val_loss: 1698939.2500 - val_mean_absolute_error: 1685836.8750\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 569158.0625 - mean_absolute_error: 555981.9375 - val_loss: 1738215.6250 - val_mean_absolute_error: 1724908.3750\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 553450.0625 - mean_absolute_error: 540121.1875 - val_loss: 1696290.2500 - val_mean_absolute_error: 1682888.3750\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 520288.3750 - mean_absolute_error: 506814.1875 - val_loss: 1716271.8750 - val_mean_absolute_error: 1702681.6250\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 468165.3438 - mean_absolute_error: 454563.5938 - val_loss: 1690459.3750 - val_mean_absolute_error: 1676797.2500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 463170.1250 - mean_absolute_error: 449440.0938 - val_loss: 1706466.2500 - val_mean_absolute_error: 1692650.3750\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 441544.8438 - mean_absolute_error: 427714.1562 - val_loss: 1689687.8750 - val_mean_absolute_error: 1675778.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 415434.7812 - mean_absolute_error: 401462.9688 - val_loss: 1696917.6250 - val_mean_absolute_error: 1682884.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 434183.9688 - mean_absolute_error: 420149.9062 - val_loss: 1696430.0000 - val_mean_absolute_error: 1682331.2500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 421533.6875 - mean_absolute_error: 407397.5000 - val_loss: 1697313.5000 - val_mean_absolute_error: 1683192.5000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 404388.6875 - mean_absolute_error: 390287.3438 - val_loss: 1686514.6250 - val_mean_absolute_error: 1672372.5000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 376165.1875 - mean_absolute_error: 361993.5625 - val_loss: 1697065.1250 - val_mean_absolute_error: 1682863.8750\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 354906.9062 - mean_absolute_error: 340695.2812 - val_loss: 1679208.7500 - val_mean_absolute_error: 1664999.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 336811.2188 - mean_absolute_error: 322599.8125 - val_loss: 1690486.3750 - val_mean_absolute_error: 1676237.8750\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 326369.9062 - mean_absolute_error: 312117.8750 - val_loss: 1674290.2500 - val_mean_absolute_error: 1660048.8750\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 341445.5000 - mean_absolute_error: 327200.1562 - val_loss: 1695117.5000 - val_mean_absolute_error: 1680830.3750\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 320868.0625 - mean_absolute_error: 306586.9062 - val_loss: 1674588.0000 - val_mean_absolute_error: 1660331.2500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 335220.0938 - mean_absolute_error: 320958.8438 - val_loss: 1701961.1250 - val_mean_absolute_error: 1687657.2500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 329399.9688 - mean_absolute_error: 315099.9688 - val_loss: 1673557.2500 - val_mean_absolute_error: 1659279.3750\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 315003.2188 - mean_absolute_error: 300701.0312 - val_loss: 1691344.1250 - val_mean_absolute_error: 1676966.6250\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 311652.9062 - mean_absolute_error: 297267.0625 - val_loss: 1679542.2500 - val_mean_absolute_error: 1665187.8750\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 297845.9688 - mean_absolute_error: 283487.3438 - val_loss: 1684935.6250 - val_mean_absolute_error: 1670556.3750\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 289533.8438 - mean_absolute_error: 275147.9375 - val_loss: 1677300.0000 - val_mean_absolute_error: 1662930.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 262749.3750 - mean_absolute_error: 248376.1094 - val_loss: 1686769.5000 - val_mean_absolute_error: 1672357.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 270607.1250 - mean_absolute_error: 256177.5781 - val_loss: 1684866.0000 - val_mean_absolute_error: 1670425.1250\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 282554.0625 - mean_absolute_error: 268116.5938 - val_loss: 1683242.0000 - val_mean_absolute_error: 1668792.3750\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 34s 5s/step - loss: 3976304.5000 - mean_absolute_error: 3974670.7500 - val_loss: 4099196.2500 - val_mean_absolute_error: 4098403.2500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3974827.0000 - mean_absolute_error: 3974155.0000 - val_loss: 4097955.7500 - val_mean_absolute_error: 4097257.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 3973210.0000 - mean_absolute_error: 3972459.7500 - val_loss: 4094795.2500 - val_mean_absolute_error: 4093989.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3968725.2500 - mean_absolute_error: 3967885.2500 - val_loss: 4087048.0000 - val_mean_absolute_error: 4086078.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3958400.2500 - mean_absolute_error: 3957320.0000 - val_loss: 4069958.7500 - val_mean_absolute_error: 4068606.2500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3936296.0000 - mean_absolute_error: 3934789.2500 - val_loss: 4034429.5000 - val_mean_absolute_error: 4032550.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3890625.7500 - mean_absolute_error: 3888532.2500 - val_loss: 3964951.7500 - val_mean_absolute_error: 3962349.2500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3803648.0000 - mean_absolute_error: 3800767.2500 - val_loss: 3835349.0000 - val_mean_absolute_error: 3831822.2500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3644141.0000 - mean_absolute_error: 3640269.0000 - val_loss: 3603675.0000 - val_mean_absolute_error: 3599017.7500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3364498.5000 - mean_absolute_error: 3359437.5000 - val_loss: 3204906.7500 - val_mean_absolute_error: 3198932.7500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2885287.0000 - mean_absolute_error: 2878844.5000 - val_loss: 2538751.5000 - val_mean_absolute_error: 2531259.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2214636.0000 - mean_absolute_error: 2206624.5000 - val_loss: 1742887.7500 - val_mean_absolute_error: 1733783.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1741452.6250 - mean_absolute_error: 1731926.6250 - val_loss: 1664915.0000 - val_mean_absolute_error: 1654627.5000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1900587.8750 - mean_absolute_error: 1890131.1250 - val_loss: 1766443.2500 - val_mean_absolute_error: 1755808.8750\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1969994.3750 - mean_absolute_error: 1959387.6250 - val_loss: 1664059.2500 - val_mean_absolute_error: 1653576.3750\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1791478.8750 - mean_absolute_error: 1781049.1250 - val_loss: 1590638.5000 - val_mean_absolute_error: 1580347.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1715018.5000 - mean_absolute_error: 1704798.0000 - val_loss: 1646566.7500 - val_mean_absolute_error: 1636428.8750\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1687493.8750 - mean_absolute_error: 1677329.5000 - val_loss: 1660895.7500 - val_mean_absolute_error: 1650618.1250\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1690164.1250 - mean_absolute_error: 1679782.2500 - val_loss: 1602626.7500 - val_mean_absolute_error: 1592039.2500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1622225.1250 - mean_absolute_error: 1611535.7500 - val_loss: 1574485.2500 - val_mean_absolute_error: 1563562.3750\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1600647.7500 - mean_absolute_error: 1589602.7500 - val_loss: 1563560.7500 - val_mean_absolute_error: 1552269.1250\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1559533.1250 - mean_absolute_error: 1548138.0000 - val_loss: 1559081.2500 - val_mean_absolute_error: 1547501.3750\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1510934.0000 - mean_absolute_error: 1499278.5000 - val_loss: 1555217.7500 - val_mean_absolute_error: 1543393.1250\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1491105.8750 - mean_absolute_error: 1479197.2500 - val_loss: 1556308.3750 - val_mean_absolute_error: 1544218.3750\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1437078.3750 - mean_absolute_error: 1424892.2500 - val_loss: 1554964.5000 - val_mean_absolute_error: 1542550.2500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1377099.1250 - mean_absolute_error: 1364573.7500 - val_loss: 1544985.3750 - val_mean_absolute_error: 1532178.2500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1308818.7500 - mean_absolute_error: 1295879.3750 - val_loss: 1531988.0000 - val_mean_absolute_error: 1518729.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1253495.1250 - mean_absolute_error: 1240082.1250 - val_loss: 1532812.8750 - val_mean_absolute_error: 1519090.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1201017.1250 - mean_absolute_error: 1187180.1250 - val_loss: 1519717.7500 - val_mean_absolute_error: 1505636.7500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1133075.1250 - mean_absolute_error: 1118872.6250 - val_loss: 1514796.2500 - val_mean_absolute_error: 1500325.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1055089.3750 - mean_absolute_error: 1040470.0625 - val_loss: 1516297.3750 - val_mean_absolute_error: 1501346.2500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 980425.0625 - mean_absolute_error: 965329.0625 - val_loss: 1513659.3750 - val_mean_absolute_error: 1498295.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 876145.3125 - mean_absolute_error: 860686.4375 - val_loss: 1475349.2500 - val_mean_absolute_error: 1459647.8750\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 801753.5000 - mean_absolute_error: 785888.1250 - val_loss: 1515609.2500 - val_mean_absolute_error: 1499382.2500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 769237.3750 - mean_absolute_error: 752897.9375 - val_loss: 1475593.6250 - val_mean_absolute_error: 1459052.3750\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 700496.7500 - mean_absolute_error: 683883.8125 - val_loss: 1448621.3750 - val_mean_absolute_error: 1431848.6250\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 644020.1875 - mean_absolute_error: 627177.0000 - val_loss: 1461037.7500 - val_mean_absolute_error: 1444007.3750\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 625478.8750 - mean_absolute_error: 608383.6875 - val_loss: 1446564.8750 - val_mean_absolute_error: 1429351.2500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 569737.2500 - mean_absolute_error: 552482.5000 - val_loss: 1427748.1250 - val_mean_absolute_error: 1410378.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 501104.4062 - mean_absolute_error: 483671.2500 - val_loss: 1421685.0000 - val_mean_absolute_error: 1404122.1250\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 462129.5938 - mean_absolute_error: 444507.2188 - val_loss: 1432555.5000 - val_mean_absolute_error: 1414800.6250\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 453200.2812 - mean_absolute_error: 435425.0000 - val_loss: 1428013.1250 - val_mean_absolute_error: 1410189.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 415843.2188 - mean_absolute_error: 397966.3750 - val_loss: 1442298.6250 - val_mean_absolute_error: 1424311.1250\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 407946.4375 - mean_absolute_error: 389937.8750 - val_loss: 1429138.8750 - val_mean_absolute_error: 1411106.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 370956.7188 - mean_absolute_error: 352879.0312 - val_loss: 1434710.0000 - val_mean_absolute_error: 1416550.8750\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 342406.1250 - mean_absolute_error: 324234.8750 - val_loss: 1418033.2500 - val_mean_absolute_error: 1399834.2500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 23s 6s/step - loss: 315398.7812 - mean_absolute_error: 297175.4688 - val_loss: 1420816.3750 - val_mean_absolute_error: 1402513.8750\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 23s 6s/step - loss: 328981.3438 - mean_absolute_error: 310657.8750 - val_loss: 1410647.1250 - val_mean_absolute_error: 1392323.6250\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 352243.1250 - mean_absolute_error: 333913.0312 - val_loss: 1427040.7500 - val_mean_absolute_error: 1408652.1250\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 327120.6562 - mean_absolute_error: 308719.2188 - val_loss: 1418219.3750 - val_mean_absolute_error: 1399848.8750\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 307199.8438 - mean_absolute_error: 288844.8750 - val_loss: 1420129.6250 - val_mean_absolute_error: 1401749.2500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 290419.6562 - mean_absolute_error: 272032.7500 - val_loss: 1414363.2500 - val_mean_absolute_error: 1395978.5000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 21s 6s/step - loss: 280604.3438 - mean_absolute_error: 262212.6562 - val_loss: 1409908.1250 - val_mean_absolute_error: 1391491.1250\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 271478.3750 - mean_absolute_error: 253049.6250 - val_loss: 1413444.7500 - val_mean_absolute_error: 1394989.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 269014.8750 - mean_absolute_error: 250565.1562 - val_loss: 1414836.1250 - val_mean_absolute_error: 1396405.3750\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 241755.1562 - mean_absolute_error: 223312.8594 - val_loss: 1419636.8750 - val_mean_absolute_error: 1401210.2500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 266771.1562 - mean_absolute_error: 248357.0156 - val_loss: 1420576.2500 - val_mean_absolute_error: 1402146.6250\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 260976.1562 - mean_absolute_error: 242545.1719 - val_loss: 1413729.0000 - val_mean_absolute_error: 1395320.3750\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 258756.6875 - mean_absolute_error: 240347.0625 - val_loss: 1410047.6250 - val_mean_absolute_error: 1391637.6250\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 226225.2031 - mean_absolute_error: 207826.3750 - val_loss: 1407919.3750 - val_mean_absolute_error: 1389542.5000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 238422.9844 - mean_absolute_error: 220048.4688 - val_loss: 1421045.0000 - val_mean_absolute_error: 1402658.8750\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 230396.2031 - mean_absolute_error: 212019.0156 - val_loss: 1406107.8750 - val_mean_absolute_error: 1387781.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 267315.5625 - mean_absolute_error: 248996.4219 - val_loss: 1425627.1250 - val_mean_absolute_error: 1407272.6250\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 225972.0781 - mean_absolute_error: 207614.5625 - val_loss: 1409226.1250 - val_mean_absolute_error: 1390904.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 224330.7812 - mean_absolute_error: 206015.8750 - val_loss: 1416229.6250 - val_mean_absolute_error: 1397883.2500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 218999.4531 - mean_absolute_error: 200637.4844 - val_loss: 1403775.6250 - val_mean_absolute_error: 1385404.5000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 209399.6094 - mean_absolute_error: 191024.0312 - val_loss: 1398864.6250 - val_mean_absolute_error: 1380457.6250\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 216881.3125 - mean_absolute_error: 198464.0156 - val_loss: 1388600.1250 - val_mean_absolute_error: 1370207.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 219194.3750 - mean_absolute_error: 200833.4844 - val_loss: 1389658.5000 - val_mean_absolute_error: 1371339.5000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 198351.2812 - mean_absolute_error: 180035.1406 - val_loss: 1399232.8750 - val_mean_absolute_error: 1380925.3750\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 218328.7188 - mean_absolute_error: 200032.7188 - val_loss: 1399637.0000 - val_mean_absolute_error: 1381311.3750\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 188630.9531 - mean_absolute_error: 170292.2812 - val_loss: 1379551.7500 - val_mean_absolute_error: 1361229.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 214524.7969 - mean_absolute_error: 196206.9844 - val_loss: 1383495.3750 - val_mean_absolute_error: 1365148.1250\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 194717.5781 - mean_absolute_error: 176353.9531 - val_loss: 1381569.2500 - val_mean_absolute_error: 1363215.6250\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 203354.5938 - mean_absolute_error: 185025.6562 - val_loss: 1376718.2500 - val_mean_absolute_error: 1358412.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 190897.6406 - mean_absolute_error: 172578.9219 - val_loss: 1386019.7500 - val_mean_absolute_error: 1367731.5000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 215214.3125 - mean_absolute_error: 196951.0938 - val_loss: 1378755.3750 - val_mean_absolute_error: 1360495.6250\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 182603.3906 - mean_absolute_error: 164316.2500 - val_loss: 1393026.8750 - val_mean_absolute_error: 1374722.6250\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 199382.9219 - mean_absolute_error: 181089.8125 - val_loss: 1379621.6250 - val_mean_absolute_error: 1361369.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 214770.8906 - mean_absolute_error: 196515.2031 - val_loss: 1404613.0000 - val_mean_absolute_error: 1386328.6250\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 237316.4688 - mean_absolute_error: 219045.2969 - val_loss: 1381700.5000 - val_mean_absolute_error: 1363502.7500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 209845.2188 - mean_absolute_error: 191659.0312 - val_loss: 1388644.3750 - val_mean_absolute_error: 1370428.2500\n",
      "7/7 [==============================] - 15s 1s/step\n",
      "7/7 [==============================] - 12s 1s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 17:18:38.134525', 'R2': 0.4085996067265357, 'MAE': 1578480.6146965115, 'Percentage Error': 34.27526725969592, 'MSE': 6860523928253.198, 'Feature Importances': {'image_predictions': 0.8228580817555349, 'lattitude': 0.006343925500361719, 'longitude': 0.0075764932806826465, 'postal_code': 0.009048654118731516, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.10224407446855208, 'basement_size': 0.0, 'rooms': 0.041159889746165856, 'year_built': 0.0038594328984858234, 'year_rebuilt': 0.003710250746033922, 'energy_label': 0.0031991974854515643}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.6202693512057609, 'MAE': 1259895.8418233586, 'Percentage Error': 30.334324922911918, 'MSE': 4405054903538.699}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.8228580817555349, 'lattitude': 0.006343925500361719, 'longitude': 0.0075764932806826465, 'postal_code': 0.009048654118731516, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.10224407446855208, 'basement_size': 0.0, 'rooms': 0.041159889746165856, 'year_built': 0.0038594328984858234, 'year_rebuilt': 0.003710250746033922, 'energy_label': 0.0031991974854515643}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import N_CNN_RF_model\n",
    "from keras.applications import MobileNetV3Small\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "FUNCTION: object = N_CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    4,\n",
    "    MobileNetV3Small,\n",
    "    np.concatenate((train1_images, train2_images), axis=0),\n",
    "    pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "    np.concatenate((train1_prices, train2_prices), axis=0),\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
