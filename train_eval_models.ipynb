{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 10:50:42.753557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-22 10:50:42.753621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-22 10:50:42.754985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-22 10:50:42.763263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 10:50:44.331866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH: int = 448\n",
    "IMAGE_HEIGHT: int = 448\n",
    "MODELS_PATH: str = \"./vision_models\"\n",
    "USE_GPU: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ../nybolig-scrape/output/train/train_1: 100%|██████████| 311/311 [00:00<00:00, 1964500.82it/s]\n",
      "Processing ../nybolig-scrape/output/train/train_2: 100%|██████████| 312/312 [00:00<00:00, 1561602.44it/s]\n",
      "Processing ../nybolig-scrape/output/valid: 100%|██████████| 89/89 [00:00<00:00, 947444.30it/s]\n",
      "Processing ../nybolig-scrape/output/test: 100%|██████████| 178/178 [00:00<00:00, 1367373.83it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 182.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "train_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_evaluate(\n",
    "    model, fit_history, test_images, test_prices, model_dir\n",
    "):\n",
    "    # Save Model\n",
    "    print(\"Saving Model...\")\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model.save(f\"{model_dir}/model\")\n",
    "\n",
    "    # Save Training History\n",
    "    with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "        pickle.dump(fit_history.history, file_pi)\n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    test_predictions = model.predict(test_images)\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importance_\n",
    "    except AttributeError:\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": str(feature_importance) if feature_importance else None,\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"Model Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"Median Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object, args: tuple, test_images: np.array, test_prices: np.array, model_dir: str\n",
    "):\n",
    "    if USE_GPU:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    model, fit_history = model_func(*args)\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_prices, model_dir)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object, args: tuple, test_images: np.array, test_prices: np.array, model_dir: str\n",
    "):\n",
    "    if USE_GPU:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model,\n",
    "            fit_history,\n",
    "            test_images,\n",
    "            test_prices,\n",
    "            f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 10:54:36.449036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.498913: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.499048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.503280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.503518: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.503628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 10:54:36.685594: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.685904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.685937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-22 10:54:36.686042: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 10:54:36.686077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 10:54:44.648400: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-22 10:54:44.726745: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-22 10:54:44.924944: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-22 10:54:48.341362: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f51e1b70dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-22 10:54:48.341433: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-04-22 10:54:48.348428: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713776088.420974   46590 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 16s 761ms/step - loss: 4097187.5000 - mean_absolute_error: 4095483.2500 - val_loss: 4385090.5000 - val_mean_absolute_error: 4383242.5000\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 4024998.5000 - mean_absolute_error: 4022337.7500 - val_loss: 4167484.5000 - val_mean_absolute_error: 4163149.0000\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 3518967.0000 - mean_absolute_error: 3512964.2500 - val_loss: 2969980.7500 - val_mean_absolute_error: 2961101.2500\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 2082090.1250 - mean_absolute_error: 2071092.0000 - val_loss: 1918351.6250 - val_mean_absolute_error: 1905259.3750\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 1896946.6250 - mean_absolute_error: 1884243.5000 - val_loss: 1908325.0000 - val_mean_absolute_error: 1896143.6250\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 1734983.8750 - mean_absolute_error: 1722730.2500 - val_loss: 1838381.8750 - val_mean_absolute_error: 1825691.0000\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1615974.6250 - mean_absolute_error: 1602944.0000 - val_loss: 1703043.3750 - val_mean_absolute_error: 1689481.5000\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1554101.0000 - mean_absolute_error: 1540276.8750 - val_loss: 1676060.3750 - val_mean_absolute_error: 1661844.0000\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 1506339.0000 - mean_absolute_error: 1491811.1250 - val_loss: 1664860.2500 - val_mean_absolute_error: 1649758.5000\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1441452.5000 - mean_absolute_error: 1425911.0000 - val_loss: 1564215.1250 - val_mean_absolute_error: 1547987.0000\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 2s 226ms/step - loss: 1371534.0000 - mean_absolute_error: 1354814.8750 - val_loss: 1581611.7500 - val_mean_absolute_error: 1564264.0000\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 1323853.8750 - mean_absolute_error: 1306000.7500 - val_loss: 1473258.2500 - val_mean_absolute_error: 1454650.2500\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1250500.2500 - mean_absolute_error: 1231437.3750 - val_loss: 1470672.6250 - val_mean_absolute_error: 1450925.2500\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 1167812.6250 - mean_absolute_error: 1147571.1250 - val_loss: 1450191.6250 - val_mean_absolute_error: 1429236.6250\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 1070561.2500 - mean_absolute_error: 1049103.6250 - val_loss: 1404941.3750 - val_mean_absolute_error: 1382748.2500\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 973090.9375 - mean_absolute_error: 950405.6875 - val_loss: 1373038.6250 - val_mean_absolute_error: 1349657.0000\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 891776.3750 - mean_absolute_error: 867989.3750 - val_loss: 1355752.2500 - val_mean_absolute_error: 1331365.3750\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 798516.1250 - mean_absolute_error: 773786.1875 - val_loss: 1347599.0000 - val_mean_absolute_error: 1322343.2500\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 745874.1250 - mean_absolute_error: 720325.0000 - val_loss: 1364101.1250 - val_mean_absolute_error: 1338137.7500\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 679600.7500 - mean_absolute_error: 653399.3125 - val_loss: 1351129.6250 - val_mean_absolute_error: 1324594.6250\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 603140.6875 - mean_absolute_error: 576383.8125 - val_loss: 1341881.8750 - val_mean_absolute_error: 1314818.2500\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 607903.3125 - mean_absolute_error: 580689.6250 - val_loss: 1332658.2500 - val_mean_absolute_error: 1305206.7500\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 560728.0625 - mean_absolute_error: 533173.5625 - val_loss: 1332211.1250 - val_mean_absolute_error: 1304430.6250\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 2s 218ms/step - loss: 521481.3750 - mean_absolute_error: 493602.7812 - val_loss: 1333820.2500 - val_mean_absolute_error: 1305819.2500\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 528342.4375 - mean_absolute_error: 500326.1875 - val_loss: 1347020.3750 - val_mean_absolute_error: 1318949.1250\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 544097.5625 - mean_absolute_error: 515976.2812 - val_loss: 1394703.0000 - val_mean_absolute_error: 1366472.6250\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 2s 218ms/step - loss: 523843.0000 - mean_absolute_error: 495454.6875 - val_loss: 1374657.5000 - val_mean_absolute_error: 1346138.5000\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 465363.4375 - mean_absolute_error: 436782.2500 - val_loss: 1356716.5000 - val_mean_absolute_error: 1328081.5000\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./vision_models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./vision_models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "6/6 [==============================] - 3s 381ms/step\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-22 10:56:42.938143', 'R2': 0.3128360843724488, 'MAE': 1497950.018404908, 'Percentage Error': 55.91313852380283, 'MSE': 4457597925288.614, 'Feature Importances': None}\n",
      "Median Evaluation:\n",
      "{'R2': 0.3099037387253228, 'MAE': 1487103.299846626, 'Percentage Error': 55.67302026742497, 'MSE': 4476619904725.53}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME: str = \"VGG16\"\n",
    "FUNCTION: object = CNN_model\n",
    "VARIABLES: tuple = (\n",
    "    VGG16,\n",
    "    True,\n",
    "    train_images,\n",
    "    train_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "p = Process(\n",
    "    target=train_save_model,\n",
    "    args=(FUNCTION, VARIABLES, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    ")\n",
    "\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2\"\n",
    "# FUNCTION: object = N_CNN_model\n",
    "# VARIABLES: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     3,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, VARIABLES, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "p.start()\n",
    "p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
