{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:24:34.503076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, MobileNetV3Small\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ../nybolig-scrape/output/train/train_1: 100%|██████████| 113/113 [00:00<00:00, 33081.34it/s]\n",
      "Processing ../nybolig-scrape/output/train/train_2: 100%|██████████| 114/114 [00:00<00:00, 261427.37it/s]\n",
      "Processing ../nybolig-scrape/output/valid: 100%|██████████| 33/33 [00:00<00:00, 103524.33it/s]\n",
      "Processing ../nybolig-scrape/output/test: 100%|██████████| 64/64 [00:00<00:00, 139446.99it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 47.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from img_utils import data_to_df\n",
    "#try reloading the module\n",
    "IMAGE_WIDTH: int = 448\n",
    "IMAGE_HEIGHT: int = 448\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "# TODO: Would be better with this format\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_expected_predicted(test_prices, test_predictions, img_dir):\n",
    "        #Set X and Y axis to [0, 9.000.000]\n",
    "    #plt.xlim(0, 9999999)\n",
    "    #plt.ylim(0, 9999999)\n",
    "    plt.scatter(test_prices, test_predictions)\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(\"Expected vs Predicted Price\")\n",
    "    try: \n",
    "        plt.plot([min(test_prices), max(test_prices)], [min(test_prices), max(test_prices)], color='red')\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f\"{img_dir}/expected_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_residuals(test_prices, test_predictions, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    plt.scatter(test_predictions, residuals)\n",
    "    try:\n",
    "        plt.hlines(y=0, xmin=test_prices.min(), xmax=test_prices.max(), colors=\"r\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(f\"{img_dir}/residuals.png\")\n",
    "    plt.close()\n",
    "\n",
    "def get_saliency_map(model, image):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "    gradients = tape.gradient(prediction, image)\n",
    "    gradients = tf.squeeze(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy()\n",
    "    gradients = (gradients - np.min(gradients)) / (np.max(gradients) - np.min(gradients))\n",
    "    return gradients\n",
    "\n",
    "def save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    test_images = np.array(test_images)\n",
    "    for i, idx in enumerate(worst_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    for i, idx in enumerate(best_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_{i}.png\")\n",
    "        plt.close()\n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_features_importance(feature_importance, img_dir):\n",
    "    #sort the feature_importance dict by value\n",
    "    feature_importance = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #add percentages to the bars\n",
    "    plt.bar(feature_importance.keys(), feature_importance.values())\n",
    "    #plt.bar_label = feature_importance.values()\n",
    "    plt.title('Feature Importance')\n",
    "    #Remove y-labels\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=90)\n",
    "    #Zoom out so that text is visible \n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.savefig(f\"{img_dir}/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_worst_best(test_predictions, test_prices, test_features, model_dir):\n",
    "    #Find the best predictions, and worst predictions. \n",
    "    #Save them in two dataframes. Save a latex of the dataframe in a txt-file \n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    \n",
    "    test_features_ = pd.DataFrame(test_features).copy()\n",
    "    test_features_[\"Price\"] = test_prices\n",
    "    test_features_[\"Predicted Price\"] = test_predictions\n",
    "    test_features_[\"Residual\"] = residuals\n",
    "    test_features_ = test_features_.sort_values(by=\"Residual\", ascending=False)\n",
    "    worst_df = test_features_.iloc[worst_predictions]\n",
    "    best_df = test_features_.iloc[best_predictions]\n",
    "    #save worst and best as latex in txt-file \n",
    "    worst_df.to_latex(f\"{model_dir}/worst_predictions.txt\")\n",
    "    best_df.to_latex(f\"{model_dir}/best_predictions.txt\")\n",
    "    \n",
    "\n",
    "\n",
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "    \n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        #Save Model Architecture\n",
    "        #plot_model(model, to_file=f\"{model_dir}/model_architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "        img = plot_model(model, to_file=f\"{model_dir}/architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "\n",
    "    if model_type == 'CNN_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "        \n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "    \n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "    \n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: train_save_model() missing 1 required positional argument: 'model_type'\n"
     ]
    }
   ],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = True\n",
    "\n",
    "#TYPE = \"RF\"\n",
    "# MODEL_NAME: str = \"RF\"\n",
    "# FUNCTION: object = RF\n",
    "# ARGS: tuple = (\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU),\n",
    "# )\n",
    "\n",
    "TYPE = \"CNN\"\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV2,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "p = Process(\n",
    "    target=train_save_model,\n",
    "    args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    ")\n",
    "\n",
    "#TYPE = \"N_CNN\"\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2\"\n",
    "# FUNCTION: object = N_CNN_model\n",
    "# ARGS: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     3,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Saving Model...\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 16:27:56.607591', 'R2': 0.8285589473024165, 'MAE': 966431.8352315673, 'Percentage Error': 26.22719955981217, 'MSE': 1988797196779.7188, 'Feature Importances': {'lattitude': 0.01705717524669862, 'longitude': 0.03229756548846307, 'postal_code': 0.10615194572626248, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6189949697329585, 'basement_size': 0.0, 'rooms': 0.18865932995915347, 'year_built': 0.013948218808430241, 'year_rebuilt': 0.0181661533729196, 'energy_label': 0.004724641665114032}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8241391743510718, 'MAE': 1004422.6693959701, 'Percentage Error': 27.814622804485744, 'MSE': 2040068650831.8735}\n",
      "Feauter Importance...\n",
      "{'lattitude': 0.01705717524669862, 'longitude': 0.03229756548846307, 'postal_code': 0.10615194572626248, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6189949697329585, 'basement_size': 0.0, 'rooms': 0.18865932995915347, 'year_built': 0.013948218808430241, 'year_rebuilt': 0.0181661533729196, 'energy_label': 0.004724641665114032}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import RF\n",
    "TYPE = \"RF\"\n",
    "MODEL_NAME: str = \"RF\"\n",
    "FUNCTION: object = RF\n",
    "ARGS: tuple = (\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 26s 3s/step - loss: 3978669.0000 - mean_absolute_error: 3977023.2500 - val_loss: 3793802.5000 - val_mean_absolute_error: 3792947.2500\n",
      "Epoch 2/100\n",
      "2/4 [==============>...............] - ETA: 5s - loss: 4196767.0000 - mean_absolute_error: 4195967.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m FUNCTION: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m CNN_model\n\u001b[1;32m      5\u001b[0m ARGS: \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     MobileNetV3Small,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     valid_prices,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFUNCTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mARGS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODELS_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSE_GPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTYPE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 267\u001b[0m, in \u001b[0;36mtrain_save_model\u001b[0;34m(model_func, args, test_images, test_features, test_prices, model_dir, use_gpu, model_type)\u001b[0m\n\u001b[1;32m    264\u001b[0m     set_cpu()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 267\u001b[0m     model, fit_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    269\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_func(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Google Drev/Datalogi/Masters Project/Git/thesis-house-price-estimation/models.py:219\u001b[0m, in \u001b[0;36mCNN_model\u001b[0;34m(pretrained_model, custom_layers, train_images, y_train, validation_images, y_valid)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m fit_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, fit_history\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import CNN_model\n",
    "TYPE = 'CNN'\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV3Small,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m MODEL_NAME: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobileNetV2_RF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m FUNCTION: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m CNN_RF_model\n\u001b[1;32m      5\u001b[0m ARGS: \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mimg_model\u001b[49m, \u001b[38;5;66;03m# keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     train2_images,\n\u001b[1;32m      8\u001b[0m     train2_features,\n\u001b[1;32m      9\u001b[0m     train2_prices,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODELS_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, USE_GPU, TYPE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_model' is not defined"
     ]
    }
   ],
   "source": [
    "from models import CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "FUNCTION: object = CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN_AE_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, #keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import N_CNN_RF_model\n",
    "from keras.applications import MobileNetV3Small\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "FUNCTION: object = N_CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    2,\n",
    "    MobileNetV3Small,\n",
    "    np.concatenate((train1_images, train2_images), axis=0),\n",
    "    pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "    np.concatenate((train1_prices, train2_prices), axis=0),\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
