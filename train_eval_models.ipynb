{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ../nybolig-scrape/output/train/train_1: 100%|██████████| 113/113 [00:00<00:00, 142714.95it/s]\n",
      "Processing ../nybolig-scrape/output/train/train_2: 100%|██████████| 114/114 [00:00<00:00, 305722.93it/s]\n",
      "Processing ../nybolig-scrape/output/valid: 100%|██████████| 33/33 [00:00<00:00, 110376.42it/s]\n",
      "Processing ../nybolig-scrape/output/test: 100%|██████████| 64/64 [00:00<00:00, 414892.51it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 28.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from img_utils import data_to_df\n",
    "#try reloading the module\n",
    "IMAGE_WIDTH: int = 448\n",
    "IMAGE_HEIGHT: int = 448\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "# TODO: Would be better with this format\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_expected_predicted(test_prices, test_predictions, img_dir):\n",
    "        #Set X and Y axis to [0, 9.000.000]\n",
    "    #plt.xlim(0, 9999999)\n",
    "    #plt.ylim(0, 9999999)\n",
    "    plt.scatter(test_prices, test_predictions)\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(\"Expected vs Predicted Price\")\n",
    "    try: \n",
    "        plt.plot([min(test_prices), max(test_prices)], [min(test_prices), max(test_prices)], color='red')\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f\"{img_dir}/expected_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_residuals(test_prices, test_predictions, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    plt.scatter(test_predictions, residuals)\n",
    "    try:\n",
    "        plt.hlines(y=0, xmin=test_prices.min(), xmax=test_prices.max(), colors=\"r\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(f\"{img_dir}/residuals.png\")\n",
    "    plt.close()\n",
    "\n",
    "def get_saliency_map(model, image):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "    gradients = tape.gradient(prediction, image)\n",
    "    gradients = tf.squeeze(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy()\n",
    "    gradients = (gradients - np.min(gradients)) / (np.max(gradients) - np.min(gradients))\n",
    "    return gradients\n",
    "\n",
    "def save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    test_images = np.array(test_images)\n",
    "    for i, idx in enumerate(worst_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    for i, idx in enumerate(best_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_{i}.png\")\n",
    "        plt.close()\n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_features_importance(feature_importance, img_dir):\n",
    "    #sort the feature_importance dict by value\n",
    "    feature_importance = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #add percentages to the bars\n",
    "    plt.bar(feature_importance.keys(), feature_importance.values())\n",
    "    #plt.bar_label = feature_importance.values()\n",
    "    plt.title('Feature Importance')\n",
    "    #Remove y-labels\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=90)\n",
    "    #Zoom out so that text is visible \n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.savefig(f\"{img_dir}/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_worst_best(test_predictions, test_prices, test_features, model_dir):\n",
    "    #Find the best predictions, and worst predictions. \n",
    "    #Save them in two dataframes. Save a latex of the dataframe in a txt-file \n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    \n",
    "    test_features_ = pd.DataFrame(test_features)\n",
    "    test_features_[\"Price\"] = test_prices\n",
    "    test_features_[\"Predicted Price\"] = test_predictions\n",
    "    test_features_[\"Residual\"] = residuals\n",
    "    test_features_ = test_features.sort_values(by=\"Residual\", ascending=False)\n",
    "    worst_df = test_features_.iloc[worst_predictions]\n",
    "    best_df = test_features_.iloc[best_predictions]\n",
    "    #save worst and best as latex in txt-file \n",
    "    worst_df.to_latex(f\"{model_dir}/worst_predictions.txt\")\n",
    "    best_df.to_latex(f\"{model_dir}/best_predictions.txt\")\n",
    "\n",
    "\n",
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "    \n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        #Save Model Architecture\n",
    "        plot_model(model, to_file=f\"{model_dir}/model_architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "        plot_model(model, to_file=\"architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "\n",
    "    if model_type == 'CNN_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "        \n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "    \n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "    \n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 11:58:56.197612: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.238691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.238782: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.242355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.242558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.242677: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 11:58:56.411413: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.411591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.411609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-22 11:58:56.411670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 11:58:56.411689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 11:59:03.690523: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-22 11:59:03.792601: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-22 11:59:04.024400: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-22 11:59:07.397578: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fe2fda5e1d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-22 11:59:07.397618: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-04-22 11:59:07.403020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713779947.498196   78260 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 16s 738ms/step - loss: 4099945.2500 - mean_absolute_error: 4098415.2500 - val_loss: 4399402.5000 - val_mean_absolute_error: 4398138.5000\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 4072331.0000 - mean_absolute_error: 4070577.0000 - val_loss: 4310734.0000 - val_mean_absolute_error: 4307788.0000\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 3848637.2500 - mean_absolute_error: 3844325.2500 - val_loss: 3719758.0000 - val_mean_absolute_error: 3712978.0000\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 2681056.2500 - mean_absolute_error: 2672059.0000 - val_loss: 1882596.0000 - val_mean_absolute_error: 1870154.5000\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 1936807.0000 - mean_absolute_error: 1923537.7500 - val_loss: 1809200.6250 - val_mean_absolute_error: 1796145.8750\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 2s 235ms/step - loss: 1695205.3750 - mean_absolute_error: 1682319.5000 - val_loss: 1888484.3750 - val_mean_absolute_error: 1875580.2500\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 1659978.5000 - mean_absolute_error: 1646757.6250 - val_loss: 1699987.6250 - val_mean_absolute_error: 1686173.7500\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 1602880.2500 - mean_absolute_error: 1588849.0000 - val_loss: 1703274.1250 - val_mean_absolute_error: 1688985.5000\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1520179.8750 - mean_absolute_error: 1505565.7500 - val_loss: 1688392.2500 - val_mean_absolute_error: 1673273.1250\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 1471942.6250 - mean_absolute_error: 1456349.5000 - val_loss: 1565390.2500 - val_mean_absolute_error: 1549108.7500\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 1401637.1250 - mean_absolute_error: 1384973.2500 - val_loss: 1644903.7500 - val_mean_absolute_error: 1627665.3750\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 1358391.6250 - mean_absolute_error: 1340657.1250 - val_loss: 1497413.7500 - val_mean_absolute_error: 1478880.0000\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 2s 225ms/step - loss: 1294372.6250 - mean_absolute_error: 1275337.3750 - val_loss: 1505976.3750 - val_mean_absolute_error: 1486136.5000\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1210737.3750 - mean_absolute_error: 1190406.3750 - val_loss: 1442443.7500 - val_mean_absolute_error: 1421260.5000\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 1185198.5000 - mean_absolute_error: 1163521.8750 - val_loss: 1476006.2500 - val_mean_absolute_error: 1453651.2500\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 1057387.1250 - mean_absolute_error: 1034502.5625 - val_loss: 1386342.1250 - val_mean_absolute_error: 1362709.3750\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 972653.0625 - mean_absolute_error: 948538.1875 - val_loss: 1420520.6250 - val_mean_absolute_error: 1395763.7500\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 890158.3125 - mean_absolute_error: 864960.6875 - val_loss: 1354782.5000 - val_mean_absolute_error: 1328992.2500\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 788178.3750 - mean_absolute_error: 761982.0000 - val_loss: 1332709.0000 - val_mean_absolute_error: 1305962.6250\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 691935.7500 - mean_absolute_error: 664857.6875 - val_loss: 1357257.6250 - val_mean_absolute_error: 1329734.1250\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 668982.1250 - mean_absolute_error: 641187.7500 - val_loss: 1326314.5000 - val_mean_absolute_error: 1298159.0000\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 611375.7500 - mean_absolute_error: 583062.8750 - val_loss: 1337861.3750 - val_mean_absolute_error: 1309326.6250\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 571407.1250 - mean_absolute_error: 542718.8125 - val_loss: 1332779.7500 - val_mean_absolute_error: 1303874.2500\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 510707.8438 - mean_absolute_error: 481699.1250 - val_loss: 1334281.0000 - val_mean_absolute_error: 1305038.2500\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 544536.3125 - mean_absolute_error: 515159.7188 - val_loss: 1339007.3750 - val_mean_absolute_error: 1309394.2500\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 521926.5625 - mean_absolute_error: 492247.9375 - val_loss: 1324271.2500 - val_mean_absolute_error: 1294472.2500\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 461539.2188 - mean_absolute_error: 431707.4375 - val_loss: 1316381.8750 - val_mean_absolute_error: 1286475.3750\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 2s 234ms/step - loss: 431638.1250 - mean_absolute_error: 401668.9062 - val_loss: 1344767.6250 - val_mean_absolute_error: 1314720.1250\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 407059.1562 - mean_absolute_error: 376950.8438 - val_loss: 1351624.6250 - val_mean_absolute_error: 1321426.2500\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 374520.8125 - mean_absolute_error: 344278.1250 - val_loss: 1360567.0000 - val_mean_absolute_error: 1330289.1250\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 2s 229ms/step - loss: 373554.7812 - mean_absolute_error: 343224.0312 - val_loss: 1334946.0000 - val_mean_absolute_error: 1304497.0000\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 367819.4688 - mean_absolute_error: 337325.4062 - val_loss: 1355985.8750 - val_mean_absolute_error: 1325448.6250\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "6/6 [==============================] - 3s 343ms/step\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-22 12:01:10.015847', 'R2': 0.3197749694068269, 'MAE': 1470665.3167177914, 'Percentage Error': 55.93252305824403, 'MSE': 4412585725390.41, 'Feature Importances': None}\n",
      "Median Evaluation:\n",
      "{'R2': 0.3113964044602101, 'MAE': 1485475.259202454, 'Percentage Error': 55.91313852380283, 'MSE': 4466937056817.391}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = True\n",
    "\n",
    "#TYPE = \"RF\"\n",
    "# MODEL_NAME: str = \"RF\"\n",
    "# FUNCTION: object = RF\n",
    "# ARGS: tuple = (\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU),\n",
    "# )\n",
    "\n",
    "TYPE = \"CNN\"\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV2,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "p = Process(\n",
    "    target=train_save_model,\n",
    "    args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    ")\n",
    "\n",
    "#TYPE = \"N_CNN\"\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2\"\n",
    "# FUNCTION: object = N_CNN_model\n",
    "# ARGS: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     3,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Saving Model...\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 14:57:43.213742', 'R2': 0.8289665942093328, 'MAE': 996231.6707605342, 'Percentage Error': 28.018551978180028, 'MSE': 1984068300094.8555, 'Feature Importances': {'lattitude': 0.01602962256428797, 'longitude': 0.042573922319192915, 'postal_code': 0.11869857747103998, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.570671807578891, 'basement_size': 0.0, 'rooms': 0.22731129682279755, 'year_built': 0.012148670466301418, 'year_rebuilt': 0.009125838054946411, 'energy_label': 0.003440264722542739}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8241391743510718, 'MAE': 1004422.6693959701, 'Percentage Error': 27.814622804485744, 'MSE': 2040068650831.8735}\n",
      "Feauter Importance...\n",
      "{'lattitude': 0.01602962256428797, 'longitude': 0.042573922319192915, 'postal_code': 0.11869857747103998, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.570671807578891, 'basement_size': 0.0, 'rooms': 0.22731129682279755, 'year_built': 0.012148670466301418, 'year_rebuilt': 0.009125838054946411, 'energy_label': 0.003440264722542739}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import RF\n",
    "TYPE = \"RF\"\n",
    "MODEL_NAME: str = \"RF\"\n",
    "FUNCTION: object = RF\n",
    "ARGS: tuple = (\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Fitting Model\n",
      "4/4 [==============================] - 44s 8s/step - loss: 3979012.0000 - mean_absolute_error: 3976821.7500 - val_loss: 3792807.2500 - val_mean_absolute_error: 3791740.0000\n",
      "Saving Model...\n",
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 5s/step\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Evaluating Model...\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 11:22:12.694251', 'R2': -1.672832482507375, 'MAE': 4405220.689214798, 'Percentage Error': 99.9189227756262, 'MSE': 31006119392239.19, 'Feature Importances': None}\n",
      "Median Evaluation:\n",
      "{'R2': -1.6735697893206494, 'MAE': 4406175.383364723, 'Percentage Error': 99.9505681825545, 'MSE': 31014672499562.867}\n",
      "Expected vs Predicted\n",
      "Residuals\n",
      "Saving Best and Worst Image Predictions\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_model\n",
    "TYPE = 'CNN'\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV2,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "4/4 [==============================] - 15s 3s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "Evaluating Model...\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 14:35:53.246289', 'R2': 0.8160100811706473, 'MAE': 1017904.6852259422, 'Percentage Error': 28.601578353487096, 'MSE': 2134369971753.5764, 'Feature Importances': {'image_predictions': 0.04981168165048342, 'lattitude': 0.012466178841286406, 'longitude': 0.03442733501581914, 'postal_code': 0.11451325660153887, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.5968602239710372, 'basement_size': 0.0, 'rooms': 0.16058157954733135, 'year_built': 0.019117720348834296, 'year_rebuilt': 0.009714347681800023, 'energy_label': 0.0025076763418691965}}\n",
      "Median Evaluation:\n",
      "{'R2': 0.8218716651945884, 'MAE': 1011506.9829500999, 'Percentage Error': 28.022329718048578, 'MSE': 2066372828175.2158}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.04981168165048342, 'lattitude': 0.012466178841286406, 'longitude': 0.03442733501581914, 'postal_code': 0.11451325660153887, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.5968602239710372, 'basement_size': 0.0, 'rooms': 0.16058157954733135, 'year_built': 0.019117720348834296, 'year_rebuilt': 0.009714347681800023, 'energy_label': 0.0025076763418691965}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Feature Importance\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "FUNCTION: object = CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN_AE_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 17s 3s/step - loss: 0.2045 - val_loss: 0.2089\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1961 - val_loss: 0.1978\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.1841 - val_loss: 0.1791\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1638 - val_loss: 0.1497\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1335 - val_loss: 0.1100\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0952 - val_loss: 0.0696\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0611 - val_loss: 0.0456\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0455 - val_loss: 0.0402\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0441 - val_loss: 0.0404\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0443 - val_loss: 0.0388\n",
      "4/4 [==============================] - 11s 2s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 7s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 14:22:38.386143', 'R2': 0.8511217609475337, 'MAE': 970361.2261451767, 'Percentage Error': 29.046820972564607, 'MSE': 1727057900252.9617, 'Feature Importances': {'image_predictions': 0.0463097610424511, 'reconstruction_error': 0.04876594116836159, 'lattitude': 0.01587018442779833, 'longitude': 0.038786463741958474, 'postal_code': 0.10793556853748301, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.5737296348626781, 'basement_size': 0.0, 'rooms': 0.1501734766219969, 'year_built': 0.0073559505727489646, 'year_rebuilt': 0.008787498384729194, 'energy_label': 0.002285520639794364}}\n",
      "Median Evaluation:\n",
      "{'R2': 0.8604386880810646, 'MAE': 952247.6402482346, 'Percentage Error': 27.988216235197285, 'MSE': 1618977144365.0898}\n",
      "Saving Prediction Results\n",
      "Saving Feature Importance\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, #keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 54s 8s/step - loss: 4019937.7500 - mean_absolute_error: 4017999.5000 - val_loss: 4068496.7500 - val_mean_absolute_error: 4067209.5000\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 36s 7s/step - loss: 4009602.5000 - mean_absolute_error: 4008039.0000 - val_loss: 4046127.5000 - val_mean_absolute_error: 4044235.2500\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 3972351.2500 - mean_absolute_error: 3970156.5000 - val_loss: 3972884.2500 - val_mean_absolute_error: 3969949.7500\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 31s 6s/step - loss: 3861631.2500 - mean_absolute_error: 3858189.5000 - val_loss: 3772308.7500 - val_mean_absolute_error: 3767880.7500\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 3576941.0000 - mean_absolute_error: 3571796.2500 - val_loss: 3290297.0000 - val_mean_absolute_error: 3283848.2500\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 2919225.5000 - mean_absolute_error: 2911897.2500 - val_loss: 2334790.5000 - val_mean_absolute_error: 2325847.2500\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1866587.6250 - mean_absolute_error: 1856659.0000 - val_loss: 1924938.6250 - val_mean_absolute_error: 1913469.0000\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1844464.0000 - mean_absolute_error: 1832687.3750 - val_loss: 2098223.2500 - val_mean_absolute_error: 2086294.2500\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1764217.2500 - mean_absolute_error: 1752506.6250 - val_loss: 1820169.2500 - val_mean_absolute_error: 1808859.7500\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1614351.7500 - mean_absolute_error: 1603210.6250 - val_loss: 1891304.6250 - val_mean_absolute_error: 1880280.2500\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1668149.7500 - mean_absolute_error: 1656998.5000 - val_loss: 1819820.3750 - val_mean_absolute_error: 1808322.0000\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1561949.6250 - mean_absolute_error: 1550182.6250 - val_loss: 1844903.1250 - val_mean_absolute_error: 1832723.5000\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1558532.5000 - mean_absolute_error: 1546247.6250 - val_loss: 1816648.2500 - val_mean_absolute_error: 1804270.6250\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1500713.2500 - mean_absolute_error: 1488297.2500 - val_loss: 1786436.3750 - val_mean_absolute_error: 1773945.0000\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1484601.0000 - mean_absolute_error: 1471981.2500 - val_loss: 1778085.8750 - val_mean_absolute_error: 1765205.0000\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1455884.2500 - mean_absolute_error: 1442829.5000 - val_loss: 1776810.3750 - val_mean_absolute_error: 1763444.0000\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1419980.2500 - mean_absolute_error: 1406447.6250 - val_loss: 1773833.8750 - val_mean_absolute_error: 1759946.6250\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1364515.3750 - mean_absolute_error: 1350423.2500 - val_loss: 1767439.1250 - val_mean_absolute_error: 1752964.5000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1342849.7500 - mean_absolute_error: 1328175.7500 - val_loss: 1759271.6250 - val_mean_absolute_error: 1744154.0000\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1307082.0000 - mean_absolute_error: 1291693.5000 - val_loss: 1754977.0000 - val_mean_absolute_error: 1739186.3750\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1253996.6250 - mean_absolute_error: 1237998.7500 - val_loss: 1737674.6250 - val_mean_absolute_error: 1721270.6250\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1209120.8750 - mean_absolute_error: 1192461.3750 - val_loss: 1738715.0000 - val_mean_absolute_error: 1721632.0000\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1156629.6250 - mean_absolute_error: 1139322.7500 - val_loss: 1706814.5000 - val_mean_absolute_error: 1689078.5000\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1089531.2500 - mean_absolute_error: 1071504.7500 - val_loss: 1712677.5000 - val_mean_absolute_error: 1694186.0000\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1040217.0000 - mean_absolute_error: 1021495.5625 - val_loss: 1680461.8750 - val_mean_absolute_error: 1661367.6250\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 991865.0625 - mean_absolute_error: 972571.3750 - val_loss: 1703512.8750 - val_mean_absolute_error: 1683833.2500\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 956938.1875 - mean_absolute_error: 937088.5625 - val_loss: 1667973.3750 - val_mean_absolute_error: 1647910.8750\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 952489.8125 - mean_absolute_error: 932279.5625 - val_loss: 1679537.7500 - val_mean_absolute_error: 1658990.0000\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 892061.8125 - mean_absolute_error: 871371.2500 - val_loss: 1654481.2500 - val_mean_absolute_error: 1633590.3750\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 785573.3125 - mean_absolute_error: 764536.7500 - val_loss: 1665482.7500 - val_mean_absolute_error: 1644162.1250\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 777362.6250 - mean_absolute_error: 755925.5625 - val_loss: 1630740.3750 - val_mean_absolute_error: 1609120.8750\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 31s 7s/step - loss: 732262.5000 - mean_absolute_error: 710478.0000 - val_loss: 1622796.7500 - val_mean_absolute_error: 1600775.2500\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 675878.1875 - mean_absolute_error: 653753.5000 - val_loss: 1630271.3750 - val_mean_absolute_error: 1607930.1250\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 652757.5625 - mean_absolute_error: 630320.0000 - val_loss: 1614030.0000 - val_mean_absolute_error: 1591490.6250\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 630149.2500 - mean_absolute_error: 607509.2500 - val_loss: 1625156.0000 - val_mean_absolute_error: 1602330.6250\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 569711.8750 - mean_absolute_error: 546845.6250 - val_loss: 1611275.6250 - val_mean_absolute_error: 1588328.8750\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 521272.9688 - mean_absolute_error: 498239.7812 - val_loss: 1605578.1250 - val_mean_absolute_error: 1582447.6250\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 501578.7500 - mean_absolute_error: 478395.7812 - val_loss: 1607361.1250 - val_mean_absolute_error: 1584065.1250\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 508060.3750 - mean_absolute_error: 484722.2812 - val_loss: 1622225.5000 - val_mean_absolute_error: 1598756.3750\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 501607.4062 - mean_absolute_error: 478109.5000 - val_loss: 1614068.2500 - val_mean_absolute_error: 1590508.2500\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 487871.7812 - mean_absolute_error: 464238.0938 - val_loss: 1608890.8750 - val_mean_absolute_error: 1585206.5000\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 457453.6875 - mean_absolute_error: 433754.0938 - val_loss: 1634068.8750 - val_mean_absolute_error: 1610303.6250\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 58s 9s/step - loss: 4150569.5000 - mean_absolute_error: 4148669.0000 - val_loss: 3809906.2500 - val_mean_absolute_error: 3808721.7500\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 39s 8s/step - loss: 4144031.2500 - mean_absolute_error: 4142637.0000 - val_loss: 3796675.5000 - val_mean_absolute_error: 3795094.0000\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 4121658.7500 - mean_absolute_error: 4119858.5000 - val_loss: 3752675.0000 - val_mean_absolute_error: 3750275.5000\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 4052766.2500 - mean_absolute_error: 4049938.5000 - val_loss: 3627901.0000 - val_mean_absolute_error: 3624223.2500\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 3869568.7500 - mean_absolute_error: 3865258.0000 - val_loss: 3316038.2500 - val_mean_absolute_error: 3310540.0000\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 3431908.7500 - mean_absolute_error: 3425578.7500 - val_loss: 2611317.7500 - val_mean_absolute_error: 2603450.5000\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 2510629.0000 - mean_absolute_error: 2501771.5000 - val_loss: 1612735.7500 - val_mean_absolute_error: 1602114.6250\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 1922035.8750 - mean_absolute_error: 1910559.7500 - val_loss: 1911060.3750 - val_mean_absolute_error: 1898650.0000\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 2077798.2500 - mean_absolute_error: 2065389.6250 - val_loss: 1744433.2500 - val_mean_absolute_error: 1732285.2500\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1864783.6250 - mean_absolute_error: 1852953.5000 - val_loss: 1541873.0000 - val_mean_absolute_error: 1530470.2500\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 35s 8s/step - loss: 1761093.7500 - mean_absolute_error: 1749722.2500 - val_loss: 1548845.2500 - val_mean_absolute_error: 1537345.2500\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 36s 7s/step - loss: 1700173.8750 - mean_absolute_error: 1688429.3750 - val_loss: 1561388.7500 - val_mean_absolute_error: 1549193.6250\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 35s 7s/step - loss: 1702550.6250 - mean_absolute_error: 1690143.5000 - val_loss: 1599352.0000 - val_mean_absolute_error: 1586737.2500\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 1656280.2500 - mean_absolute_error: 1643622.3750 - val_loss: 1544142.3750 - val_mean_absolute_error: 1531389.2500\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1618884.6250 - mean_absolute_error: 1606085.3750 - val_loss: 1517610.0000 - val_mean_absolute_error: 1504646.7500\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1598325.1250 - mean_absolute_error: 1585207.0000 - val_loss: 1529140.8750 - val_mean_absolute_error: 1515660.7500\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 1562452.0000 - mean_absolute_error: 1548731.2500 - val_loss: 1567411.0000 - val_mean_absolute_error: 1553310.0000\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1563713.7500 - mean_absolute_error: 1549431.7500 - val_loss: 1536410.1250 - val_mean_absolute_error: 1521843.5000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1502229.0000 - mean_absolute_error: 1487450.7500 - val_loss: 1522519.0000 - val_mean_absolute_error: 1507343.6250\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 39s 8s/step - loss: 1467274.7500 - mean_absolute_error: 1451862.0000 - val_loss: 1525027.2500 - val_mean_absolute_error: 1509148.7500\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/150\n",
      "5/5 [==============================] - 60s 9s/step - loss: 3943293.0000 - mean_absolute_error: 3941408.0000 - val_loss: 4225477.0000 - val_mean_absolute_error: 4224336.0000\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 3938365.0000 - mean_absolute_error: 3937035.2500 - val_loss: 4215990.5000 - val_mean_absolute_error: 4214512.5000\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 3921946.0000 - mean_absolute_error: 3920271.5000 - val_loss: 4183455.2500 - val_mean_absolute_error: 4181214.2500\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 38s 8s/step - loss: 3871108.7500 - mean_absolute_error: 3868464.7500 - val_loss: 4091606.5000 - val_mean_absolute_error: 4088147.5000\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 3734423.2500 - mean_absolute_error: 3730340.0000 - val_loss: 3858944.7500 - val_mean_absolute_error: 3853701.2500\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 3400166.0000 - mean_absolute_error: 3394107.7500 - val_loss: 3325662.2500 - val_mean_absolute_error: 3318077.0000\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 2690655.2500 - mean_absolute_error: 2682060.2500 - val_loss: 2238664.0000 - val_mean_absolute_error: 2228220.0000\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1894558.2500 - mean_absolute_error: 1883052.7500 - val_loss: 1778560.0000 - val_mean_absolute_error: 1765642.3750\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 36s 8s/step - loss: 1856140.1250 - mean_absolute_error: 1843051.2500 - val_loss: 1829924.7500 - val_mean_absolute_error: 1816810.6250\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 37s 8s/step - loss: 1779722.6250 - mean_absolute_error: 1766834.0000 - val_loss: 1701512.3750 - val_mean_absolute_error: 1688992.7500\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 1653213.2500 - mean_absolute_error: 1640770.6250 - val_loss: 1802701.6250 - val_mean_absolute_error: 1790270.3750\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1692197.6250 - mean_absolute_error: 1679643.2500 - val_loss: 1727852.6250 - val_mean_absolute_error: 1714950.5000\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 1580221.8750 - mean_absolute_error: 1567098.5000 - val_loss: 1671017.8750 - val_mean_absolute_error: 1657517.8750\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 1590319.1250 - mean_absolute_error: 1576631.3750 - val_loss: 1667339.2500 - val_mean_absolute_error: 1653405.3750\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 31s 6s/step - loss: 1553526.2500 - mean_absolute_error: 1539494.0000 - val_loss: 1673059.8750 - val_mean_absolute_error: 1658845.6250\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 1525853.0000 - mean_absolute_error: 1511512.1250 - val_loss: 1699794.7500 - val_mean_absolute_error: 1685144.6250\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 1508222.0000 - mean_absolute_error: 1493296.3750 - val_loss: 1653971.7500 - val_mean_absolute_error: 1638578.7500\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 1446327.3750 - mean_absolute_error: 1430667.0000 - val_loss: 1649620.1250 - val_mean_absolute_error: 1633522.0000\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 36s 7s/step - loss: 1408727.1250 - mean_absolute_error: 1392333.2500 - val_loss: 1641407.8750 - val_mean_absolute_error: 1624506.3750\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1350972.3750 - mean_absolute_error: 1333778.0000 - val_loss: 1634826.0000 - val_mean_absolute_error: 1617102.0000\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 27s 6s/step - loss: 1307433.0000 - mean_absolute_error: 1289395.1250 - val_loss: 1626224.8750 - val_mean_absolute_error: 1607656.5000\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1259382.5000 - mean_absolute_error: 1240494.3750 - val_loss: 1611953.2500 - val_mean_absolute_error: 1592493.2500\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 27s 6s/step - loss: 1178037.8750 - mean_absolute_error: 1158255.3750 - val_loss: 1600785.0000 - val_mean_absolute_error: 1580477.6250\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 27s 6s/step - loss: 1089927.8750 - mean_absolute_error: 1069316.3750 - val_loss: 1585758.7500 - val_mean_absolute_error: 1564595.6250\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1042980.7500 - mean_absolute_error: 1021498.9375 - val_loss: 1581377.5000 - val_mean_absolute_error: 1559348.3750\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 962446.3750 - mean_absolute_error: 940128.5625 - val_loss: 1593808.8750 - val_mean_absolute_error: 1570947.0000\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 876503.0000 - mean_absolute_error: 853367.1250 - val_loss: 1575187.1250 - val_mean_absolute_error: 1551614.7500\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 804145.3750 - mean_absolute_error: 780306.8125 - val_loss: 1625524.7500 - val_mean_absolute_error: 1601210.2500\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 32s 7s/step - loss: 755313.7500 - mean_absolute_error: 730768.6250 - val_loss: 1580838.2500 - val_mean_absolute_error: 1555950.8750\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 689884.6250 - mean_absolute_error: 664771.0000 - val_loss: 1574450.8750 - val_mean_absolute_error: 1549026.3750\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 604723.3125 - mean_absolute_error: 579183.3750 - val_loss: 1566654.5000 - val_mean_absolute_error: 1540890.5000\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 547111.1875 - mean_absolute_error: 521235.5625 - val_loss: 1567034.1250 - val_mean_absolute_error: 1540958.6250\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 502280.8125 - mean_absolute_error: 476105.9062 - val_loss: 1573505.8750 - val_mean_absolute_error: 1547149.8750\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 477470.0000 - mean_absolute_error: 450999.4688 - val_loss: 1586223.7500 - val_mean_absolute_error: 1559635.6250\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 33s 7s/step - loss: 434262.3750 - mean_absolute_error: 407618.4062 - val_loss: 1621086.0000 - val_mean_absolute_error: 1594320.7500\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 34s 7s/step - loss: 475528.5000 - mean_absolute_error: 448763.7812 - val_loss: 1579198.5000 - val_mean_absolute_error: 1552378.7500\n",
      "7/7 [==============================] - 27s 3s/step\n",
      "7/7 [==============================] - 28s 3s/step\n",
      "7/7 [==============================] - 27s 3s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 222",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m FUNCTION: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m N_CNN_RF_model\n\u001b[1;32m      5\u001b[0m ARGS: \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      7\u001b[0m     MobileNetV2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate((train1_prices, train2_prices), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrain_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFUNCTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mARGS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODELS_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSE_GPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTYPE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 198\u001b[0m, in \u001b[0;36mtrain_save_model\u001b[0;34m(model_func, args, test_images, test_features, test_prices, model_dir, use_gpu, model_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     fit_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_RF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 198\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     fit_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    200\u001b[0m save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
      "File \u001b[0;32m~/Google Drev/Datalogi/Masters Project/Git/thesis-house-price-estimation/models.py:447\u001b[0m, in \u001b[0;36mN_CNN_RF_model\u001b[0;34m(n, base_model, train_images, train_features, train_y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mN_CNN_RF_model\u001b[39m(\n\u001b[1;32m    440\u001b[0m     n,\n\u001b[1;32m    441\u001b[0m     base_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     train_y,\n\u001b[1;32m    445\u001b[0m ):\n\u001b[1;32m    446\u001b[0m     N_CNN_RF_ \u001b[38;5;241m=\u001b[39m N_CNN_RF(n, base_model)\n\u001b[0;32m--> 447\u001b[0m     \u001b[43mN_CNN_RF_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m N_CNN_RF_\n",
      "File \u001b[0;32m~/Google Drev/Datalogi/Masters Project/Git/thesis-house-price-estimation/models.py:430\u001b[0m, in \u001b[0;36mN_CNN_RF.fit\u001b[0;34m(self, train_images, train_features, train_y, n)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m#Step 2: Combine the models into a single model.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m img_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([model\u001b[38;5;241m.\u001b[39mpredict(train_images) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels])\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28minput\u001b[39m, train_y)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/lib/shape_base.py:656\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    655\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m--> 656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 222"
     ]
    }
   ],
   "source": [
    "from models import N_CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "FUNCTION: object = N_CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    3,\n",
    "    MobileNetV2,\n",
    "    #combine the two sets of images\n",
    "    np.concatenate((train1_images, train2_images), axis=0),\n",
    "    #combine the two sets of features\n",
    "    np.concatenate((train1_features, train2_features), axis=0),\n",
    "    np.concatenate((train1_prices, train2_prices), axis=0),\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
