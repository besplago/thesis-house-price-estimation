{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:24:34.503076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, MobileNetV3Small\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ../nybolig-scrape/output/train/train_1: 100%|██████████| 113/113 [00:00<00:00, 33081.34it/s]\n",
      "Processing ../nybolig-scrape/output/train/train_2: 100%|██████████| 114/114 [00:00<00:00, 261427.37it/s]\n",
      "Processing ../nybolig-scrape/output/valid: 100%|██████████| 33/33 [00:00<00:00, 103524.33it/s]\n",
      "Processing ../nybolig-scrape/output/test: 100%|██████████| 64/64 [00:00<00:00, 139446.99it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 47.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from img_utils import data_to_df\n",
    "#try reloading the module\n",
    "IMAGE_WIDTH: int = 448\n",
    "IMAGE_HEIGHT: int = 448\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "# TODO: Would be better with this format\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_expected_predicted(test_prices, test_predictions, img_dir):\n",
    "        #Set X and Y axis to [0, 9.000.000]\n",
    "    #plt.xlim(0, 9999999)\n",
    "    #plt.ylim(0, 9999999)\n",
    "    plt.scatter(test_prices, test_predictions)\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(\"Expected vs Predicted Price\")\n",
    "    try: \n",
    "        plt.plot([min(test_prices), max(test_prices)], [min(test_prices), max(test_prices)], color='red')\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f\"{img_dir}/expected_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_residuals(test_prices, test_predictions, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    plt.scatter(test_predictions, residuals)\n",
    "    try:\n",
    "        plt.hlines(y=0, xmin=test_prices.min(), xmax=test_prices.max(), colors=\"r\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(f\"{img_dir}/residuals.png\")\n",
    "    plt.close()\n",
    "\n",
    "def get_saliency_map(model, image):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "    gradients = tape.gradient(prediction, image)\n",
    "    gradients = tf.squeeze(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy()\n",
    "    gradients = (gradients - np.min(gradients)) / (np.max(gradients) - np.min(gradients))\n",
    "    return gradients\n",
    "\n",
    "def save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    test_images = np.array(test_images)\n",
    "    for i, idx in enumerate(worst_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    for i, idx in enumerate(best_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_{i}.png\")\n",
    "        plt.close()\n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_features_importance(feature_importance, img_dir):\n",
    "    #sort the feature_importance dict by value\n",
    "    feature_importance = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #add percentages to the bars\n",
    "    plt.bar(feature_importance.keys(), feature_importance.values())\n",
    "    #plt.bar_label = feature_importance.values()\n",
    "    plt.title('Feature Importance')\n",
    "    #Remove y-labels\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=90)\n",
    "    #Zoom out so that text is visible \n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.savefig(f\"{img_dir}/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_worst_best(test_predictions, test_prices, test_features, model_dir):\n",
    "    #Find the best predictions, and worst predictions. \n",
    "    #Save them in two dataframes. Save a latex of the dataframe in a txt-file \n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    \n",
    "    test_features_ = pd.DataFrame(test_features).copy()\n",
    "    test_features_[\"Price\"] = test_prices\n",
    "    test_features_[\"Predicted Price\"] = test_predictions\n",
    "    test_features_[\"Residual\"] = residuals\n",
    "    test_features_ = test_features_.sort_values(by=\"Residual\", ascending=False)\n",
    "    worst_df = test_features_.iloc[worst_predictions]\n",
    "    best_df = test_features_.iloc[best_predictions]\n",
    "    #save worst and best as latex in txt-file \n",
    "    worst_df.to_latex(f\"{model_dir}/worst_predictions.txt\")\n",
    "    best_df.to_latex(f\"{model_dir}/best_predictions.txt\")\n",
    "    \n",
    "\n",
    "\n",
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "    \n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        #Save Model Architecture\n",
    "        #plot_model(model, to_file=f\"{model_dir}/model_architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "        img = plot_model(model, to_file=f\"{model_dir}/architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "\n",
    "    if model_type == 'CNN_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "        \n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "    \n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "    \n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: train_save_model() missing 1 required positional argument: 'model_type'\n"
     ]
    }
   ],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = True\n",
    "\n",
    "#TYPE = \"RF\"\n",
    "# MODEL_NAME: str = \"RF\"\n",
    "# FUNCTION: object = RF\n",
    "# ARGS: tuple = (\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "TYPE = \"CNN\"\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV2,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "p = Process(\n",
    "    target=train_save_model,\n",
    "    args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    ")\n",
    "\n",
    "\n",
    "# from models import CNN_RF_model\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "# FUNCTION: object = CNN_RF_model\n",
    "# ARGS: tuple = (\n",
    "#     # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\") #Load the model that is trained above\n",
    "#     train2_images,\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_model,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "# FUNCTION: object = CNN_AE_RF_model\n",
    "# ARGS: tuple = (\n",
    "#      # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\") #Load the model that is trained above (e.g. vgg16)\n",
    "#     train2_images,\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# TYPE = 'CNN_RF'\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "# FUNCTION: object = N_CNN_RF_model\n",
    "# ARGS: tuple = (\n",
    "#     2,\n",
    "#     MobileNetV3Small,\n",
    "#     np.concatenate((train1_images, train2_images), axis=0),\n",
    "#     pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "#     np.concatenate((train1_prices, train2_prices), axis=0),\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#TYPE = \"N_CNN\"\n",
    "# MODEL_NAME: str = \"N_CNN_MobileNetV2\"\n",
    "# FUNCTION: object = N_CNN_model\n",
    "# ARGS: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train_images,\n",
    "#     train_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     3,\n",
    "# )\n",
    "# p = Process(\n",
    "#     target=train_save_models,\n",
    "#     args=(FUNCTION, ARGS, test_images, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\"),\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Saving Model...\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 16:27:56.607591', 'R2': 0.8285589473024165, 'MAE': 966431.8352315673, 'Percentage Error': 26.22719955981217, 'MSE': 1988797196779.7188, 'Feature Importances': {'lattitude': 0.01705717524669862, 'longitude': 0.03229756548846307, 'postal_code': 0.10615194572626248, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6189949697329585, 'basement_size': 0.0, 'rooms': 0.18865932995915347, 'year_built': 0.013948218808430241, 'year_rebuilt': 0.0181661533729196, 'energy_label': 0.004724641665114032}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8241391743510718, 'MAE': 1004422.6693959701, 'Percentage Error': 27.814622804485744, 'MSE': 2040068650831.8735}\n",
      "Feauter Importance...\n",
      "{'lattitude': 0.01705717524669862, 'longitude': 0.03229756548846307, 'postal_code': 0.10615194572626248, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6189949697329585, 'basement_size': 0.0, 'rooms': 0.18865932995915347, 'year_built': 0.013948218808430241, 'year_rebuilt': 0.0181661533729196, 'energy_label': 0.004724641665114032}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import RF\n",
    "TYPE = \"RF\"\n",
    "MODEL_NAME: str = \"RF\"\n",
    "FUNCTION: object = RF\n",
    "ARGS: tuple = (\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 34s 5s/step - loss: 3978696.5000 - mean_absolute_error: 3977040.7500 - val_loss: 3793892.7500 - val_mean_absolute_error: 3793022.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 3975840.2500 - mean_absolute_error: 3975051.7500 - val_loss: 3789566.7500 - val_mean_absolute_error: 3788664.5000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3969618.2500 - mean_absolute_error: 3968606.2500 - val_loss: 3778251.0000 - val_mean_absolute_error: 3777033.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3954062.2500 - mean_absolute_error: 3952735.2500 - val_loss: 3751231.5000 - val_mean_absolute_error: 3749606.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 3917852.5000 - mean_absolute_error: 3916042.5000 - val_loss: 3692288.7500 - val_mean_absolute_error: 3690033.2500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3841650.5000 - mean_absolute_error: 3839157.7500 - val_loss: 3573463.7500 - val_mean_absolute_error: 3570407.5000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3691023.7500 - mean_absolute_error: 3687662.5000 - val_loss: 3346542.7500 - val_mean_absolute_error: 3342475.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 3409074.2500 - mean_absolute_error: 3404648.7500 - val_loss: 2933479.0000 - val_mean_absolute_error: 2928226.5000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2903783.0000 - mean_absolute_error: 2898111.5000 - val_loss: 2224504.2500 - val_mean_absolute_error: 2217881.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2144457.0000 - mean_absolute_error: 2137375.5000 - val_loss: 1343675.2500 - val_mean_absolute_error: 1335604.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1811499.3750 - mean_absolute_error: 1803061.8750 - val_loss: 1348633.5000 - val_mean_absolute_error: 1339589.7500\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2057066.8750 - mean_absolute_error: 2047852.2500 - val_loss: 1508406.7500 - val_mean_absolute_error: 1499050.8750\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2021507.6250 - mean_absolute_error: 2012235.5000 - val_loss: 1274996.2500 - val_mean_absolute_error: 1265937.1250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1767409.0000 - mean_absolute_error: 1758444.3750 - val_loss: 1270592.5000 - val_mean_absolute_error: 1261807.2500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1716811.5000 - mean_absolute_error: 1708082.0000 - val_loss: 1423918.5000 - val_mean_absolute_error: 1415259.6250\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1756543.2500 - mean_absolute_error: 1747859.8750 - val_loss: 1432375.6250 - val_mean_absolute_error: 1423568.5000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1681392.0000 - mean_absolute_error: 1672484.2500 - val_loss: 1302667.7500 - val_mean_absolute_error: 1293500.7500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1636697.6250 - mean_absolute_error: 1627400.0000 - val_loss: 1230909.7500 - val_mean_absolute_error: 1221337.3750\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1612128.6250 - mean_absolute_error: 1602463.7500 - val_loss: 1212650.0000 - val_mean_absolute_error: 1202795.5000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1584149.2500 - mean_absolute_error: 1574231.6250 - val_loss: 1213153.0000 - val_mean_absolute_error: 1203092.2500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1542615.8750 - mean_absolute_error: 1532481.6250 - val_loss: 1226952.0000 - val_mean_absolute_error: 1216669.2500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1497973.0000 - mean_absolute_error: 1487632.3750 - val_loss: 1281860.7500 - val_mean_absolute_error: 1271331.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1477333.0000 - mean_absolute_error: 1466655.2500 - val_loss: 1221672.2500 - val_mean_absolute_error: 1210679.5000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1394143.3750 - mean_absolute_error: 1383011.3750 - val_loss: 1199296.8750 - val_mean_absolute_error: 1187881.2500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1353094.7500 - mean_absolute_error: 1341566.8750 - val_loss: 1200660.2500 - val_mean_absolute_error: 1188879.7500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1252344.7500 - mean_absolute_error: 1240446.1250 - val_loss: 1224157.6250 - val_mean_absolute_error: 1211986.2500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1174427.0000 - mean_absolute_error: 1162104.3750 - val_loss: 1191099.7500 - val_mean_absolute_error: 1178462.7500\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1093875.0000 - mean_absolute_error: 1081107.8750 - val_loss: 1160997.6250 - val_mean_absolute_error: 1147907.7500\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 10s 3s/step - loss: 994030.8125 - mean_absolute_error: 980789.4375 - val_loss: 1128923.2500 - val_mean_absolute_error: 1115335.3750\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 10s 3s/step - loss: 917465.7500 - mean_absolute_error: 903742.1875 - val_loss: 1138094.6250 - val_mean_absolute_error: 1124101.2500\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 10s 3s/step - loss: 802051.0625 - mean_absolute_error: 787935.9375 - val_loss: 1126727.3750 - val_mean_absolute_error: 1112332.6250\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 746143.8125 - mean_absolute_error: 731637.0000 - val_loss: 1113149.5000 - val_mean_absolute_error: 1098421.2500\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 682518.1875 - mean_absolute_error: 667710.5625 - val_loss: 1136141.6250 - val_mean_absolute_error: 1121178.5000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 607386.0625 - mean_absolute_error: 592356.4375 - val_loss: 1104297.5000 - val_mean_absolute_error: 1089104.2500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 581010.3750 - mean_absolute_error: 565754.0625 - val_loss: 1146599.0000 - val_mean_absolute_error: 1131239.3750\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 569618.1250 - mean_absolute_error: 554193.8125 - val_loss: 1101965.3750 - val_mean_absolute_error: 1086357.2500\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 538083.1250 - mean_absolute_error: 522426.6875 - val_loss: 1101211.0000 - val_mean_absolute_error: 1085478.7500\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 467552.0312 - mean_absolute_error: 451781.8125 - val_loss: 1122444.5000 - val_mean_absolute_error: 1106600.5000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 411378.8438 - mean_absolute_error: 395504.4375 - val_loss: 1100244.5000 - val_mean_absolute_error: 1084279.7500\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 428225.1562 - mean_absolute_error: 412211.8438 - val_loss: 1115516.5000 - val_mean_absolute_error: 1099438.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 10s 3s/step - loss: 371211.8125 - mean_absolute_error: 355104.2188 - val_loss: 1094092.0000 - val_mean_absolute_error: 1077859.6250\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 369281.0938 - mean_absolute_error: 353021.3438 - val_loss: 1129842.8750 - val_mean_absolute_error: 1113574.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 356196.5312 - mean_absolute_error: 339897.8125 - val_loss: 1088703.3750 - val_mean_absolute_error: 1072321.1250\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 325423.1250 - mean_absolute_error: 309033.9375 - val_loss: 1109823.5000 - val_mean_absolute_error: 1093433.5000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 302576.3750 - mean_absolute_error: 286169.9375 - val_loss: 1105594.5000 - val_mean_absolute_error: 1089140.2500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 290973.1562 - mean_absolute_error: 274507.2812 - val_loss: 1106193.0000 - val_mean_absolute_error: 1089701.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 283124.7500 - mean_absolute_error: 266619.6875 - val_loss: 1093331.6250 - val_mean_absolute_error: 1076801.1250\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 9s 2s/step - loss: 295312.9062 - mean_absolute_error: 278795.0625 - val_loss: 1147160.1250 - val_mean_absolute_error: 1130735.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 344547.1875 - mean_absolute_error: 328135.7188 - val_loss: 1091408.5000 - val_mean_absolute_error: 1074960.2500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 10s 2s/step - loss: 303620.2500 - mean_absolute_error: 287179.7500 - val_loss: 1120766.8750 - val_mean_absolute_error: 1104391.5000\n",
      "Saving Model...\n",
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MobileNetV2/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 1s/step\n",
      "Evaluating Model...\n",
      "Cant find feature_importance\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 16:39:29.432211', 'R2': 0.19912610641197925, 'MAE': 1839526.6587301588, 'Percentage Error': 58.97405147893265, 'MSE': 9290515483193.63, 'Feature Importances': None}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': -1.6735583622516519, 'MAE': 4406159.544906374, 'Percentage Error': 99.9500431825222, 'MSE': 31014539940164.57}\n",
      "Feauter Importance...\n",
      "None\n",
      "\n",
      "Saving Best and Worst Image Predictions\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_model\n",
    "TYPE = 'CNN'\n",
    "MODEL_NAME: str = \"MobileNetV2\"\n",
    "FUNCTION: object = CNN_model\n",
    "ARGS: tuple = (\n",
    "    MobileNetV3Small,\n",
    "    True,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 16:40:40.303149', 'R2': 0.82973645810032, 'MAE': 957930.6136137181, 'Percentage Error': 27.53683621360667, 'MSE': 1975137515290.366, 'Feature Importances': {'image_predictions': 0.05978953509743043, 'lattitude': 0.015862818708810372, 'longitude': 0.04504545153953138, 'postal_code': 0.10191371325505799, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.5684099203648966, 'basement_size': 0.0, 'rooms': 0.1807754535835351, 'year_built': 0.01497920602653795, 'year_rebuilt': 0.00884813568336506, 'energy_label': 0.004375765740835261}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8223735192612573, 'MAE': 1007864.3283610474, 'Percentage Error': 28.00639476190426, 'MSE': 2060551083935.5537}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.05978953509743043, 'lattitude': 0.015862818708810372, 'longitude': 0.04504545153953138, 'postal_code': 0.10191371325505799, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.5684099203648966, 'basement_size': 0.0, 'rooms': 0.1807754535835351, 'year_built': 0.01497920602653795, 'year_rebuilt': 0.00884813568336506, 'energy_label': 0.004375765740835261}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "FUNCTION: object = CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN_AE_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 19s 3s/step - loss: 0.2018 - val_loss: 0.2048\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1911 - val_loss: 0.1880\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1730 - val_loss: 0.1618\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1460 - val_loss: 0.1263\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.1113 - val_loss: 0.0868\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 11s 2s/step - loss: 0.0761 - val_loss: 0.0565\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0538 - val_loss: 0.0446\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0478 - val_loss: 0.0434\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0488 - val_loss: 0.0440\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0496 - val_loss: 0.0433\n",
      "4/4 [==============================] - 5s 1s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 3s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 16:43:15.093784', 'R2': 0.8966876159070315, 'MAE': 833409.4302232856, 'Percentage Error': 26.599829111681313, 'MSE': 1198472458280.8247, 'Feature Importances': {'image_predictions': 0.0547240342187647, 'reconstruction_error': 0.04026456044299854, 'lattitude': 0.017320575169738495, 'longitude': 0.04238863562559668, 'postal_code': 0.09273245711900918, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6071024800545901, 'basement_size': 0.0, 'rooms': 0.12106811127167834, 'year_built': 0.011558257289309518, 'year_rebuilt': 0.010571116912140603, 'energy_label': 0.0022697718961739743}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8697556152145957, 'MAE': 934134.0543512926, 'Percentage Error': 26.92961149782996, 'MSE': 1510896388477.218}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.0547240342187647, 'reconstruction_error': 0.04026456044299854, 'lattitude': 0.017320575169738495, 'longitude': 0.04238863562559668, 'postal_code': 0.09273245711900918, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.6071024800545901, 'basement_size': 0.0, 'rooms': 0.12106811127167834, 'year_built': 0.011558257289309518, 'year_rebuilt': 0.010571116912140603, 'energy_label': 0.0022697718961739743}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, #keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 26s 4s/step - loss: 4100177.0000 - mean_absolute_error: 4098541.7500 - val_loss: 3974675.0000 - val_mean_absolute_error: 3973844.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 4097649.2500 - mean_absolute_error: 4096912.5000 - val_loss: 3970960.7500 - val_mean_absolute_error: 3970133.5000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 4092029.0000 - mean_absolute_error: 4091102.2500 - val_loss: 3960168.2500 - val_mean_absolute_error: 3959062.2500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 4076274.5000 - mean_absolute_error: 4075067.5000 - val_loss: 3932723.0000 - val_mean_absolute_error: 3931239.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4038510.5000 - mean_absolute_error: 4036842.0000 - val_loss: 3870072.7500 - val_mean_absolute_error: 3867960.5000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3954569.5000 - mean_absolute_error: 3952208.7500 - val_loss: 3737726.7500 - val_mean_absolute_error: 3734789.2500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3780488.0000 - mean_absolute_error: 3777234.7500 - val_loss: 3475249.2500 - val_mean_absolute_error: 3471276.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3438744.2500 - mean_absolute_error: 3434395.0000 - val_loss: 2982499.0000 - val_mean_absolute_error: 2977296.2500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 2814942.0000 - mean_absolute_error: 2809298.7500 - val_loss: 2177082.5000 - val_mean_absolute_error: 2170456.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1899743.3750 - mean_absolute_error: 1892635.8750 - val_loss: 1801265.0000 - val_mean_absolute_error: 1793168.8750\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1722885.5000 - mean_absolute_error: 1714503.5000 - val_loss: 2004706.2500 - val_mean_absolute_error: 1995983.3750\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1832034.8750 - mean_absolute_error: 1823341.0000 - val_loss: 1888309.8750 - val_mean_absolute_error: 1879737.2500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1612350.2500 - mean_absolute_error: 1603855.3750 - val_loss: 1771766.2500 - val_mean_absolute_error: 1763449.1250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1520043.3750 - mean_absolute_error: 1511777.5000 - val_loss: 1779439.2500 - val_mean_absolute_error: 1771211.2500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1541823.3750 - mean_absolute_error: 1533539.7500 - val_loss: 1759768.6250 - val_mean_absolute_error: 1751310.1250\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1440194.8750 - mean_absolute_error: 1431624.2500 - val_loss: 1778993.2500 - val_mean_absolute_error: 1770173.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1473587.6250 - mean_absolute_error: 1464676.6250 - val_loss: 1795845.7500 - val_mean_absolute_error: 1786788.3750\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1438428.8750 - mean_absolute_error: 1429346.0000 - val_loss: 1765861.7500 - val_mean_absolute_error: 1756709.2500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1358538.1250 - mean_absolute_error: 1349330.5000 - val_loss: 1748481.6250 - val_mean_absolute_error: 1739162.2500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1322088.5000 - mean_absolute_error: 1312704.6250 - val_loss: 1745731.0000 - val_mean_absolute_error: 1736178.8750\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1283422.3750 - mean_absolute_error: 1273781.3750 - val_loss: 1747783.8750 - val_mean_absolute_error: 1737935.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1248915.0000 - mean_absolute_error: 1238972.6250 - val_loss: 1738358.0000 - val_mean_absolute_error: 1728237.3750\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1186312.8750 - mean_absolute_error: 1176112.7500 - val_loss: 1730283.5000 - val_mean_absolute_error: 1719880.8750\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1146348.3750 - mean_absolute_error: 1135816.6250 - val_loss: 1738262.5000 - val_mean_absolute_error: 1727462.7500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1056955.0000 - mean_absolute_error: 1046043.4375 - val_loss: 1728863.0000 - val_mean_absolute_error: 1717716.3750\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1005953.3125 - mean_absolute_error: 994697.4375 - val_loss: 1722714.2500 - val_mean_absolute_error: 1711225.1250\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 907454.3125 - mean_absolute_error: 895864.3750 - val_loss: 1723279.8750 - val_mean_absolute_error: 1711473.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 868888.0000 - mean_absolute_error: 856996.8750 - val_loss: 1704444.0000 - val_mean_absolute_error: 1692408.8750\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 843773.9375 - mean_absolute_error: 831674.7500 - val_loss: 1696936.6250 - val_mean_absolute_error: 1684695.8750\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 789290.8750 - mean_absolute_error: 776977.0000 - val_loss: 1707711.8750 - val_mean_absolute_error: 1695237.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 742668.8125 - mean_absolute_error: 730122.8750 - val_loss: 1706036.6250 - val_mean_absolute_error: 1693371.5000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 675427.8125 - mean_absolute_error: 662706.0625 - val_loss: 1700993.2500 - val_mean_absolute_error: 1688158.3750\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 621737.5000 - mean_absolute_error: 608861.6875 - val_loss: 1715633.0000 - val_mean_absolute_error: 1702660.1250\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 612536.3750 - mean_absolute_error: 599535.4375 - val_loss: 1698939.2500 - val_mean_absolute_error: 1685836.8750\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 569158.0625 - mean_absolute_error: 555981.9375 - val_loss: 1738215.6250 - val_mean_absolute_error: 1724908.3750\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 553450.0625 - mean_absolute_error: 540121.1875 - val_loss: 1696290.2500 - val_mean_absolute_error: 1682888.3750\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 520288.3750 - mean_absolute_error: 506814.1875 - val_loss: 1716271.8750 - val_mean_absolute_error: 1702681.6250\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 468165.3438 - mean_absolute_error: 454563.5938 - val_loss: 1690459.3750 - val_mean_absolute_error: 1676797.2500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 463170.1250 - mean_absolute_error: 449440.0938 - val_loss: 1706466.2500 - val_mean_absolute_error: 1692650.3750\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 441544.8438 - mean_absolute_error: 427714.1562 - val_loss: 1689687.8750 - val_mean_absolute_error: 1675778.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 415434.7812 - mean_absolute_error: 401462.9688 - val_loss: 1696917.6250 - val_mean_absolute_error: 1682884.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 434183.9688 - mean_absolute_error: 420149.9062 - val_loss: 1696430.0000 - val_mean_absolute_error: 1682331.2500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 421533.6875 - mean_absolute_error: 407397.5000 - val_loss: 1697313.5000 - val_mean_absolute_error: 1683192.5000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 404388.6875 - mean_absolute_error: 390287.3438 - val_loss: 1686514.6250 - val_mean_absolute_error: 1672372.5000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 376165.1875 - mean_absolute_error: 361993.5625 - val_loss: 1697065.1250 - val_mean_absolute_error: 1682863.8750\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 354906.9062 - mean_absolute_error: 340695.2812 - val_loss: 1679208.7500 - val_mean_absolute_error: 1664999.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 336811.2188 - mean_absolute_error: 322599.8125 - val_loss: 1690486.3750 - val_mean_absolute_error: 1676237.8750\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 326369.9062 - mean_absolute_error: 312117.8750 - val_loss: 1674290.2500 - val_mean_absolute_error: 1660048.8750\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 341445.5000 - mean_absolute_error: 327200.1562 - val_loss: 1695117.5000 - val_mean_absolute_error: 1680830.3750\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 320868.0625 - mean_absolute_error: 306586.9062 - val_loss: 1674588.0000 - val_mean_absolute_error: 1660331.2500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 335220.0938 - mean_absolute_error: 320958.8438 - val_loss: 1701961.1250 - val_mean_absolute_error: 1687657.2500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 17s 5s/step - loss: 329399.9688 - mean_absolute_error: 315099.9688 - val_loss: 1673557.2500 - val_mean_absolute_error: 1659279.3750\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 315003.2188 - mean_absolute_error: 300701.0312 - val_loss: 1691344.1250 - val_mean_absolute_error: 1676966.6250\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 311652.9062 - mean_absolute_error: 297267.0625 - val_loss: 1679542.2500 - val_mean_absolute_error: 1665187.8750\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 297845.9688 - mean_absolute_error: 283487.3438 - val_loss: 1684935.6250 - val_mean_absolute_error: 1670556.3750\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 289533.8438 - mean_absolute_error: 275147.9375 - val_loss: 1677300.0000 - val_mean_absolute_error: 1662930.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 262749.3750 - mean_absolute_error: 248376.1094 - val_loss: 1686769.5000 - val_mean_absolute_error: 1672357.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 270607.1250 - mean_absolute_error: 256177.5781 - val_loss: 1684866.0000 - val_mean_absolute_error: 1670425.1250\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 282554.0625 - mean_absolute_error: 268116.5938 - val_loss: 1683242.0000 - val_mean_absolute_error: 1668792.3750\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model\n",
      "Fitting Model\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 34s 5s/step - loss: 3976304.5000 - mean_absolute_error: 3974670.7500 - val_loss: 4099196.2500 - val_mean_absolute_error: 4098403.2500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3974827.0000 - mean_absolute_error: 3974155.0000 - val_loss: 4097955.7500 - val_mean_absolute_error: 4097257.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 3973210.0000 - mean_absolute_error: 3972459.7500 - val_loss: 4094795.2500 - val_mean_absolute_error: 4093989.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3968725.2500 - mean_absolute_error: 3967885.2500 - val_loss: 4087048.0000 - val_mean_absolute_error: 4086078.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3958400.2500 - mean_absolute_error: 3957320.0000 - val_loss: 4069958.7500 - val_mean_absolute_error: 4068606.2500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3936296.0000 - mean_absolute_error: 3934789.2500 - val_loss: 4034429.5000 - val_mean_absolute_error: 4032550.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3890625.7500 - mean_absolute_error: 3888532.2500 - val_loss: 3964951.7500 - val_mean_absolute_error: 3962349.2500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3803648.0000 - mean_absolute_error: 3800767.2500 - val_loss: 3835349.0000 - val_mean_absolute_error: 3831822.2500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3644141.0000 - mean_absolute_error: 3640269.0000 - val_loss: 3603675.0000 - val_mean_absolute_error: 3599017.7500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 3364498.5000 - mean_absolute_error: 3359437.5000 - val_loss: 3204906.7500 - val_mean_absolute_error: 3198932.7500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2885287.0000 - mean_absolute_error: 2878844.5000 - val_loss: 2538751.5000 - val_mean_absolute_error: 2531259.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2214636.0000 - mean_absolute_error: 2206624.5000 - val_loss: 1742887.7500 - val_mean_absolute_error: 1733783.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1741452.6250 - mean_absolute_error: 1731926.6250 - val_loss: 1664915.0000 - val_mean_absolute_error: 1654627.5000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1900587.8750 - mean_absolute_error: 1890131.1250 - val_loss: 1766443.2500 - val_mean_absolute_error: 1755808.8750\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1969994.3750 - mean_absolute_error: 1959387.6250 - val_loss: 1664059.2500 - val_mean_absolute_error: 1653576.3750\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1791478.8750 - mean_absolute_error: 1781049.1250 - val_loss: 1590638.5000 - val_mean_absolute_error: 1580347.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1715018.5000 - mean_absolute_error: 1704798.0000 - val_loss: 1646566.7500 - val_mean_absolute_error: 1636428.8750\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1687493.8750 - mean_absolute_error: 1677329.5000 - val_loss: 1660895.7500 - val_mean_absolute_error: 1650618.1250\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1690164.1250 - mean_absolute_error: 1679782.2500 - val_loss: 1602626.7500 - val_mean_absolute_error: 1592039.2500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1622225.1250 - mean_absolute_error: 1611535.7500 - val_loss: 1574485.2500 - val_mean_absolute_error: 1563562.3750\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1600647.7500 - mean_absolute_error: 1589602.7500 - val_loss: 1563560.7500 - val_mean_absolute_error: 1552269.1250\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1559533.1250 - mean_absolute_error: 1548138.0000 - val_loss: 1559081.2500 - val_mean_absolute_error: 1547501.3750\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1510934.0000 - mean_absolute_error: 1499278.5000 - val_loss: 1555217.7500 - val_mean_absolute_error: 1543393.1250\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1491105.8750 - mean_absolute_error: 1479197.2500 - val_loss: 1556308.3750 - val_mean_absolute_error: 1544218.3750\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1437078.3750 - mean_absolute_error: 1424892.2500 - val_loss: 1554964.5000 - val_mean_absolute_error: 1542550.2500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1377099.1250 - mean_absolute_error: 1364573.7500 - val_loss: 1544985.3750 - val_mean_absolute_error: 1532178.2500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1308818.7500 - mean_absolute_error: 1295879.3750 - val_loss: 1531988.0000 - val_mean_absolute_error: 1518729.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1253495.1250 - mean_absolute_error: 1240082.1250 - val_loss: 1532812.8750 - val_mean_absolute_error: 1519090.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1201017.1250 - mean_absolute_error: 1187180.1250 - val_loss: 1519717.7500 - val_mean_absolute_error: 1505636.7500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1133075.1250 - mean_absolute_error: 1118872.6250 - val_loss: 1514796.2500 - val_mean_absolute_error: 1500325.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 1055089.3750 - mean_absolute_error: 1040470.0625 - val_loss: 1516297.3750 - val_mean_absolute_error: 1501346.2500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 980425.0625 - mean_absolute_error: 965329.0625 - val_loss: 1513659.3750 - val_mean_absolute_error: 1498295.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 876145.3125 - mean_absolute_error: 860686.4375 - val_loss: 1475349.2500 - val_mean_absolute_error: 1459647.8750\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 801753.5000 - mean_absolute_error: 785888.1250 - val_loss: 1515609.2500 - val_mean_absolute_error: 1499382.2500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 769237.3750 - mean_absolute_error: 752897.9375 - val_loss: 1475593.6250 - val_mean_absolute_error: 1459052.3750\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 700496.7500 - mean_absolute_error: 683883.8125 - val_loss: 1448621.3750 - val_mean_absolute_error: 1431848.6250\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 644020.1875 - mean_absolute_error: 627177.0000 - val_loss: 1461037.7500 - val_mean_absolute_error: 1444007.3750\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 625478.8750 - mean_absolute_error: 608383.6875 - val_loss: 1446564.8750 - val_mean_absolute_error: 1429351.2500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 569737.2500 - mean_absolute_error: 552482.5000 - val_loss: 1427748.1250 - val_mean_absolute_error: 1410378.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 501104.4062 - mean_absolute_error: 483671.2500 - val_loss: 1421685.0000 - val_mean_absolute_error: 1404122.1250\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 462129.5938 - mean_absolute_error: 444507.2188 - val_loss: 1432555.5000 - val_mean_absolute_error: 1414800.6250\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 453200.2812 - mean_absolute_error: 435425.0000 - val_loss: 1428013.1250 - val_mean_absolute_error: 1410189.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 415843.2188 - mean_absolute_error: 397966.3750 - val_loss: 1442298.6250 - val_mean_absolute_error: 1424311.1250\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 407946.4375 - mean_absolute_error: 389937.8750 - val_loss: 1429138.8750 - val_mean_absolute_error: 1411106.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 370956.7188 - mean_absolute_error: 352879.0312 - val_loss: 1434710.0000 - val_mean_absolute_error: 1416550.8750\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 342406.1250 - mean_absolute_error: 324234.8750 - val_loss: 1418033.2500 - val_mean_absolute_error: 1399834.2500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 23s 6s/step - loss: 315398.7812 - mean_absolute_error: 297175.4688 - val_loss: 1420816.3750 - val_mean_absolute_error: 1402513.8750\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 23s 6s/step - loss: 328981.3438 - mean_absolute_error: 310657.8750 - val_loss: 1410647.1250 - val_mean_absolute_error: 1392323.6250\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 352243.1250 - mean_absolute_error: 333913.0312 - val_loss: 1427040.7500 - val_mean_absolute_error: 1408652.1250\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 327120.6562 - mean_absolute_error: 308719.2188 - val_loss: 1418219.3750 - val_mean_absolute_error: 1399848.8750\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 307199.8438 - mean_absolute_error: 288844.8750 - val_loss: 1420129.6250 - val_mean_absolute_error: 1401749.2500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 290419.6562 - mean_absolute_error: 272032.7500 - val_loss: 1414363.2500 - val_mean_absolute_error: 1395978.5000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 21s 6s/step - loss: 280604.3438 - mean_absolute_error: 262212.6562 - val_loss: 1409908.1250 - val_mean_absolute_error: 1391491.1250\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 271478.3750 - mean_absolute_error: 253049.6250 - val_loss: 1413444.7500 - val_mean_absolute_error: 1394989.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 269014.8750 - mean_absolute_error: 250565.1562 - val_loss: 1414836.1250 - val_mean_absolute_error: 1396405.3750\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 241755.1562 - mean_absolute_error: 223312.8594 - val_loss: 1419636.8750 - val_mean_absolute_error: 1401210.2500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 266771.1562 - mean_absolute_error: 248357.0156 - val_loss: 1420576.2500 - val_mean_absolute_error: 1402146.6250\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 260976.1562 - mean_absolute_error: 242545.1719 - val_loss: 1413729.0000 - val_mean_absolute_error: 1395320.3750\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 258756.6875 - mean_absolute_error: 240347.0625 - val_loss: 1410047.6250 - val_mean_absolute_error: 1391637.6250\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 226225.2031 - mean_absolute_error: 207826.3750 - val_loss: 1407919.3750 - val_mean_absolute_error: 1389542.5000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 238422.9844 - mean_absolute_error: 220048.4688 - val_loss: 1421045.0000 - val_mean_absolute_error: 1402658.8750\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 16s 5s/step - loss: 230396.2031 - mean_absolute_error: 212019.0156 - val_loss: 1406107.8750 - val_mean_absolute_error: 1387781.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 267315.5625 - mean_absolute_error: 248996.4219 - val_loss: 1425627.1250 - val_mean_absolute_error: 1407272.6250\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 225972.0781 - mean_absolute_error: 207614.5625 - val_loss: 1409226.1250 - val_mean_absolute_error: 1390904.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 224330.7812 - mean_absolute_error: 206015.8750 - val_loss: 1416229.6250 - val_mean_absolute_error: 1397883.2500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 218999.4531 - mean_absolute_error: 200637.4844 - val_loss: 1403775.6250 - val_mean_absolute_error: 1385404.5000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 209399.6094 - mean_absolute_error: 191024.0312 - val_loss: 1398864.6250 - val_mean_absolute_error: 1380457.6250\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 216881.3125 - mean_absolute_error: 198464.0156 - val_loss: 1388600.1250 - val_mean_absolute_error: 1370207.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 219194.3750 - mean_absolute_error: 200833.4844 - val_loss: 1389658.5000 - val_mean_absolute_error: 1371339.5000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 198351.2812 - mean_absolute_error: 180035.1406 - val_loss: 1399232.8750 - val_mean_absolute_error: 1380925.3750\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 15s 4s/step - loss: 218328.7188 - mean_absolute_error: 200032.7188 - val_loss: 1399637.0000 - val_mean_absolute_error: 1381311.3750\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 188630.9531 - mean_absolute_error: 170292.2812 - val_loss: 1379551.7500 - val_mean_absolute_error: 1361229.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 214524.7969 - mean_absolute_error: 196206.9844 - val_loss: 1383495.3750 - val_mean_absolute_error: 1365148.1250\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 194717.5781 - mean_absolute_error: 176353.9531 - val_loss: 1381569.2500 - val_mean_absolute_error: 1363215.6250\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 203354.5938 - mean_absolute_error: 185025.6562 - val_loss: 1376718.2500 - val_mean_absolute_error: 1358412.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 190897.6406 - mean_absolute_error: 172578.9219 - val_loss: 1386019.7500 - val_mean_absolute_error: 1367731.5000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 14s 4s/step - loss: 215214.3125 - mean_absolute_error: 196951.0938 - val_loss: 1378755.3750 - val_mean_absolute_error: 1360495.6250\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 12s 3s/step - loss: 182603.3906 - mean_absolute_error: 164316.2500 - val_loss: 1393026.8750 - val_mean_absolute_error: 1374722.6250\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 199382.9219 - mean_absolute_error: 181089.8125 - val_loss: 1379621.6250 - val_mean_absolute_error: 1361369.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 13s 3s/step - loss: 214770.8906 - mean_absolute_error: 196515.2031 - val_loss: 1404613.0000 - val_mean_absolute_error: 1386328.6250\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 237316.4688 - mean_absolute_error: 219045.2969 - val_loss: 1381700.5000 - val_mean_absolute_error: 1363502.7500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 13s 4s/step - loss: 209845.2188 - mean_absolute_error: 191659.0312 - val_loss: 1388644.3750 - val_mean_absolute_error: 1370428.2500\n",
      "7/7 [==============================] - 15s 1s/step\n",
      "7/7 [==============================] - 12s 1s/step\n",
      "Saving Model...\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-24 17:18:38.134525', 'R2': 0.4085996067265357, 'MAE': 1578480.6146965115, 'Percentage Error': 34.27526725969592, 'MSE': 6860523928253.198, 'Feature Importances': {'image_predictions': 0.8228580817555349, 'lattitude': 0.006343925500361719, 'longitude': 0.0075764932806826465, 'postal_code': 0.009048654118731516, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.10224407446855208, 'basement_size': 0.0, 'rooms': 0.041159889746165856, 'year_built': 0.0038594328984858234, 'year_rebuilt': 0.003710250746033922, 'energy_label': 0.0031991974854515643}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.6202693512057609, 'MAE': 1259895.8418233586, 'Percentage Error': 30.334324922911918, 'MSE': 4405054903538.699}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.8228580817555349, 'lattitude': 0.006343925500361719, 'longitude': 0.0075764932806826465, 'postal_code': 0.009048654118731516, 'type': 0.0, 'postal_avg_sqm_price': 0.0, 'size': 0.10224407446855208, 'basement_size': 0.0, 'rooms': 0.041159889746165856, 'year_built': 0.0038594328984858234, 'year_rebuilt': 0.003710250746033922, 'energy_label': 0.0031991974854515643}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import N_CNN_RF_model\n",
    "from keras.applications import MobileNetV3Small\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "FUNCTION: object = N_CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    2,\n",
    "    MobileNetV3Small,\n",
    "    np.concatenate((train1_images, train2_images), axis=0),\n",
    "    pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "    np.concatenate((train1_prices, train2_prices), axis=0),\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
