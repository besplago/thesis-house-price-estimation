{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:13:46.638733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-08 15:13:46.638821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-08 15:13:46.640210: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-08 15:13:46.652582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 15:13:48.648925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, MobileNetV3Small, DenseNet201\n",
    "\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ../nybolig-scrape/output/train/train_1: 100%|██████████| 311/311 [00:00<00:00, 1462363.84it/s]\n",
      "Processing ../nybolig-scrape/output/train/train_2: 100%|██████████| 312/312 [00:00<00:00, 1641935.82it/s]\n",
      "Processing ../nybolig-scrape/output/valid: 100%|██████████| 89/89 [00:00<00:00, 789203.08it/s]\n",
      "Processing ../nybolig-scrape/output/test: 100%|██████████| 178/178 [00:00<00:00, 1287217.43it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 186.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing outliers...\n",
      "Datapoints before: 829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing outliers: 100%|██████████| 4/4 [00:00<00:00, 543.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoints after: 813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>image_floorplan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1945000</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>5</td>\n",
       "      <td>33273.25</td>\n",
       "      <td>56.575356</td>\n",
       "      <td>8.205598</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2725000</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33507.50</td>\n",
       "      <td>55.696548</td>\n",
       "      <td>12.500334</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3195000</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>5</td>\n",
       "      <td>51502.50</td>\n",
       "      <td>55.691847</td>\n",
       "      <td>12.559937</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3550000</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44946.75</td>\n",
       "      <td>55.658402</td>\n",
       "      <td>12.594399</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>5295000</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44946.75</td>\n",
       "      <td>55.658402</td>\n",
       "      <td>12.594399</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type    price  size  basement_size  rooms  year_built  \\\n",
       "0           46     0  1945000    70              0    2.0      1968.0   \n",
       "1           54     0  2725000    66              0    3.0      1934.0   \n",
       "2           39     0  3195000    51              0    2.0      1886.0   \n",
       "4           40     0  3550000    74              0    3.0      2018.0   \n",
       "5           40     0  5295000   120              0    4.0      2018.0   \n",
       "\n",
       "   year_rebuilt  energy_label  postal_avg_sqm_price        lat        lng  \\\n",
       "0        1968.0             5              33273.25  56.575356   8.205598   \n",
       "1        1934.0             4              33507.50  55.696548  12.500334   \n",
       "2        1886.0             5              51502.50  55.691847  12.559937   \n",
       "4        2018.0             1              44946.75  55.658402  12.594399   \n",
       "5        2018.0             1              44946.75  55.658402  12.594399   \n",
       "\n",
       "                                     image_floorplan  \n",
       "0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "1  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "2  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "4  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "5  [[[255, 255, 255], [255, 255, 255], [255, 255,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of datasets:\n",
      "Train 1: 284\n",
      "Train 2: 286\n",
      "Valid: 83\n",
      "Test: 160\n",
      "Total: 813\n"
     ]
    }
   ],
   "source": [
    "IMAGE_WIDTH: int = 448\n",
    "IMAGE_HEIGHT: int = 448\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"../nybolig-scrape/output/train/train_1\"\n",
    "train_2_path: str = \"../nybolig-scrape/output/train/train_2\"\n",
    "valid_path: str = \"../nybolig-scrape/output/valid\"\n",
    "test_path: str = \"../nybolig-scrape/output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True, rm_outliers=True\n",
    ")\n",
    "\n",
    "display(train1_df.head())\n",
    "print(\"Length of datasets:\")\n",
    "print(f\"Train 1: {len(train1_df)}\")\n",
    "print(f\"Train 2: {len(train2_df)}\")\n",
    "print(f\"Valid: {len(valid_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "print(f\"Total: {len(train1_df) + len(train2_df) + len(valid_df) + len(test_df)}\")\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values\n",
    "\n",
    "\n",
    "# Apparently the feature column order is not consistent between the datasets, so the \n",
    "# following code is needed to ensure that the columns are in the same order\n",
    "train2_features = train2_features[train1_features.columns]\n",
    "valid_features = valid_features[train1_features.columns]\n",
    "test_features = test_features[train1_features.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        # Save Model Architecture\n",
    "        img = plot_model(model, to_file=f\"{model_dir}/architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "        print(f\"Before sorting: {feature_importance}\")\n",
    "        feature_importance = {\n",
    "            k: v\n",
    "            for k, v in sorted(\n",
    "                feature_importance.items(), key=lambda item: item[1], reverse=True\n",
    "            )\n",
    "        }\n",
    "        print(f\"After sorting: {feature_importance}\")\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "\n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "\n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "\n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "    if model_type == 'CNN_AE_RF':\n",
    "        print(\"\\nSaving Reconstructions\")\n",
    "        save_reconstuctions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    \n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# TYPE = \"RF\"\n",
    "# MODEL_NAME: str = \"RF\"\n",
    "# FUNCTION: object = RF\n",
    "# ARGS: tuple = (\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "\n",
    "\n",
    "# CNN\n",
    "# TYPE = \"CNN\"\n",
    "# MODEL_NAME: str = \"MobileNetV2\"\n",
    "# FUNCTION: object = CNN_model\n",
    "# ARGS: tuple = (\n",
    "#     MobileNetV2,\n",
    "#     train1_images,\n",
    "#     train1_prices,\n",
    "#     valid_images,\n",
    "#     valid_prices,\n",
    "#     [\n",
    "#         Flatten(),\n",
    "#         Dense(512, activation=\"relu\"),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(256, activation=\"relu\"),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(128, activation=\"relu\"),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(1),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "\n",
    "# CNN + Random Forest\n",
    "# TYPE = \"CNN_RF\"\n",
    "# MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "# FUNCTION: object = CNN_RF_model\n",
    "# ARGS: tuple = (\n",
    "#     f\"{MODELS_PATH}/MobileNetV2/model\",\n",
    "#     train2_images,\n",
    "#     train2_features,\n",
    "#     train2_prices,\n",
    "# )\n",
    "\n",
    "\n",
    "# CNN + Autoencoder + Random Forest\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"VGG16_AE_RF\"\n",
    "# MODEL_NAME: str = \"EfficientNetB3_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    f\"{MODELS_PATH}/VGG16/model\",\n",
    "    # f\"{MODELS_PATH}/EfficientNetB3/model\",\n",
    "    None,\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:20:37.653181: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.692801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.693047: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.699768: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.699969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.700053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:20:37.926639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.926866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.926892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-08 15:20:37.926967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-08 15:20:37.927018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:20:47.434071: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-05-08 15:20:47.685134: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-08 15:20:49.008994: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-08 15:20:53.510857: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f1d2058e160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-08 15:20:53.510908: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-05-08 15:20:53.516127: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715174453.589742  166737 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 32s 2s/step - loss: 53630.2461\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 43506.6172\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 19462.1992\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 9011.5908\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 5355.2324\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 4089.6240\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 3626.8977\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 3392.0200\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 3244.8074\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 3161.6426\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 3106.0044\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 3057.6914\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 3027.4761\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 3000.3540\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 4s 424ms/step - loss: 2977.1499\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 4s 424ms/step - loss: 2958.5422\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 2942.3130\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 2927.2222\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 2916.7378\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 2900.2903\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 4s 424ms/step - loss: 2890.7134\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 2876.2637\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 2863.6177\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 2851.9387\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 4s 422ms/step - loss: 2841.5378\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 2834.6980\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 2819.1216\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 4s 423ms/step - loss: 2802.3787\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 2784.8184\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 4s 421ms/step - loss: 2757.9065\n",
      "9/9 [==============================] - 1s 60ms/step\n",
      "9/9 [==============================] - 1s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:23:08.958657: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 688816128 exceeds 10% of free system memory.\n",
      "2024-05-08 15:23:27.536744: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.62GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:28.355897: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.62GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:28.600507: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:28.600565: W tensorflow/core/kernels/gpu_utils.cc:54] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2024-05-08 15:23:33.179081: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:33.829912: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:33.829986: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:34.032938: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:34.680859: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:34.680925: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-05-08 15:23:34.949474: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 44s 3s/step\n",
      "Saving Model...\n",
      "5/5 [==============================] - 0s 103ms/step\n",
      "5/5 [==============================] - 0s 82ms/step\n",
      "5/5 [==============================] - 1s 354ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model...\n",
      "Before sorting: {'image_predictions': 0.03689113823055403, 'reconstruction_error': 0.02507884655387852, 'postal_code': 0.06357794652775754, 'type': 0.0, 'size': 0.6342430786977415, 'basement_size': 0.0, 'rooms': 0.0069665290381536625, 'year_built': 0.029392211274597308, 'year_rebuilt': 0.045119314430167236, 'energy_label': 0.007194854445207026, 'postal_avg_sqm_price': 0.11540237621445673, 'lat': 0.016150496244513854, 'lng': 0.019983208342972646}\n",
      "After sorting: {'size': 0.6342430786977415, 'postal_avg_sqm_price': 0.11540237621445673, 'postal_code': 0.06357794652775754, 'year_rebuilt': 0.045119314430167236, 'image_predictions': 0.03689113823055403, 'year_built': 0.029392211274597308, 'reconstruction_error': 0.02507884655387852, 'lng': 0.019983208342972646, 'lat': 0.016150496244513854, 'energy_label': 0.007194854445207026, 'rooms': 0.0069665290381536625, 'type': 0.0, 'basement_size': 0.0}\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-05-08 15:24:29.402137', 'R2': 0.7886327593197248, 'MAE': 674487.0625, 'Percentage Error': 15.978583028682248, 'MSE': 1019397067126.875, 'Feature Importances': {'size': 0.6342430786977415, 'postal_avg_sqm_price': 0.11540237621445673, 'postal_code': 0.06357794652775754, 'year_rebuilt': 0.045119314430167236, 'image_predictions': 0.03689113823055403, 'year_built': 0.029392211274597308, 'reconstruction_error': 0.02507884655387852, 'lng': 0.019983208342972646, 'lat': 0.016150496244513854, 'energy_label': 0.007194854445207026, 'rooms': 0.0069665290381536625, 'type': 0.0, 'basement_size': 0.0}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8029669604096588, 'MAE': 665286.125, 'Percentage Error': 15.684412622592777, 'MSE': 950265055450.625}\n",
      "Feauter Importance...\n",
      "{'size': 0.6342430786977415, 'postal_avg_sqm_price': 0.11540237621445673, 'postal_code': 0.06357794652775754, 'year_rebuilt': 0.045119314430167236, 'image_predictions': 0.03689113823055403, 'year_built': 0.029392211274597308, 'reconstruction_error': 0.02507884655387852, 'lng': 0.019983208342972646, 'lat': 0.016150496244513854, 'energy_label': 0.007194854445207026, 'rooms': 0.0069665290381536625, 'type': 0.0, 'basement_size': 0.0}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "N = 2\n",
    "\n",
    "for i in range(N):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Run {i + 1}/{N}\")\n",
    "    p = Process(\n",
    "        target=train_save_model,\n",
    "        args=(\n",
    "            FUNCTION,\n",
    "            ARGS,\n",
    "            test_images,\n",
    "            test_features,\n",
    "            test_prices,\n",
    "            f\"{MODELS_PATH}/{MODEL_NAME}\",\n",
    "            USE_GPU,\n",
    "            TYPE,\n",
    "        ),\n",
    "    )\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "print(\"All Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
