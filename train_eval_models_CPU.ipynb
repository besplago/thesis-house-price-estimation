{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 07:39:04.809017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "from multiprocess import Process\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, MobileNetV3Small\n",
    "\n",
    "from models import *\n",
    "from utils import regression_stats\n",
    "from img_utils import data_to_df, preprocess_images, set_gpu, set_cpu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing output/train/train_1: 100%|██████████| 311/311 [00:00<00:00, 462071.75it/s]\n",
      "Processing output/train/train_2: 100%|██████████| 312/312 [00:00<00:00, 569213.94it/s]\n",
      "Processing output/valid: 100%|██████████| 89/89 [00:00<00:00, 352828.98it/s]\n",
      "Processing output/test: 100%|██████████| 178/178 [00:00<00:00, 511710.84it/s]\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 37.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>image_floorplan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1750000</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32687.50</td>\n",
       "      <td>55.736966</td>\n",
       "      <td>12.513117</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>8500000</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>4</td>\n",
       "      <td>55737.75</td>\n",
       "      <td>55.698085</td>\n",
       "      <td>12.594470</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>13495000</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>5</td>\n",
       "      <td>55737.75</td>\n",
       "      <td>55.693852</td>\n",
       "      <td>12.587047</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>5995000</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4</td>\n",
       "      <td>44946.75</td>\n",
       "      <td>55.654361</td>\n",
       "      <td>12.601795</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4495000</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50502.00</td>\n",
       "      <td>55.691502</td>\n",
       "      <td>12.529448</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type     price  size  basement_size  rooms  year_built  \\\n",
       "0           64     0   1750000    40              0    2.0      1944.0   \n",
       "1           37     0   8500000   138              0    4.0      2005.0   \n",
       "2           37     0  13495000   176              0    5.0      1907.0   \n",
       "3           40     0   5995000   139              0    5.0      1935.0   \n",
       "4           36     0   4495000    76              0    3.0      1932.0   \n",
       "\n",
       "   year_rebuilt  energy_label  postal_avg_sqm_price        lat        lng  \\\n",
       "0        1944.0             4              32687.50  55.736966  12.513117   \n",
       "1        2005.0             4              55737.75  55.698085  12.594470   \n",
       "2        1907.0             5              55737.75  55.693852  12.587047   \n",
       "3        2009.0             4              44946.75  55.654361  12.601795   \n",
       "4        1932.0             4              50502.00  55.691502  12.529448   \n",
       "\n",
       "                                     image_floorplan  \n",
       "0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "1  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "2  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "3  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "4  [[[255, 255, 255], [255, 255, 255], [255, 255,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of datasets:\n",
      "Train 1: 292\n",
      "Train 2: 290\n",
      "Valid: 84\n",
      "Test: 163\n"
     ]
    }
   ],
   "source": [
    "from img_utils import data_to_df\n",
    "#try reloading the module\n",
    "IMAGE_WIDTH: int = 224\n",
    "IMAGE_HEIGHT: int = 224\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_1_path: str = \"output/train/train_1\"\n",
    "train_2_path: str = \"output/train/train_2\"\n",
    "valid_path: str = \"output/valid\"\n",
    "test_path: str = \"output/test\"\n",
    "\n",
    "# train_1_path: str = \"output/train/train_1\"\n",
    "# train_2_path: str = \"output/train/train_2\"\n",
    "# valid_path: str = \"output/valid\"\n",
    "# test_path: str = \"output/test\"\n",
    "\n",
    "train1_df, train2_df, valid_df, test_df = data_to_df(\n",
    "    [train_1_path, train_2_path, valid_path, test_path], preprocess=True\n",
    ")\n",
    "\n",
    "display(train1_df.head())\n",
    "# Print the lenghts of the datasets\n",
    "print(\"Length of datasets:\")\n",
    "print(f\"Train 1: {len(train1_df)}\")\n",
    "print(f\"Train 2: {len(train2_df)}\")\n",
    "print(f\"Valid: {len(valid_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "\n",
    "# TODO: Would be better with this format\n",
    "# train_images: np.array = preprocess_images(\n",
    "#     train1_df[\"image_floorplan\"], IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    "# )\n",
    "\n",
    "\n",
    "#### Train Set 1 ####\n",
    "train1_features = train1_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train1_images: np.array = preprocess_images(\n",
    "    train1_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train1_prices: np.array = train1_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Train Set 2 ####\n",
    "train2_features = train2_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "train2_images: np.array = preprocess_images(\n",
    "    train2_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "train2_prices: np.array = train2_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Validation Set ####\n",
    "valid_features = valid_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "valid_images: np.array = preprocess_images(\n",
    "    valid_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "valid_prices: np.array = valid_df[\"price\"].values\n",
    "\n",
    "\n",
    "#### Test Set ####\n",
    "test_features = test_df.drop(columns=[\"image_floorplan\", \"price\"])\n",
    "test_images: np.array = preprocess_images(\n",
    "    test_df, \"image_floorplan\", IMAGE_WIDTH, IMAGE_HEIGHT, True, False, False\n",
    ")\n",
    "test_prices: np.array = test_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_expected_predicted(test_prices, test_predictions, img_dir):\n",
    "        #Set X and Y axis to [0, 9.000.000]\n",
    "    #plt.xlim(0, 9999999)\n",
    "    #plt.ylim(0, 9999999)\n",
    "    plt.scatter(test_prices, test_predictions)\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(\"Expected vs Predicted Price\")\n",
    "    try: \n",
    "        plt.plot([min(test_prices), max(test_prices)], [min(test_prices), max(test_prices)], color='red')\n",
    "    except:\n",
    "        pass\n",
    "    plt.savefig(f\"{img_dir}/expected_vs_predicted.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_residuals(test_prices, test_predictions, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    plt.scatter(test_predictions, residuals)\n",
    "    try:\n",
    "        plt.hlines(y=0, xmin=test_prices.min(), xmax=test_prices.max(), colors=\"r\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel(\"Expected Price\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.savefig(f\"{img_dir}/residuals.png\")\n",
    "    plt.close()\n",
    "\n",
    "def get_saliency_map(model, image):\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "    gradients = tape.gradient(prediction, image)\n",
    "    gradients = tf.squeeze(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy()\n",
    "    gradients = (gradients - np.min(gradients)) / (np.max(gradients) - np.min(gradients))\n",
    "    return gradients\n",
    "\n",
    "def save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir):\n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    test_images = np.array(test_images)\n",
    "    for i, idx in enumerate(worst_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/worst_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    for i, idx in enumerate(best_predictions):\n",
    "        image = test_images[idx]\n",
    "        price = test_prices[idx]\n",
    "        prediction = test_predictions[idx]\n",
    "        residual = residuals[idx]\n",
    "        plt.imshow(image)\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {prediction}\",\n",
    "            f\"Residual: {residual}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_{i}.png\")\n",
    "        plt.close()\n",
    "        saliency_map = get_saliency_map(model, image)\n",
    "        plt.imshow(saliency_map, cmap=\"hot\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"{img_dir}/best_saliency_map_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_features_importance(feature_importance, img_dir):\n",
    "    #sort the feature_importance dict by value\n",
    "    feature_importance = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #add percentages to the bars\n",
    "    plt.bar(feature_importance.keys(), feature_importance.values())\n",
    "    #plt.bar_label = feature_importance.values()\n",
    "    plt.title('Feature Importance')\n",
    "    #Remove y-labels\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(rotation=90)\n",
    "    #Zoom out so that text is visible \n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.savefig(f\"{img_dir}/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_worst_best(test_predictions, test_prices, test_features, model_dir):\n",
    "    #Find the best predictions, and worst predictions. \n",
    "    #Save them in two dataframes. Save a latex of the dataframe in a txt-file \n",
    "    residuals = test_prices - test_predictions.reshape(-1)\n",
    "    distances = np.abs(test_prices - test_predictions.reshape(-1))\n",
    "    worst_predictions = np.argsort(distances)[-8:]\n",
    "    best_predictions = np.argsort(distances)[:8]\n",
    "    \n",
    "    test_features_ = pd.DataFrame(test_features).copy()\n",
    "    test_features_[\"Price\"] = test_prices\n",
    "    test_features_[\"Predicted Price\"] = test_predictions\n",
    "    test_features_[\"Residual\"] = residuals\n",
    "    test_features_['Absolute Distances'] = distances\n",
    "    test_features_ = test_features_.sort_values(by=\"Absolute Distances\", ascending=False)\n",
    "    worst_df = test_features_.head(8)\n",
    "    best_df = test_features_.tail(8)\n",
    "    #save worst and best as latex in txt-file \n",
    "    worst_df.to_latex(f\"{model_dir}/worst_predictions.txt\")\n",
    "    best_df.to_latex(f\"{model_dir}/best_predictions.txt\")\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "def save_reconstuctions(AE, test_predictions, test_prices, test_images, model_dir):\n",
    "    n = 10\n",
    "    reconstruction_errors = AE.calculate_ssim(test_images)\n",
    "    best5 = np.argsort(reconstruction_errors)[:n]\n",
    "    worst5 = np.argsort(reconstruction_errors)[::-1][:n]\n",
    "    print(best5)\n",
    "    print(worst5)\n",
    "    for i in range(n):\n",
    "        idx = best5[i]\n",
    "        image = test_images[idx]\n",
    "        encoded_img = AE.encode(np.expand_dims(image, axis=0))\n",
    "        decoded_img = AE.decode(encoded_img)\n",
    "        encoded_img = np.squeeze(encoded_img)\n",
    "        decoded_img = np.squeeze(decoded_img)\n",
    "        #Turn decoded_img into intergers\n",
    "        decoded_img = decoded_img.astype(int)\n",
    "        fix, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[1].imshow(decoded_img)\n",
    "        ax[1].set_title(\"Reconstructed Image\")\n",
    "        #Set overall title as the price vs. the predicted price\n",
    "        price = test_prices[idx]\n",
    "        predicted_price = test_predictions[idx]\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {predicted_price}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.savefig(f\"{model_dir}/best_reconstruction_{i}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    for i in range(n):\n",
    "        idx = worst5[i]\n",
    "        image = test_images[idx]\n",
    "        encoded_img = AE.encode(np.expand_dims(image, axis=0))\n",
    "        decoded_img = AE.decode(encoded_img)\n",
    "        encoded_img = np.squeeze(encoded_img)\n",
    "        decoded_img = np.squeeze(decoded_img)\n",
    "        #Turn decoded_img into intergers\n",
    "        decoded_img = decoded_img.astype(int)\n",
    "        fix, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[1].imshow(decoded_img)\n",
    "        ax[1].set_title(\"Reconstructed Image\")\n",
    "        price = test_prices[idx]\n",
    "        predicted_price = test_predictions[idx]\n",
    "        textstr = '\\n'.join((\n",
    "            f\"Price: {price}\",\n",
    "            f\"Predicted Price: {predicted_price}\"\n",
    "        ))\n",
    "        plt.text(0.01, 0.99, textstr, fontsize=10, transform=plt.gcf().transFigure, verticalalignment='top')\n",
    "        plt.savefig(f\"{model_dir}/worst_reconstruction_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def save_model_and_evaluate(\n",
    "    model: object,\n",
    "    fit_history: object,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    model_type:str\n",
    "):\n",
    "    if model_type == 'RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_features)\n",
    "    \n",
    "    if model_type == \"CNN\":\n",
    "        # Save Model\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model.save(f\"{model_dir}/model\")\n",
    "        # Save Training History\n",
    "        with open(f\"{model_dir}/history\", \"wb\") as file_pi:\n",
    "            pickle.dump(fit_history.history, file_pi)\n",
    "        test_predictions = model.predict(test_images)\n",
    "        #Save Model Architecture\n",
    "        #plot_model(model, to_file=f\"{model_dir}/model_architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "        img = plot_model(model, to_file=f\"{model_dir}/architecture.png\", show_shapes=True, show_layer_names=True, show_dtype=True, rankdir=\"TB\", expand_nested=False, dpi=96)\n",
    "\n",
    "\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        print(\"Saving Model...\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        with open(f\"{model_dir}/model\", \"wb\") as file_pi:\n",
    "            pickle.dump(model, file_pi)\n",
    "        test_predictions = model.predict(test_images, test_features)\n",
    "        \n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"Evaluating Model...\")\n",
    "    r2, mae, percentage_error, mse = regression_stats(test_prices, test_predictions)\n",
    "\n",
    "    try:\n",
    "        feature_importance = model.feature_importances_\n",
    "        if model_type == \"RF\":\n",
    "            feature_importance = dict(zip(test_features.columns, feature_importance))\n",
    "    except AttributeError:\n",
    "        print(\"Cant find feature_importance\")\n",
    "        feature_importance = None\n",
    "\n",
    "    # Load existing evaluation data\n",
    "    evaluation_file_path = f\"{model_dir}/evaluation.json\"\n",
    "    evaluation_data = {}\n",
    "    if os.path.exists(evaluation_file_path):\n",
    "        with open(evaluation_file_path, \"r\") as json_file:\n",
    "            evaluation_data = json.load(json_file)\n",
    "\n",
    "    # Add new evaluation data\n",
    "    new_evaluation = {\n",
    "        \"Timestamp\": str(datetime.datetime.now()),\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"Percentage Error\": percentage_error,\n",
    "        \"MSE\": mse,\n",
    "        \"Feature Importances\": (feature_importance),\n",
    "    }\n",
    "    evaluation_data[len(evaluation_data)] = new_evaluation\n",
    "\n",
    "    # Save updated evaluation data\n",
    "    with open(evaluation_file_path, \"w\") as json_file:\n",
    "        json.dump(evaluation_data, json_file, indent=4)\n",
    "\n",
    "    # Compute median evaluation values from all instances\n",
    "    r2_values = [evaluation_data[key][\"R2\"] for key in evaluation_data]\n",
    "    mae_values = [evaluation_data[key][\"MAE\"] for key in evaluation_data]\n",
    "    percentage_error_values = [\n",
    "        evaluation_data[key][\"Percentage Error\"] for key in evaluation_data\n",
    "    ]\n",
    "    mse_values = [evaluation_data[key][\"MSE\"] for key in evaluation_data]\n",
    "\n",
    "    median_evaluation_data = {\n",
    "        \"R2\": np.median(r2_values),\n",
    "        \"MAE\": np.median(mae_values),\n",
    "        \"Percentage Error\": np.median(percentage_error_values),\n",
    "        \"MSE\": np.median(mse_values),\n",
    "    }\n",
    "\n",
    "    with open(f\"{model_dir}/median_evaluation.json\", \"w\") as json_file:\n",
    "        json.dump(median_evaluation_data, json_file, indent=4)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(new_evaluation)\n",
    "    print(\"\\nMedian Evaluation:\")\n",
    "    print(median_evaluation_data)\n",
    "    print(\"Feauter Importance...\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Images (Create or open existing folder)\n",
    "    if not os.path.exists(f\"{model_dir}/images\"):\n",
    "        os.makedirs(f\"{model_dir}/images\")\n",
    "    img_dir = f\"{model_dir}/images\"\n",
    "    \n",
    "    save_expected_predicted(test_prices, test_predictions, img_dir)\n",
    "    save_residuals(test_prices, test_predictions, img_dir)\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        print(\"\\nSaving Best and Worst Image Predictions\")\n",
    "        save_worst_best_predictions(model, test_predictions, test_prices, test_images, img_dir)\n",
    "    \n",
    "    if model_type != 'CNN': \n",
    "        print(\"\\nSaving Feature Importance\")\n",
    "        save_features_importance(feature_importance, img_dir)\n",
    "\n",
    "    if model_type == 'CNN_AE_RF':\n",
    "        print(\"\\nSaving Reconstructions\")\n",
    "        save_reconstuctions(model.autoEncoder_, test_predictions, test_prices, test_images, img_dir)\n",
    "\n",
    "    save_worst_best(test_predictions, test_prices, test_features, model_dir)\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "def train_save_model(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_features: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "    model_type:str\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    if model_type == \"CNN\":\n",
    "        model, fit_history = model_func(*args)\n",
    "    if model_type == 'RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    if model_type == 'CNN_RF' or model_type == 'CNN_AE_RF':\n",
    "        model = model_func(*args)\n",
    "        fit_history = None\n",
    "    save_model_and_evaluate(model, fit_history, test_images, test_features, test_prices, model_dir, model_type)\n",
    "\n",
    "\n",
    "def train_save_models(\n",
    "    model_func: object,\n",
    "    args: tuple,\n",
    "    test_images: np.array,\n",
    "    test_prices: np.array,\n",
    "    model_dir: str,\n",
    "    use_gpu: bool,\n",
    "):\n",
    "    if use_gpu:\n",
    "        set_gpu()\n",
    "    else:\n",
    "        set_cpu()\n",
    "\n",
    "    models, fit_histories = model_func(*args)\n",
    "    for model_idx, (model, fit_history) in enumerate(zip(models, fit_histories)):\n",
    "        save_model_and_evaluate(\n",
    "            model, fit_history, test_images, test_prices, f\"{model_dir}_{model_idx}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH: str = \"./models\"\n",
    "USE_GPU: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set postal_av_sqm_price as the last column \n",
    "train2_features = train2_features[['postal_code', 'type', 'size', 'basement_size', 'rooms', 'year_built','year_rebuilt', 'energy_label', 'postal_avg_sqm_price', 'lat', 'lng' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.545454</td>\n",
       "      <td>12.234008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           49     0   111              0    3.0      2020.0        2020.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             0                   0.0  55.545454  12.234008  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32687.5</td>\n",
       "      <td>55.736966</td>\n",
       "      <td>12.513117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           64     0    40              0    2.0      1944.0        1944.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             4               32687.5  55.736966  12.513117  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>basement_size</th>\n",
       "      <th>rooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_rebuilt</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>postal_avg_sqm_price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>4</td>\n",
       "      <td>57450.25</td>\n",
       "      <td>55.667935</td>\n",
       "      <td>12.547432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postal_code  type  size  basement_size  rooms  year_built  year_rebuilt  \\\n",
       "0           12     0    56              0    2.0        1897        1897.0   \n",
       "\n",
       "   energy_label  postal_avg_sqm_price        lat        lng  \n",
       "0             4              57450.25  55.667935  12.547432  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train2_features.head(1))\n",
    "display(train1_features.head(1))\n",
    "display(test_features.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "Saving Model...\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-30 07:40:55.466485', 'R2': 0.8443016550932964, 'MAE': 652490.8588957055, 'Percentage Error': 14.57778872142314, 'MSE': 1010007370065.6442, 'Feature Importances': {'postal_code': 0.046806393235473774, 'type': 0.0, 'size': 0.7396949007138165, 'basement_size': 0.0, 'rooms': 0.010049919376703194, 'year_built': 0.02538667049740317, 'year_rebuilt': 0.03623272120740501, 'energy_label': 0.013073504497568486, 'postal_avg_sqm_price': 0.07807195163271148, 'lat': 0.016639173988125255, 'lng': 0.034044764850793205}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8303841292303515, 'MAE': 992721.2216782337, 'Percentage Error': 27.43139309991981, 'MSE': 1967624224234.4958}\n",
      "Feauter Importance...\n",
      "{'postal_code': 0.046806393235473774, 'type': 0.0, 'size': 0.7396949007138165, 'basement_size': 0.0, 'rooms': 0.010049919376703194, 'year_built': 0.02538667049740317, 'year_rebuilt': 0.03623272120740501, 'energy_label': 0.013073504497568486, 'postal_avg_sqm_price': 0.07807195163271148, 'lat': 0.016639173988125255, 'lng': 0.034044764850793205}\n",
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import RF\n",
    "TYPE = \"RF\"\n",
    "MODEL_NAME: str = \"RF\"\n",
    "FUNCTION: object = RF\n",
    "ARGS: tuple = (\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNN_model1\n",
    "TYPE = 'CNN'\n",
    "MODEL_NAME: str = \"MobileNetV3_Small_1\"\n",
    "FUNCTION: object = CNN_model1\n",
    "ARGS: tuple = (\n",
    "    MobileNetV3Small,\n",
    "    train1_images,\n",
    "    train1_prices,\n",
    "    valid_images,\n",
    "    valid_prices,\n",
    "    [\n",
    "    #Type 1\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l1(0.2)),\n",
    "    # BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l1(0.1)),\n",
    "    layers.Dropout(0.1),\n",
    "    Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1(0.1)),\n",
    "    layers.Dropout(0.1),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\"),\n",
    "    ],\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features, test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "10/10 [==============================] - 3s 309ms/step\n",
      "Saving Model...\n",
      "6/6 [==============================] - 2s 333ms/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-30 08:56:52.974259', 'R2': 0.8544921508959845, 'MAE': 656923.5582822086, 'Percentage Error': 14.830990102535429, 'MSE': 943902133869.9386, 'Feature Importances': {'image_predictions': 0.015636355668632005, 'postal_code': 0.043718193072296706, 'type': 0.0, 'size': 0.7359901207398921, 'basement_size': 0.0, 'rooms': 0.00805295724476705, 'year_built': 0.03273396136580977, 'year_rebuilt': 0.02477864542461593, 'energy_label': 0.018258429424106534, 'postal_avg_sqm_price': 0.07480951252204446, 'lat': 0.019344562045315837, 'lng': 0.02667726249251954}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8329630754490587, 'MAE': 981157.2788288998, 'Percentage Error': 27.45060372348743, 'MSE': 1937707229852.4219}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.015636355668632005, 'postal_code': 0.043718193072296706, 'type': 0.0, 'size': 0.7359901207398921, 'basement_size': 0.0, 'rooms': 0.00805295724476705, 'year_built': 0.03273396136580977, 'year_rebuilt': 0.02477864542461593, 'energy_label': 0.018258429424106534, 'postal_avg_sqm_price': 0.07480951252204446, 'lat': 0.019344562045315837, 'lng': 0.02667726249251954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_RF_model\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_RF\"\n",
    "FUNCTION: object = CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, # keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN_AE_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 29s 2s/step - loss: 36431.5156\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 7774.5869\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 4197.3462\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 3504.4885\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 3235.6106\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 3044.7822\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2958.7922\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2904.7471\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2831.4070\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2768.6167\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2698.8691\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2640.1726\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2630.2234\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2603.9290\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2601.5164\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2584.9990\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 2542.9639\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2494.3584\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2425.8855\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2398.9233\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2371.4294\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2322.7261\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2298.1289\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 25s 2s/step - loss: 2287.9666\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 2246.9517\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 2280.0842\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 2232.7454\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 26s 3s/step - loss: 2234.3120\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 25s 3s/step - loss: 2188.5427\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 23s 2s/step - loss: 2188.8918\n"
     ]
    }
   ],
   "source": [
    "from models import autoEncoder\n",
    "AE = autoEncoder(train2_images, latent_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU\n",
      "10/10 [==============================] - 5s 495ms/step\n",
      "10/10 [==============================] - 5s 490ms/step\n",
      "10/10 [==============================] - 4s 347ms/step\n",
      "Saving Model...\n",
      "6/6 [==============================] - 3s 415ms/step\n",
      "6/6 [==============================] - 3s 459ms/step\n",
      "6/6 [==============================] - 2s 337ms/step\n",
      "Evaluating Model...\n",
      "\n",
      "Model Evaluation:\n",
      "{'Timestamp': '2024-04-30 09:12:16.515559', 'R2': 0.8487168225509731, 'MAE': 667752.2085889571, 'Percentage Error': 15.332724598655286, 'MSE': 981366399765.0306, 'Feature Importances': {'image_predictions': 0.012469668380009177, 'reconstruction_error': 0.017205214861906053, 'postal_code': 0.04139172099648684, 'type': 0.0, 'size': 0.7347626649593174, 'basement_size': 0.0, 'rooms': 0.005898332643423903, 'year_built': 0.03389545760217403, 'year_rebuilt': 0.023105984610404806, 'energy_label': 0.014480188279061475, 'postal_avg_sqm_price': 0.07435613766932983, 'lat': 0.015460870634686649, 'lng': 0.026973759363199953}}\n",
      "\n",
      "Median Evaluation:\n",
      "{'R2': 0.8283218744225571, 'MAE': 890553.6065378301, 'Percentage Error': 21.67496515639211, 'MSE': 1494262171665.9766}\n",
      "Feauter Importance...\n",
      "{'image_predictions': 0.012469668380009177, 'reconstruction_error': 0.017205214861906053, 'postal_code': 0.04139172099648684, 'type': 0.0, 'size': 0.7347626649593174, 'basement_size': 0.0, 'rooms': 0.005898332643423903, 'year_built': 0.03389545760217403, 'year_rebuilt': 0.023105984610404806, 'energy_label': 0.014480188279061475, 'postal_avg_sqm_price': 0.07435613766932983, 'lat': 0.015460870634686649, 'lng': 0.026973759363199953}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Feature Importance\n",
      "\n",
      "Saving Reconstructions\n",
      "6/6 [==============================] - 3s 566ms/step\n",
      "6/6 [==============================] - 3s 457ms/step\n",
      "[ 67 120 153  25 124  96  49  18  29  78]\n",
      "[ 51  21 146  99  16 119 150  85 107  65]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from models import CNN_AE_RF_model\n",
    "#img_model =  keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "TYPE = 'CNN_AE_RF'\n",
    "MODEL_NAME: str = \"MobileNetV2_AE_RF\"\n",
    "FUNCTION: object = CNN_AE_RF_model\n",
    "ARGS: tuple = (\n",
    "    img_model, #keras.models.load_model(f\"{MODELS_PATH}/MobileNetV2/model\")\n",
    "    AE, #Or none for training it from scratch\n",
    "    train2_images,\n",
    "    train2_features,\n",
    "    train2_prices,\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import N_CNN_RF_model\n",
    "from keras.applications import MobileNetV3Small\n",
    "TYPE = 'CNN_RF'\n",
    "MODEL_NAME: str = \"N_CNN_MobileNetV2_RF\"\n",
    "FUNCTION: object = N_CNN_RF_model\n",
    "ARGS: tuple = (\n",
    "    4,\n",
    "    MobileNetV3Small,\n",
    "    np.concatenate((train1_images, train2_images), axis=0),\n",
    "    pd.concat((train1_features, train2_features), axis=0),\n",
    "\n",
    "    np.concatenate((train1_prices, train2_prices), axis=0),\n",
    ")\n",
    "train_save_model(FUNCTION, ARGS, test_images, test_features,  test_prices, f\"{MODELS_PATH}/{MODEL_NAME}\", USE_GPU, TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- decoded_images = AE.decode(AE.encode(test_images))\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "img_shape = train2_images.shape\n",
    "print(img_shape)\n",
    "def recon_err1(images, encoded_images):\n",
    "  return tf.square(images - encoded_images)\n",
    "\n",
    "def recon_err2(images, encoded_images): \n",
    "  return tf.reduce_mean(tf.square(images - encoded_images), axis=(1,2,3))\n",
    "\n",
    "def recon_err3(images, encoded_images):\n",
    "  normalized_images = images / 255.0\n",
    "  normalized_encoded_images = encoded_images / 255.0 \n",
    "  def calc_ssim(normalized_img, normalized_encoded_img):\n",
    "    return ssim(normalized_img, normalized_encoded_img, channel_axis=2, data_range=1)\n",
    "  return [calc_ssim(img, encoded_img) for img, encoded_img in zip(normalized_images, normalized_encoded_images)]\n",
    "\n",
    "#recon1 = recon_err1(test_images, decoded_images)\n",
    "#recon2 = recon_err2(test_images, decoded_images)\n",
    "recon3 = recon_err3(test_images, decoded_images)\n",
    "print(recon3)\n",
    "reconstructions_errors = recon3\n",
    "\n",
    "#Get the reconstructions of the best and worst predictions\n",
    "n = 10\n",
    "best5 = np.argsort(reconstructions_errors)[:n]\n",
    "worst5 = np.argsort(reconstructions_errors)[::-1][:n]\n",
    "print(best5)\n",
    "print(worst5)\n",
    "for i in range(n):\n",
    "    idx = best5[i]\n",
    "    image = test_images[idx]\n",
    "    print(\"Reconstruction Error\", reconstructions_errors[idx])\n",
    "    encoded_img = AE.encode(np.expand_dims(image, axis=0))\n",
    "    decoded_img = AE.decode(encoded_img)\n",
    "    encoded_img = np.squeeze(encoded_img)\n",
    "    decoded_img = np.squeeze(decoded_img)\n",
    "    #Turn decoded_img into intergers\n",
    "    decoded_img = decoded_img.astype(int)\n",
    "    fix, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(decoded_img)\n",
    "    ax[1].set_title(\"Reconstructed Image\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "for i in range(n):\n",
    "    idx = worst5[i]\n",
    "    image = test_images[idx]\n",
    "    print(\"Reconstruction Error\", reconstructions_errors[idx])\n",
    "    encoded_img = AE.encode(np.expand_dims(image, axis=0))\n",
    "    decoded_img = AE.decode(encoded_img)\n",
    "    encoded_img = np.squeeze(encoded_img)\n",
    "    decoded_img = np.squeeze(decoded_img)\n",
    "    #Turn decoded_img into intergers\n",
    "    decoded_img = decoded_img.astype(int)\n",
    "    fix, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(decoded_img)\n",
    "    ax[1].set_title(\"Reconstructed Image\")\n",
    "    plt.show() -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
