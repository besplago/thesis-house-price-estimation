{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class House: \n",
    "  def __init__(self, address, postal_code, type, real_price, \n",
    "                size, basement_size, rooms, year_built, \n",
    "                year_rebuilt, energy_label, image_floorplan): \n",
    "    \n",
    "    #Textual Data \n",
    "    self.address = address  \n",
    "    self.postal_code = postal_code\n",
    "    self.type = type\n",
    "    self.price = real_price\n",
    "    self.size = size\n",
    "    self.basement_size = basement_size\n",
    "    self.rooms = rooms\n",
    "    self.year_built = year_built\n",
    "    self.year_rebuilt = year_rebuilt\n",
    "    self.energy_label = energy_label\n",
    "\n",
    "    #Image Data \n",
    "    self.image_floorplan = image_floorplan\n",
    "    \n",
    "    #Predictions \n",
    "    self.predicted_price = None\n",
    "\n",
    "\n",
    "def load_jpg_and_json(folder_path:str) -> (dict, np.ndarray):\n",
    "  files = os.listdir(folder_path)\n",
    "  jpg_file_path = None\n",
    "  json_file_path = None\n",
    "\n",
    "  # Find the jpg and json file in the folder\n",
    "  for filename in files:\n",
    "    if filename.endswith(\".jpg\"):\n",
    "      jpg_file_path = os.path.join(folder_path, filename)\n",
    "    elif filename.endswith(\".json\"):\n",
    "      json_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "  # Load the jpg\n",
    "  image_data = cv2.imread(jpg_file_path)\n",
    "  # Load the json\n",
    "  with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "  if image_data is None:\n",
    "    raise Exception(f\"Error loading image {jpg_file_path}\")\n",
    "  if json_data is None:\n",
    "    raise Exception(f\"Error loading json {json_file_path}\")\n",
    "\n",
    "  return json_data, image_data\n",
    "\n",
    "def create_house_instance(json_data, jpg): \n",
    "  address = json_data[\"address\"]\n",
    "  postal_code = json_data[\"postal_code\"]\n",
    "  type = json_data[\"type\"]\n",
    "  price = json_data[\"price\"]\n",
    "  size = json_data[\"size\"]\n",
    "  basement_size = json_data[\"basement_size\"]\n",
    "  rooms = json_data[\"rooms\"]\n",
    "  year_built = json_data[\"year_built\"]\n",
    "  year_rebuilt = json_data[\"year_rebuilt\"] if json_data[\"year_rebuilt\"] else None\n",
    "  energy_label = json_data[\"energy_label\"]\n",
    "  image_floorplan = jpg\n",
    "\n",
    "  house = House(address, postal_code, type, price, \n",
    "                size, basement_size, rooms, year_built, \n",
    "                year_rebuilt, energy_label, image_floorplan)\n",
    "  return house\n",
    "\n",
    "def load_houses(folder_path: str, max_houses: int = None):\n",
    "    houses = []\n",
    "    count = 0  # Counter to track the number of loaded houses\n",
    "    for folder in os.listdir(folder_path):\n",
    "        if max_houses is not None and count >= max_houses:\n",
    "            break  # Stop loading houses if the maximum number is reached\n",
    "        try:\n",
    "            json_data, jpg = load_jpg_and_json(os.path.join(folder_path, folder))\n",
    "            house = create_house_instance(json_data, jpg)\n",
    "            houses.append(house)\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading house {folder}: {e}\")\n",
    "    return houses\n",
    "\n",
    "#If we want to work with a DF \n",
    "def data_to_DF(houses: list[House])-> pd.DataFrame:\n",
    "  data = []\n",
    "  for house in houses:\n",
    "    data.append([house.address, house.postal_code, house.type, house.price, \n",
    "                house.size, house.basement_size, house.rooms, house.year_built, \n",
    "                house.year_rebuilt, house.energy_label, house.image_floorplan])\n",
    "  df = pd.DataFrame(data, columns = [\"address\", \"postal_code\", \"type\", \"price\", \n",
    "                \"size\", \"basement_size\", \"rooms\", \"year_built\", \n",
    "                \"year_rebuilt\", \"energy_label\", \"image_floorplan\"])\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../nybolig-scrape/output\"\n",
    "houses = load_houses(path, max_houses=1000)\n",
    "houses_df = data_to_DF(houses)\n",
    "houses_df = houses_df[(houses_df['postal_code'] >= 1000) & (houses_df['postal_code'] <= 2920)]\n",
    "#Count type \n",
    "print(houses_df['type'].value_counts())\n",
    "houses_df = houses_df[houses_df['type'] == 'ejerlejlighed']\n",
    "\n",
    "print(\"Number of datapoints of type Ejerlejlighed: \", len(houses_df))\n",
    "display(houses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\"\"\"\n",
    "Add labels-column to the data-points, based on prices. Simply version\n",
    "\"\"\"\n",
    "def binary_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  mean = df[\"price\"].mean()\n",
    "  df[\"label\"] = df[\"price\"].apply(lambda x: 0 if x > mean else 1)\n",
    "  return df\n",
    "\n",
    "\"\"\"\n",
    "Add labels-column to the data-points, based on prices\n",
    "Creates labels based on a normal distribution around the data.\n",
    "That is, we have more labels the closer we are to the mean price, and less the further away we are.\n",
    "Return a data-Frame with the labels and the label codes. \n",
    "\"\"\"\n",
    "def normal_distribution_label(data: pd.DataFrame, num_labels:int)-> pd.DataFrame:\n",
    "  #We want to predict the price of the house \n",
    "  min = data['price'].min()\n",
    "  first_quan = data['price'].quantile(0.25)\n",
    "  mean = data['price'].mean()\n",
    "  third_quan = data['price'].quantile(0.75)\n",
    "  max = data['price'].max()\n",
    "  #Create a normal distribution of the labels\n",
    "  f1 = np.linspace(0, min, round(num_labels*0.023))\n",
    "  f2 = np.linspace(min, first_quan, round(num_labels*0.14))\n",
    "  f3 = np.linspace(first_quan, mean, round(num_labels*0.34))\n",
    "  f4 = np.linspace(mean, third_quan, round(num_labels*0.34))\n",
    "  f5 = np.linspace(third_quan,max, round(num_labels*0.14))\n",
    "  f6 = np.linspace(max, max*2, round(num_labels*0.023))\n",
    "  potential_labels = np.concatenate((f1, f2, f3, f4, f5, f6))\n",
    "\n",
    "  #Create the label codes\n",
    "  label_codes = [(i, label) for i, label in enumerate(potential_labels)]\n",
    "  \n",
    "  #Create the labels\n",
    "  price_labels = []\n",
    "  price_bracket = []\n",
    "  for price in data['price']:\n",
    "    diff = abs(potential_labels - price)\n",
    "    index = np.argmin(diff)\n",
    "    price_labels.append(index)\n",
    "    left = potential_labels[index-1] if index > 0 else potential_labels[index]\n",
    "    right = potential_labels[index+1] if index < len(potential_labels)-1 else potential_labels[index]\n",
    "    price_bracket.append((left, right))\n",
    "\n",
    "  data['label'] = price_labels\n",
    "  data['price_bracket'] = price_bracket\n",
    "  return data, label_codes\n",
    "\n",
    "def label_low_med_high(df: pd.DataFrame, onehot:bool)-> pd.DataFrame:\n",
    "  price_ranges = {\n",
    "    \"low\": (0,df['price'].quantile(0.33)),\n",
    "    \"med\": (df['price'].quantile(0.33), df['price'].quantile(0.66)),\n",
    "    \"high\": (df['price'].quantile(0.66), df['price'].max()), \n",
    "  }\n",
    "  def label(price): \n",
    "    if price >= price_ranges['low'][0] and price<= price_ranges['low'][1]: \n",
    "      return 0\n",
    "    elif price >= price_ranges['med'][0] and price <= price_ranges['med'][1]:\n",
    "      return 1\n",
    "    else: \n",
    "      return 2\n",
    "  df['label_price'] = df['price'].apply(label)\n",
    "\n",
    "  return df \n",
    "  \n",
    "\n",
    "def preprocces_data(df: pd.DataFrame)-> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Preprocess the data.\n",
    "  \"\"\"\n",
    "  #df = df.drop(columns=[\"address\"])\n",
    "  #Feature Columns\n",
    "  df['basement_size'] = df[\"basement_size\"].fillna(0)\n",
    "  df['year_rebuilt'] = df['year_rebuilt'].where(~df['year_rebuilt'].isna(), df['year_built']).astype(int)\n",
    "  #df['type'] = df['type'].astype('category').cat.codes\n",
    "  df['energy_label'] = df['energy_label'].astype('category').cat.codes\n",
    "  #data.dropna(inplace=True)\n",
    "\n",
    "  #Image Columns \n",
    "  #df['image_floorplan'] = df['image_floorplan'].apply(convert_to_grayscale)\n",
    "  #Optimal: use ImageGenerator to augment the images#\n",
    "  \n",
    "  #Adding Labels \n",
    "  #df = (label_low_med_high(df, onehot=True))\n",
    "\n",
    "  #Add a column that holds the image resolution\n",
    "  df['image_resolution'] = df['image_floorplan'].apply(lambda x: x.shape)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df = preprocces_data(houses_df)\n",
    "display(houses_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of different image_resolutions\n",
    "print(houses_df['image_resolution'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(df, column_name:str, width:int, height:int)-> np.array:\n",
    "  images = [image for image in df[column_name]]\n",
    "  resized_images = np.array([cv2.resize(image, (width, height), interpolation=cv2.INTER_LINEAR) for image in df[column_name]])\n",
    "  return resized_images\n",
    "\n",
    "def convert_to_grayscale(images: np.array)-> np.array:\n",
    "  gray_images = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images])\n",
    "  return gray_images\n",
    "\n",
    "def threshold_images(images: np.array)-> np.array:\n",
    "  image_shape = images[0].shape\n",
    "  if len(image_shape) == 3: #RGB\n",
    "    images = convert_to_grayscale(images)\n",
    "    thresholded_images = np.array([cv2.threshold(image, 150, 255, cv2.THRESH_BINARY)[1] for image in images])\n",
    "    #Convert back to RGB \n",
    "    thresholded_images = np.array([cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) for image in thresholded_images])\n",
    "  else: #GrayScale\n",
    "    thresholded_images = np.array([cv2.threshold(image, 150, 255, cv2.THRESH_BINARY)[1] for image in images])\n",
    "    \n",
    "  return thresholded_images\n",
    "\n",
    "def preprocess_images(df:pd.DataFrame, column_name:str, width:int, height:int, resize:bool, gray_scale:bool, threshhold:bool)-> np.array:\n",
    "  if resize:\n",
    "    images = resize_images(df, column_name, width, height)\n",
    "  if gray_scale:\n",
    "    images = convert_to_grayscale(images)\n",
    "  if threshhold:\n",
    "    images = threshold_images(images)\n",
    "  return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train, validation and test sets with a 60-20-20 ratio\n",
    "train_df, test_df = train_test_split(houses_df, test_size=0.2, random_state=0)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As most of the original images are 2100x1400, we resize them to 448*x\n",
    "target_width = 224*3\n",
    "target_height = 224*3\n",
    "\n",
    "train_images_Ori = preprocess_images(train_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=False)\n",
    "train_images_Gray = preprocess_images(train_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=True, threshhold=True)\n",
    "train_images_RGB = preprocess_images(train_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=True)\n",
    "\n",
    "validation_images_Ori = preprocess_images(valid_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=False)\n",
    "validation_images_Gray = preprocess_images(valid_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=True, threshhold=True)\n",
    "validation_images_RGB = preprocess_images(valid_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=True)\n",
    "\n",
    "test_images_Ori = preprocess_images(test_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=False)\n",
    "test_images_Gray = preprocess_images(test_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=True, threshhold=True)\n",
    "test_images_RGB = preprocess_images(test_df, \"image_floorplan\", target_width, target_height, resize=True, gray_scale=False, threshhold=True)\n",
    "\n",
    "# Display the first 5 images of train_images, train_images_gray and train_images_RGB\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 30))\n",
    "for i, (image, title) in enumerate(zip([train_images_Ori, train_images_Gray, train_images_RGB], [\"Original\", \"Grayscale\", \"Thresholded\"])):\n",
    "    axes[i].imshow(image[70])\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(zip(train_df[\"image_floorplan\"][0:9], train_df[\"price\"][0:9])):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{label}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def save_model(model, name): \n",
    "  model.save(name)\n",
    "  \n",
    "def load_model(model_name): \n",
    "  model = tf.keras.models.load_model(model_name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Check available GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Set the GPU to be used\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pre-trained VGG16 model (without including top layers)\n",
    "input_shape = train_images_RGB[0].shape \n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new top layers for regression\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_absolute_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images_RGB, train_df[\"price\"], validation_data=(validation_images_RGB, valid_df[\"price\"]), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save th model \n",
    "save_model(model, \"VVG16_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images_RGB, test_df[\"price\"])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images_RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "real_prices = test_df['price'].values\n",
    "predicted_prices = predictions.flatten()\n",
    "\n",
    "# Print the R2 score, MAE and MSE\n",
    "print(f\"R2 score: {r2_score(real_prices, predicted_prices):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae(real_prices, predicted_prices):.2f}\")\n",
    "print(f\"Mean Squared Error: {mse(real_prices, predicted_prices):.2f}\")\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label, prediction) in enumerate(zip(test_images_RGB[0:9], test_df[\"price\"][0:9], predictions[0:9])):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Real: {label}\\nPredicted: {prediction[0]:.0f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the predictions vs real prices\n",
    "plot_regression_results('VGG16', real_prices, predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPool2D, MaxPool1D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images_RGB\n",
    "validation_images = validation_images_RGB\n",
    "test_images = test_images_RGB\n",
    "\n",
    "\n",
    "median = houses_df[\"price\"].median()\n",
    "train_labels = train_df[\"price\"].apply(lambda x: 0 if x > median else 1)\n",
    "valid_labels = valid_df[\"price\"].apply(lambda x: 0 if x > median else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images[0].shape\n",
    "\n",
    "binary_model = Sequential()\n",
    "\n",
    "# Convolutional layers with batch normalization and dropout\n",
    "binary_model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "binary_model.add(BatchNormalization())\n",
    "binary_model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "binary_model.add(BatchNormalization())\n",
    "binary_model.add(MaxPooling2D(strides=(2, 2)))\n",
    "binary_model.add(Dropout(0.25))\n",
    "\n",
    "binary_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "binary_model.add(BatchNormalization())\n",
    "binary_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "binary_model.add(BatchNormalization())\n",
    "binary_model.add(MaxPooling2D(strides=(2, 2)))\n",
    "binary_model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten and dense layers with dropout\n",
    "binary_model.add(Flatten())\n",
    "binary_model.add(Dense(512, activation='relu'))\n",
    "binary_model.add(Dropout(0.25))\n",
    "binary_model.add(Dense(1024, activation='relu'))\n",
    "binary_model.add(Dropout(0.4))\n",
    "\n",
    "# Output layer with sigmoid activation for binary prediction\n",
    "binary_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "binary_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "#binary_model.summary()\n",
    "binary_model.fit(train_images, train_labels, validation_data=(validation_images, valid_labels), epochs=8, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train  = np.round(binary_model.predict(train_images),2)\n",
    "actual_train = train_labels\n",
    "for x,y in zip(predict_train, actual_train):\n",
    "  print(f\"Predicted: {x} Actual: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the binary model\n",
    "binary_model.save(\"binary_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Model: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "predicted_test_labels = binary_model.predict(test_images)\n",
    "actual_test_labels = [test_df['price'].apply(lambda x: 0 if x >= median else 1)]\n",
    "print(np.round(predicted_test_labels,2))\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy_score(actual_test_labels, predicted_test_labels):.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
