{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on: https://www.kaggle.com/code/raufmomin/vision-transformer-vit-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41341/485958369.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-03-11 10:28:57.946282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 10:28:57.946340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 10:28:57.947181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 10:28:57.953393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 10:28:58.855824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kaggle/input/vit-b32-classification/saved_model.pb\n",
      "./kaggle/input/vit-b32-classification/variables/variables.data-00000-of-00001\n",
      "./kaggle/input/vit-b32-classification/variables/variables.index\n",
      "./kaggle/input/vit-b32-fe/saved_model.pb\n",
      "./kaggle/input/vit-b32-fe/variables/variables.data-00000-of-00001\n",
      "./kaggle/input/vit-b32-fe/variables/variables.index\n",
      "./kaggle/input/vit-b8-fe/saved_model.pb\n",
      "./kaggle/input/vit-b8-fe/variables/variables.data-00000-of-00001\n",
      "./kaggle/input/vit-b8-fe/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from img_utils import *\n",
    "from multiprocessing import Process, Queue\n",
    "for dirname, _, filenames in os.walk('./kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: vit-b32-classification : ./kaggle/input/vit-b32-classification\n",
      "Image size: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Select an Image Classification model\n",
    "model_name = \"vit-b32-classification\"\n",
    "\n",
    "model_handle_map = {\n",
    "  \"vit-b8-fe\": \"./kaggle/input/vit-b8-fe\",\n",
    "  \"vit-b32-fe\": \"./kaggle/input/vit-b32-fe\",\n",
    "  \"vit-b32-classification\": \"./kaggle/input/vit-b32-classification\",\n",
    "}\n",
    "\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"vit-b8-fe\": 224,\n",
    "  \"vit-b32-fe\": 224,\n",
    "  \"vit-b32-classification\": 224,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name, 224)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Image size: {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(subset):\n",
    "    data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=.20,\n",
    "        subset=subset,\n",
    "        label_mode=\"categorical\",\n",
    "        # Seed needs to provided when using validation_split and shuffle = True.\n",
    "        # A fixed seed is used so that the validation set is stable across runs.\n",
    "        seed=123,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        batch_size=1)\n",
    "\n",
    "def parse_data(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_path = os.path.join(root, file)\n",
    "                with open(json_path) as f:\n",
    "                    data = json.load(f)\n",
    "                    price = data['price']\n",
    "                    image_path = os.path.join(root, '0.jpg')\n",
    "                    # Get image as tensor\n",
    "                    try:\n",
    "                        image = tf.io.read_file(image_path)\n",
    "                        image = tf.image.decode_jpeg(image, channels=3)\n",
    "                        # Resize image\n",
    "                        image = tf.image.resize(image, IMAGE_SIZE)\n",
    "                        # Normalize image\n",
    "                        image = image/255.0\n",
    "                        yield price, image\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading image {image_path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    pass\n",
    "\n",
    "def build_custom_dataset(directory: str, preprocces_data: bool = False, validation_split: float = 0.2) -> tf.data.Dataset:\n",
    "    data_generator = lambda: parse_data(directory)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        data_generator,\n",
    "        output_signature=(tf.TensorSpec(shape=(), dtype=tf.float32), tf.TensorSpec(shape=(pixels, pixels, 3), dtype=tf.float32))\n",
    "    )\n",
    "    print(f\"Found {len(list(dataset))} images in {directory}\")\n",
    "    dataset = dataset.map(lambda price, image: (image, price))\n",
    "    # Reshape dataset\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Split dataset\n",
    "    train_size = int((1-validation_split) * len(list(dataset)))\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 10:29:00.770642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.796424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.796523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.799664: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.799772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.799815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "Getting training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 10:29:00.986818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.986985: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.987004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-11 10:29:00.987063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-11 10:29:00.987086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 735 images in ../nybolig-scrape/output\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# p = Process(target=compile_and_fit_classification, args=(10, False))\u001b[39;00m\n\u001b[1;32m     89\u001b[0m p\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 90\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]], shape=(1, 224, 224, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_41341/2548349563.py\", line 16, in compile_and_fit_regression\n",
      "    plt.imshow(images.numpy().astype(\"uint8\"))\n",
      "  File \"/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/matplotlib/pyplot.py\", line 3343, in imshow\n",
      "    __ret = gca().imshow(\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/matplotlib/__init__.py\", line 1465, in inner\n",
      "    return func(ax, *map(sanitize_sequence, args), **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/matplotlib/axes/_axes.py\", line 5756, in imshow\n",
      "    im.set_data(X)\n",
      "  File \"/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/matplotlib/image.py\", line 723, in set_data\n",
      "    self._A = self._normalize_image_array(A)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/besplago/.pyenv/versions/penv/lib/python3.11/site-packages/matplotlib/image.py\", line 693, in _normalize_image_array\n",
      "    raise TypeError(f\"Invalid shape {A.shape} for image data\")\n",
      "TypeError: Invalid shape (1, 224, 224, 3) for image data\n"
     ]
    }
   ],
   "source": [
    "# Combine and train the model on custom regression data, with no labels\n",
    "def compile_and_fit_regression(epochs=50, do_fine_tuning=False):  # TODO: fuck this, try manually like in cnn_regression.ipynb\n",
    "  set_gpu()\n",
    "\n",
    "  print(\"Getting training data\")\n",
    "  train_ds, valid_ds = build_custom_dataset(\"../nybolig-scrape/output\")\n",
    "  train_size = len(list(train_ds))\n",
    "  valid_size = len(list(valid_ds))\n",
    "  \n",
    "  # Show some images\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "      ax = plt.subplot(3, 3, i + 1)\n",
    "      print(images)\n",
    "      plt.imshow(images.numpy().astype(\"uint8\"))\n",
    "      plt.title(labels.numpy())\n",
    "      plt.axis(\"off\")\n",
    "\n",
    "  print(\"Building model with\", model_handle)\n",
    "  model = tf.keras.Sequential([\n",
    "      # Explicitly define the input shape so the model can be properly\n",
    "      # loaded by the TFLiteConverter\n",
    "      tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "      hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "      tf.keras.layers.Dropout(rate=0.2),\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "  model.build((None,)+IMAGE_SIZE+(3,))\n",
    "  model.summary()\n",
    "\n",
    "  print(\"Compiling model\")\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae'])\n",
    "  \n",
    "  print(\"Training model\")\n",
    "  steps_per_epoch = train_size // BATCH_SIZE\n",
    "  validation_steps = valid_size // BATCH_SIZE\n",
    "  print(f\"SPE: {steps_per_epoch}, VS: {validation_steps}\")\n",
    "  hist = model.fit(\n",
    "      train_ds,\n",
    "      epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "      validation_data=valid_ds,\n",
    "      validation_steps=validation_steps).history\n",
    "  \n",
    "  print(\"Final training loss\", hist[\"loss\"][-1])\n",
    "  print(hist)\n",
    "\n",
    "  # Visualize the training and validation accuracy\n",
    "  plt.figure()\n",
    "  plt.ylabel(\"Mean Abs Error (training and validation)\")\n",
    "  plt.xlabel(\"Training Steps\")\n",
    "  plt.ylim([0,2])\n",
    "  plt.plot(hist[\"mae\"])\n",
    "  plt.plot(hist[\"val_mae\"])\n",
    "  plt.legend(loc='lower right')\n",
    "\n",
    "  # Visualize the training and validation loss\n",
    "  plt.figure()\n",
    "  plt.ylabel(\"Loss (training and validation)\")\n",
    "  plt.xlabel(\"Training Steps\")\n",
    "  plt.ylim([0,2])\n",
    "  plt.plot(hist[\"loss\"])\n",
    "  plt.plot(hist[\"val_loss\"])\n",
    "  plt.legend(loc='upper right')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  # Try predictions\n",
    "  price_batch = np.array([price for price, image in valid_ds])\n",
    "  image_batch = np.array([image for price, image in valid_ds])\n",
    "  predicted_batch = model.predict(image_batch)\n",
    "  plt.figure(figsize=(10,9))\n",
    "  plt.scatter(price_batch, predicted_batch)\n",
    "  plt.xlabel('True Values [Price]')\n",
    "  plt.ylabel('Predictions [Price]')\n",
    "  plt.axis('equal')\n",
    "  plt.axis('square')\n",
    "  plt.xlim([0,plt.xlim()[1]])\n",
    "  plt.ylim([0,plt.ylim()[1]])\n",
    "  _ = plt.plot([-100, 100], [-100, 100])\n",
    "  plt.show()\n",
    "  \n",
    "p = Process(target=compile_and_fit_regression, args=(2, False))\n",
    "# p = Process(target=compile_and_fit_classification, args=(10, False))\n",
    "p.start()\n",
    "p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
