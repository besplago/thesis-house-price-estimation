{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from img_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../nybolig-scrape/output\"\n",
    "houses_df = data_to_DF(path, max_houses=1000)\n",
    "print(\"Number of datapoints of type 'Ejerlejlighed': \", len(houses_df))\n",
    "display(houses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove outliers\n",
    "# houses_df = remove_outliers(houses_df, \"price\", z_score_threshold=2)\n",
    "\n",
    "# Split the data into train, validation and test sets with a 60-20-20 ratio\n",
    "train_df, test_df = train_test_split(houses_df, test_size=0.2, random_state=0)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_width = 500\n",
    "target_height = 500\n",
    "\n",
    "resize: bool = True\n",
    "gray_scale: bool = False\n",
    "threshhold: bool = True\n",
    "\n",
    "train_images_RGB = preprocess_images(train_df, \"image_floorplan\", target_width, target_height, resize = resize, gray_scale = gray_scale, threshhold = threshhold)\n",
    "validation_images_RGB = preprocess_images(valid_df, \"image_floorplan\", target_width, target_height, resize = resize, gray_scale = gray_scale, threshhold = threshhold)\n",
    "test_images_RGB = preprocess_images(test_df, \"image_floorplan\", target_width, target_height, resize = resize, gray_scale = gray_scale, threshhold = threshhold)\n",
    "\n",
    "train_prices = train_df['price']\n",
    "validation_prices = valid_df['price']\n",
    "test_prices = test_df['price']\n",
    "\n",
    "#Plot the first 5 images and their prices \n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 20))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(train_images_RGB[i])\n",
    "    ax[i].set_title(f\"Price: {train_prices.iloc[i]}\")\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def train_model(fine_tune_layers: int = 0):\n",
    "    \"\"\"\n",
    "    Train a model with the VGG16 architecture and save the model to disk.\n",
    "    \n",
    "    Args:\n",
    "        fine_tune_layers (int): Number of layers to fine-tune, counting from the top of the model.\n",
    "    \"\"\"\n",
    "    set_gpu()\n",
    "    \n",
    "    # Load pre-trained VGG16 model (excluding top layers)\n",
    "    input_shape = train_images_RGB[0].shape \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers[:-fine_tune_layers] if fine_tune_layers > 0 else base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add new top layers for regression\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(1072, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_error')\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(train_images_RGB, train_df[\"price\"], validation_data=(validation_images_RGB, valid_df[\"price\"]), epochs=100, callbacks=[early_stopping])\n",
    "\n",
    "    model.save(\"./VGG16_regression_model\")\n",
    "\n",
    "    # Plot the training history\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "p = Process(target=train_model, args=(0,))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(queue: Queue):\n",
    "    set_gpu()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loaded_model = tf.keras.models.load_model(\"./VGG16_regression_model\")\n",
    "    loaded_model.evaluate(test_images_RGB, test_df[\"price\"])\n",
    "    predictions = loaded_model.predict(test_images_RGB)\n",
    "    \n",
    "    queue.put(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = Queue()\n",
    "p = Process(target=evaluate_model, args=(queue,))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "if queue.empty():\n",
    "    raise ValueError(\"Nothing was returned from the process\")\n",
    "predictions = queue.get()\n",
    "real_prices = test_df['price'].values\n",
    "predicted_prices = predictions.flatten()\n",
    "\n",
    "# Print the R2 score, MAE and MSE\n",
    "print(f\"R2 score: {r2_score(real_prices, predicted_prices):.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae(real_prices, predicted_prices):.2f}\")\n",
    "print(f\"Mean Squared Error: {mse(real_prices, predicted_prices):.2f}\")\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label, prediction) in enumerate(zip(test_images_RGB[0:9], test_df[\"price\"][0:9], predictions[0:9])):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Real: {label}\\nPredicted: {prediction[0]:.0f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the predictions vs real prices\n",
    "plot_regression_results('VGG16', real_prices, predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_saliency_maps(images: np.ndarray):\n",
    "    set_gpu()\n",
    "    model = tf.keras.models.load_model(\"./VGG16_regression_model\")\n",
    "    saliency_maps = []\n",
    "    for image in images:\n",
    "        with tf.GradientTape() as tape:\n",
    "            image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "            image = tf.expand_dims(image, axis=0)\n",
    "            tape.watch(image)\n",
    "            predictions = model(image)\n",
    "\n",
    "        # Compute gradients of the output with respect to the input image\n",
    "        gradient = tape.gradient(predictions, image)\n",
    "        \n",
    "        # Take absolute value of gradients to get saliency map\n",
    "        saliency_map = tf.abs(gradient)\n",
    "        \n",
    "        # Reshape saliency map\n",
    "        saliency_map = tf.reshape(saliency_map, image.shape[1:])  # Remove batch dimension\n",
    "        \n",
    "        # Normalize between 0 and 1\n",
    "        saliency_map /= tf.reduce_max(saliency_map)\n",
    "\n",
    "        # Set color channels to 0\n",
    "        saliency_map = saliency_map[:, :, 0]\n",
    "\n",
    "        saliency_maps.append(saliency_map)\n",
    "\n",
    "    return saliency_maps\n",
    "\n",
    "def plot_saliency_maps(images):\n",
    "    fig, axes = plt.subplots(n_images, 2, figsize=(10, 5 * n_images))\n",
    "    saliency_maps = get_saliency_maps(images)\n",
    "\n",
    "    if len(images) > 1:\n",
    "        for i, image in enumerate(images):\n",
    "            # Plot the original image\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(\"Original Image\")\n",
    "            axes[i, 0].axis(\"off\")\n",
    "            \n",
    "            # Plot the saliency map\n",
    "            axes[i, 1].imshow(saliency_maps[i], cmap=\"plasma\")\n",
    "            axes[i, 1].set_title(\"Saliency Map\")\n",
    "            axes[i, 1].axis(\"off\")\n",
    "    else:\n",
    "        # Plot the original image\n",
    "        axes[0].imshow(images[0])\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        # Plot the saliency map\n",
    "        axes[1].imshow(saliency_maps[0], cmap=\"plasma\")\n",
    "        axes[1].set_title(\"Saliency Map\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "n_images = 4\n",
    "\n",
    "p = Process(target=plot_saliency_maps, args=(test_images_RGB[:n_images],))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Maps (doesn't work, WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def get_class_activation_maps(images: np.ndarray):\n",
    "#     set_gpu()\n",
    "#     model = tf.keras.models.load_model(\"./VGG16_regression_model\")\n",
    "#     classifier_layer = model.get_layer(\"dense_2\")\n",
    "#     base_model = model.get_layer(\"vgg16\")\n",
    "#     last_conv_layer = base_model.get_layer(\"block5_conv3\")\n",
    "\n",
    "#     class_activation_maps = []\n",
    "#     for image in images:\n",
    "#         # Convert the image to a tensor of type float32\n",
    "#         image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "#         image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "#         # Get the model's prediction\n",
    "#         predictions = model(image)\n",
    "\n",
    "#         # Get the class with the highest probability\n",
    "#         predicted_class = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "#         # Get the output of the classifier layer for the predicted class\n",
    "#         class_out = model.output[:, predicted_class]\n",
    "\n",
    "#         # Get the output of the last convolutional layer\n",
    "#         last_conv_output = last_conv_layer.output\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             # Compute the gradient of the class output value with respect to the feature map\n",
    "#             grads = tape.gradient(class_out, last_conv_output)\n",
    "\n",
    "#         # Vector of shape (512,), where each entry is the mean intensity of the gradient over a specific feature map channel\n",
    "#         pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "#         # Multiply each channel in the feature map array by \"how important this channel is\" with regard to the class\n",
    "#         last_conv_output_value = last_conv_output[0].numpy()\n",
    "#         pooled_grads_value = pooled_grads.numpy()\n",
    "#         for i in range(512):\n",
    "#             last_conv_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "#         # The channel-wise mean of the resulting feature map is our class activation map\n",
    "#         class_activation_map = np.mean(last_conv_output_value, axis=-1)\n",
    "\n",
    "#         # Normalize between 0 and 1\n",
    "#         class_activation_map -= np.min(class_activation_map)\n",
    "#         class_activation_map /= np.max(class_activation_map)\n",
    "\n",
    "#         class_activation_maps.append(class_activation_map)\n",
    "\n",
    "#     return class_activation_maps\n",
    "\n",
    "# def plot_class_activation_maps(images):\n",
    "#     fig, axes = plt.subplots(n_images, 2, figsize=(10, 5 * n_images))\n",
    "#     class_activation_maps = get_class_activation_maps(images)\n",
    "\n",
    "#     if len(images) > 1:\n",
    "#         for i, image in enumerate(images):\n",
    "#             # Plot the original image\n",
    "#             axes[i, 0].imshow(image)\n",
    "#             axes[i, 0].set_title(\"Original Image\")\n",
    "#             axes[i, 0].axis(\"off\")\n",
    "            \n",
    "#             # Plot the class activation map\n",
    "#             axes[i, 1].imshow(class_activation_maps[i], cmap=\"plasma\")\n",
    "#             axes[i, 1].set_title(\"Class Activation Map\")\n",
    "#             axes[i, 1].axis(\"off\")\n",
    "#     else:\n",
    "#         # Plot the original image\n",
    "#         axes[0].imshow(images[0])\n",
    "#         axes[0].set_title(\"Original Image\")\n",
    "#         axes[0].axis(\"off\")\n",
    "        \n",
    "#         # Plot the class activation map\n",
    "#         axes[1].imshow(class_activation_maps[0], cmap=\"plasma\")\n",
    "#         axes[1].set_title(\"Class Activation Map\")\n",
    "#         axes[1].axis(\"off\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# p = Process(target=plot_class_activation_maps, args=(test_images_RGB[:n_images],))\n",
    "# p.start()\n",
    "# p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
